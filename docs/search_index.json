[
["index.html", "Tillämpad statistik med R Kapitel 1 Introduktion 1.1 Om statistisk programmering med R 1.2 Allmänna tips om R på kursen 1.3 Sammanfattning 1.4 Referenser", " Tillämpad statistik med R Ronnie Pingel och Valentin Zulj 2020-11-25 Kapitel 1 Introduktion Detta material utgör kurslitteratur till kursen Tillämpad statistik (A5). Observera att materialet kommer att utökas under kursens gång. 1.1 Om statistisk programmering med R På denna kurs arbetar vi med R, som är ett programspråk och en miljö för statistisk dataanalys (https://www.r-project.org/) som fungerar på UNIX plattformar, Windows och MacOS. Det finns flera anledningar till att vi valt R: R är gratis och har en öppen källkod. R ger tillgång till avancerade verktyg för dataanalys och datavisualisering. Användare av R bidrar ofta med egen programkod och egna paket, vilket innebär att en omfattande mängd funktioner enkelt går att implementera. Många läroböcker skrivs med utgångspunkt från R. Online-resurserna är mycket stora. Det finns många forum där användare av R kan få hjälp (t ex https://stackoverflow.com/). R är ett av de absolut vanligaste programmen för statistisk dataanalys. (http://r4stats.com/2019/04/01/scholarly-datasci-popularity-2019/) Finns det anledningar till att inte välja R? Det finns ingen officiell support. Eftersom R bygger på användarnas bidrag finns ingen garanti att funktioner fungerar som de ska. Jämfört med andra programspråk kan R uppfattas som långsamt. För den som van vid menybaserade system (sk point-and-click) kan dessutom kodning uppfattas som en nackdel. Det finns emellertid etiska och praktiska skäl att lära sig programmera i statistikprogram (dvs att i kod skriva ange hur data ska hanteras och analyseras), och inte förlita sig på menyer. Programmering är nödvändig för att tillförlitligt upprepa (replikera) dataanalyser. På företag och på myndigheter ska kolleger kunna ta över datamaterial och tillhörande analyser och på nytt genomföra dessa med samma resultat. Samma sak gäller inom forskning, där andra forskare ska erhålla samma resultat givet samma data och analys. Notera att detta även gäller för dig själv, dvs det är inte ovanligt att som analytiker på nytt upprepa en analys. spar tid för repetativa moment, t ex om många liknande analyser ska genomföras. ger möjlighet till avancerade analyser samt frihet att utforma egna analyser. bidrar till ökad förståelse för dataanalys. Kruxet? Statistisk programmering tar längre tid att lära sig jämfört med att lära sig menybaserad datahantering och analyser! Tabell 2.1 redovisar några reflektioner över ett antal vanliga statistikprogram. Table 1.1: En jämförelse av några vanliga statistikprogram Minitab Mycket enkelt att lära sig. Används främst inom kvalitetskontroll i industri samt planering av randomiserade försök. Billigt. Begränsat urval av statistiska metoder SPSS Enkelt att lära sig. Stor spridning bland samhällsvetare och utredare. Ganska stort urval av statistiska metoder som är organiserade på ett något rörigt sätt. Krånglig programkod. Stata Enkelt att lära sig och mycket enkel programkod. Spridning bland forskare inom ekonometri och epidemiologi. Stort urval av, även de senaste, statistiska metoderna SAS Medelsvårt att lära sig, med en föråldrad programkod. Kan hantera stora dataset. Används av myndigheter, industri och forskare inom alla områden. Standard för läkemdelsbolag. Stort urval av statistiska metoder, men inte de allra senaste. Dyrt. Svårt att göra bra figurer. R Svårt att lära sig. Gratis. Flexibelt. Mycket stor spridning inom alla områden för dataanalys. Enkel programkod. Python Mycket svårt att lära sig. Gratis. Flexibelt. Stor spridning inom maskininlärning och AI. Varför är inte Excel, Open Office Calc, Google Docs och andra kalkylprogram inkluderade i jämförelsen? SVaret är enkelt. Dessa är nämligen inga statistikprogram! Ofta saknas i sådana program viktiga statistiska funktioner och dessutom är den numeriska tillförlitligheten lägre än för konventionella statistiskprogram (Keeling, K. B., &amp; Pavur, R. J., 2011). 1.2 Allmänna tips om R på kursen Det tar tid att lära sig R. Det kan även vara frustrerande, inte minst eftersom programmering är inte förlåtande vad gäller fel. Men misströsta inte, i slutändan är det värt det och är i högsta grad tidsbesparande. Här följer några tips vad gäller inlärningen och användandet av R under kursens gång: Se till att snabbt få grunderna på plats. R kommer att användas löpande under kursens gång. Arbeta aktivt med R. Programmering lär man sig genom tillämpning, inte genom att läsa. Det krävs normalt sett många timmar av aktivt arbete för att lära sig ett programspråk. Använd därför R till att lösa övningsuppgifter och att replikera exempel från föreläsningar. På så vis får du rutin vad gäller användandet av R. Använd kod som presenterats på kursen. Ändra och laborera i färdig kod för att se vad som händer. Det är inte viktigt att kunna skriva all kod utantill, däremot ska man förstå skriven kod och kunna manipulera denna för sitt syfte. Lös övningsuppgifter på följande vis: 1. Läs uppgiften och skissa därefter på papper upp en lösning, men gör inga beräkningar inte. Skriv ner antaganden och formler. 2. Lös sedan uppgiften med hjälp av beräkningar i R. Om du fastnar, studera R-koden i lösningsförslaget förstå hur hur uppgiften har lösts med hjälp R alternativt använd kod som presenterats på kursen. 3. Räkna därefter igenom uppgiften för hand. När du känner dig helt trygg med att räkna för hand kan du så småningom hoppa över detta moment. 4. Fyll i din papperslösning och avsluta med ett svar. Var inte rädd för att använda resurser på nätet. Se ovan. Kontakta lärare och lärarassistenter på kursen om ni fastnar och har frågor. Utnyttja de lärarledda sessionerna. Samarbeta och diskutera i de diskussionsforum som skapats för er studenter. På denna kurs rekommenderas att ni endast skriver kod på det sätt som det presenteras på kursen. Visserligen är R oerhört flexibelt och en uppgift går att lösa på en mängd sätt. Koden som presenteras på kursen är emellertid framtagen för att vara tydlig och tillförlitlig och syftet är att du ska bli trygg med att beräkningarna är korrekta snarare än effektiva. Slutligen, så är det bra att som läsare ha i åtanke att all beskrivning av kodens funktionalitet inte är uttömmande. Syftet är nämligen att lära ut vad som är nödvändigt för denna kurs och då behövs inte en fullständig beskrivning av till exempel vad ett verktyg i R kan göra. Lycka till! 1.3 Sammanfattning div.red{ background-color:#F5B7B1; border-radius: 5px; padding: 20px;} Du ska kunna motivera varför statistisk programmering är nödvändig för arbete med data och dataanalyser. 1.4 Referenser Keeling, K. B., &amp; Pavur, R. J. (2011). Statistical accuracy of spreadsheet software. The American Statistician, 65(4), 265-273. "],
["att-börja-använda-r.html", "Kapitel 2 Att börja använda R 2.1 Installation av R och RStudio 2.2 Installation av RStudio 2.3 Första sessionen 2.4 Paket 2.5 Sammanfattning 2.6 Övningar", " Kapitel 2 Att börja använda R I detta kapitel ska du inledningsvis installera R samt ett gränssnitt som kallas för RStudio. RStudio kan liknas vid en avancerad textredigerare som underlättar arbetet med R. Det går visserligen alldeles utmärkt att använda R som det är, men RStudio förenklar i många avseenden programmeringen. 2.1 Installation av R och RStudio Vid programmering är det mycket viktigt att noga följa instruktioner. Du ska nu först installera R. Därefter ska du installera RStudio. 2.1.1 Installation av R på MacOS Ladda ner den senaste versionen från https://cran.r-project.org/bin/macosx/. Notera att versionen måste passa för ditt MacOS. Leta upp den version som passar till ditt MacOS om du har en äldre Mac. Ladda ner pkg-filen under Latest release. Öppna den nedladdade .pkg-filen och installera R. 2.1.2 Installation av R på Windows Gå till hemsidan https://cran.r-project.org/bin/windows/base/. Klicka på ‘’Download R (versionnummer) for Windows’’. Eventuellt fungerar inte den senaste versionen ditt Window om du har en äldre Windows-versions. Prova då en tidigare version av R. Du kanske även upptäcker att senaste versionnummer på Rs hemsida inte är samma som används i detta exempel eftersom det kan ha kommit senare versioner. För din del saknar just detta praktisk betydelse. Dubbelklicka på ‘’R installer’’ för att starta installationen. Välj språk och tryck OK. Välj Next. Välj sökväg för din installation. Låt default vara. Klicka Next. För att förenkla, välj alla komponenter för installation. Klicka Next. Klicka No (accept defaults). För att lägga till R i Startmenyn, klicka bort kryssrutan nedan. Klicka Next. Välj om du vill ha genvägar. Klicka Next. Installation börjar! Starta R när den är klar. Starta R för första gången. På Windows ser det ut så här. 2.2 Installation av RStudio Av olika anledningar väljer vi att inte arbeta i R Editor utan vi väljer RStudio. Stäng därför ner R. Gå till https://rstudio.com/products/rstudio/download/}. 2 Välj RStudio Desktop Free. 3 Välj sedan den version stämmer överens med ditt operativsystem. Installera (på Windows) genom att klicka Next-&gt;Next-&gt;Install Starta RStudio. Du ska nu fått upp nedanstående. Vi ska i detalj beskriva vad de olika panelerna till höger kommer vi återkomma till när det är aktuellt. Avsluta RStudio. Om du mot förmodan inte skulle lyckas installera R och RStudio, så finns möjligheten att koppla upp sig till Statistiska institutionens datorer via fjärrskrivbordet och på så sätt få tillgång nödvändig programvara. 2.3 Första sessionen I denna session ska du bekanta dig med R och prova använda R som en miniräknare. Starta RStudio. Till vänster ska du ha en panel som heter Console. I denna panel redovisas resultat. Vad övriga paneler gör kommer vi återkomma till när det blir aktuellt. Välj i menyn File &gt; New File &gt; R Script. Ett nytt fönster (Untitled1) öppnas ovanför Console Detta är ett script-fönster eller en editor. I editorn skrivs kommandon in som sedan kan utvärderas av R. Resultaten redovisas i Console. Ha för vana att aldrig skriva kod direkt i R Console. I princip är en script-fil inte annorlunda än en vanlig textfil, förutom att filen har tillägget .R. Spara script med jämna mellanrum eftersom det är önskvärt att inte förlora sin kod ifall något oförutsett händer. Skapa därför en mapp med namnet A5Rkod på din dator. Välj File &gt; Save As… och spara i A5Rkod scriptet Untitled med namnet myfirstscript.R. Efter att vi har skrivit koden i editorn måste vi meddela R att koden ska utvärderas. Kod i scriptfilen körs (exekveras) på tre olika sätt: En rad: Raden där markören är placerad körs med Ctrl+Enter (command + Enter på Mac) eller Run ovanför scriptet. Flera rader: Markera kodavsnittet och tryck Ctrl+Enter (command + Enter på Mac) eller Run. Hela scriptet: Ctrl+Shift+Enter Det finns några viktiga punkter att ha i åtanke: Om avsikten är att köra kod som sträcker sig över flera rader måste man avsluta raden med räknetecken \\((+,-,*,/)\\), kommatecken \\(,\\) eller vänsterparentes \\((\\). En rad inleds aldrig med räknetecken eller kommatecken. En rad som inleds med # exekveras inte. Tecknet # används för att kommentera koden, vilket viktigt eftersom vi då i text kan förklara vad koden gör. Skriv in nedanstående script till myfirstscript.R. Spara. # Detta är mitt första R-script som heter myfirstscript.R. # I detta script använder jag R som miniräknare samt # exekverar kod från scriptet. 1+1 1+3 2-7 2*3 4/5 3^2 Använd R som miniräknare genom att prova alla tre sätt att köra kod. Det är nödvändigt att bekanta sig med hur kod körs för att bli bekväm med att simultant arbeta i script-fönstret och se resultat i Console. Återigen, skriv aldrig i Console. 1+1 [1] 2 1+3 [1] 4 2-7 [1] -5 2*3 [1] 6 4/5 [1] 0.8 3^2 [1] 9 Matematiska funktioner, t ex kvadratroten, finns implementerade i R. Skriv sqrt(6) i scriptet och spara. Kör koden och erhåll följande i Console. sqrt(6) [1] 2.44949 Även exponentialfunktionen \\(\\exp(x)\\) finns i R. Skriv exp(3) i script-filen, spara och kör. exp(3) [1] 20.08554 Konstanten \\(\\pi\\) finns i R. Skriv pi i script-filen, spara och kör. pi [1] 3.141593 Kod finns ofta på flera rader. Anta att vi önskar beräkna \\(2 + 2+ 3+ 5\\) men att koden inte får plats på en rad utan måste delas upp på två rader. Skriv in följande rader i scriptet, spara, markera bägge raderna och kör. # Kod över 2 rader 2 + 2 + 3 + 5 Följande resultat ska presenteras i Console. # Kod över 2 rader 2 + 2 + 3 + 5 [1] 12 Kod finns ofta på flera rader. Skriv in följande rader i scriptet, spara, markera bägge raderna och kör. Jämför resultatet med punkt 6! 2 + 2 + 3 + 5 Nu utvärderas raderna var för sig, vilket inte var avsikten med analysen. 2 + 2 [1] 4 + 3 + 5 [1] 8 Grattis! Du har nu genomfört din första session i R. Scriptet ska se ut enligt nedan. Spara och stäng R. # Detta är mitt första R-script som heter myfirstscript.R. # I detta script använder jag R som miniräknare samt # exekverar kod från scriptet. 1+1 1+3 2-7 2*3 4/5 3^2 # Kvadratroten sqrt(6) # Exponentialfunktionen exp(3) # Pi pi # Kod över 2 rader 2 + 2 + 3 + 5 2 + 2 + 3 + 5 2.4 Paket En viktig styrka med R är det stora antalet tillgängliga paket utvecklade av användare. Grundinstallationen av R är nämligen tämligen begränsad vad gäller funktionalitet, men med alla paket utvidgas den statistiska verktygslådan, de grafiska möjligheterna och förmågan att hantera olika typer av data rejält. Det finns ungefär 15000 paket på “The Comprehensive R Archive Network” (CRAN) som är Rs arkiv för paket: https://cran.r-project.org/web/packages/available_packages_by_name.html Det finns ytterligare tusentals andra paket som dock inte genomgått samma granskning som paketen på CRAN, till exempel på github. Eftersom antalet paket är överväldigande för nybörjaren kan det vara ett stöd att känna till de vanligaste paketen. Ett förslag på en lista över viktiga paket finns här: https://support.rstudio.com/hc/en-us/articles/201057987-Quick-list-of-useful-R-packages För att installera ett paket skriver man in paketnamnet med ett kommando alternativt använda menyn i RStudio under *Tools &gt; Install Packages**. Vi exemplifierar nu med ett paket som hjälper oss att läsa data från Excel-filer. Funktionalitet för inläsning från Excel-filer finns inte i basversionen av R, därför är detta paket nödvändigt om data är sparat i en Excelfil. Vi installerar paketet readxl genom att i Console skriva in install.packages(&quot;readxl&quot;) och trycka enter. Som tidigare nämnt går det även att installera paket via menyn. Efter installationen finns paketet sparat på din dator. R har emellertid inte ännu aktiverat det. Genom att skriva library(&quot;readxl&quot;) och trycka enter aktiveras paketet. Nu kan analyser i R utnyttja paketets funktionalitet. Observera att ett paket måste aktiveras på nytt varje gång RStudio öppnas. Dock behövs det bara installeras en enda gång. 2.5 Sammanfattning div.red{ background-color:#F5B7B1; border-radius: 5px; padding: 20px;} Du ska kunna installera R och Rstudio och starta det utan felmeddelanden. använda R som miniräknare och använda de olika metoderna för att exekvera kod i editorn. installera ett R-paket och aktivera det. 2.6 Övningar Övning 2.1 Du har ett stickprov betående av observationerna \\(4,-2,5,6,8\\). Beräkna medelvärdet. Beräkna standardavvikelsen. Beräkna variationsbredden. Beräkna det geometriska medelvärdet för de positiva värden \\(4, 5, 6, 8\\). Beräkna det geometriska medelvärdet för alla värden \\(4, -2, 5, 6, 8\\). Visa svar Medelvärdet \\(\\bar{x}\\) beräknas i R i editorn med (4 + (-2) + 5 + 6 + 8)/5 vilket i Console ger svaret ## [1] 4.2 Svar: Medelvärdet är 4.2 Standardavvikelsen \\(s\\) beräknas i R i editorn antingen genom att direkt tillämpa formeln för stickprovets standardavvikelse \\[s=\\sqrt{\\dfrac{\\sum_{i=1}^n (x_i -\\bar{x})^2}{n-1}}\\] sqrt( ( ( 4 - (4 + (-2) + 5 + 6 + 8)/5 )^2 + ( (-2) - (4 + (-2) + 5 + 6 + 8)/5 )^2 + ( 5 - (4 + (-2) + 5 + 6 + 8)/5 )^2 + ( 6 - (4 + (-2) + 5 + 6 + 8)/5 )^2 + ( 8 - (4 + (-2) + 5 + 6 + 8)/5 )^2 ) / (5-1) ) eller genom att använda beräkningsformeln \\[s=\\sqrt{\\dfrac{\\sum_{i=1}^{n}x_i ^2 - (\\sum_{i=1}^n x_i)^2/n}{n-1}}\\]. sqrt( ( 4^2 + (-2)^2 + 5^2 + 6^2 + 8^2 - (4 + (-2) + 5 + 6 + 8)^2/5 )/ (5-1) ) Oavsett formel erhålls i Console svaret ## [1] 3.768289 Svar: Standardavvikelsen är 3.768 Variationsbredden, dvs skillnaden mellan det största och det minsta värdet är 8 - (-2) ## [1] 10 Svar: Variationsbredden är är 10. Det geometriska medelvärdet \\[\\bar{x}_g=(x_1\\cdot x_2 \\cdot \\cdots \\cdot x_n)^{1/n}\\] kan i R beräknas med (4 * 5 * 6 * 8)^(1/4) ## [1] 5.566315 Svar: Det geometriska medelvärdet är 3.95. Det geometriska medelvärdet \\[\\bar{x}_g=(x_1\\cdot x_2 \\cdot \\cdots \\cdot x_n)^{1/n}\\] kan i R beräknas med (4 * (-2) * 5 * 6 * 8)^(1/5) ## [1] NaN Svar: Eftersom en observation är negativ blir NaN, vilket betyder ‘’Not a Number’’. Det går alltså inte att beräkna. Övning 2.2 Ett slumpmässigt urval ger följande observationer \\(0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1\\),där \\(1=Arbetslös\\) och \\(0=Förvärvsarbetande\\). Beräkna andelen arbetslösa i stickprovet. Visa svar Andelen arbetslösa beräkna i R med (0 + 1 + 1 + 0 + 0 + 0 + 0 + 0 + 1 + 0 + 1 + 0 + 1)/13 ## [1] 0.3846154 Svar: Andelen arbetslösa i stickprovet är 0.38. Övning 2.3 Kosumentpriset 2006-2011 är Table 2.1: Konsumentprisindex (KPI) 2006-2011 2006 284.2 2007 290.5 2008 300.6 2009 299.7 2010 303.5 2011 311.4 Med hur många procent har prisnivån förändrats från 2007 till 2010? Visa svar Beräkning i R ger 303.46/290.51 ## [1] 1.044577 Svar: Prisnivån har ökat med 4.5%. Övning 2.4 Denna övningar handlar om potentslagarna. Då \\(x\\) och \\(y\\) är reella och \\(a,b&gt;0\\) gäller följande likheter: \\(a^x\\cdot a^y=a^{x+y}\\) \\((a^x)^y=a^{xy}\\) \\(\\left(\\frac{a}{b}\\right)^x=\\frac{a^x}{b^x}\\) \\(\\frac{a^x}{a^y}=a^{x-y}\\) \\(a^x \\cdot b^x=(ab)^x\\) \\(a^0=1\\) Beräkna nedanstående uttryck relatera svaren till potenslagarna. \\(4^2 + 4^3\\) \\(4^2*4^3\\) \\(4^5\\) \\((4^2)^3\\) \\(4^15\\) \\(4^2/4^3\\) \\(4^{-1}\\) \\(4^{-2}\\) \\(1/(4^2)\\) \\(1/16\\) \\(3^4*4^4\\) \\(12^4\\) Visa svar I R kan uttrycken enkelt beräknas. 4^2 + 4^3 [1] 80 4^2*4^3 [1] 1024 4^5 [1] 1024 (4^2)^3 [1] 4096 4^15 [1] 1073741824 4^2/4^3 [1] 0.25 4^{-1} [1] 0.25 4^{-2} [1] 0.0625 1/(4^2) [1] 0.0625 1/16 [1] 0.0625 3^4*4^4 [1] 20736 12^4 [1] 20736 Vi ser att för \\(b= c\\) pga 1. \\(d= e\\) pga 2. \\(k=l\\) pga 5. Vidare gäller… Övning 2.5 Den naturliga logaritmen, dvs logaritmen med basen \\(e \\approx 2.718282\\), används ofta i statistiska beräkningar. Några logaratimlagar som gäller för naturliga logaritmen är: \\(\\ln\\, \\left (x\\cdot y \\right )=\\ln\\,x+\\ln\\,y\\) \\(\\ln\\, \\left (x/ y \\right )=\\ln\\,x-\\ln\\,y\\) \\(\\ln\\,x^{a}=a\\cdot \\ln\\,x\\) \\(\\ln e = 1\\) \\(e^{\\ln x} = x\\) \\(\\ln^{e^x} = x\\) Beräkna nedanstående uttryck och relatera svaren till logaritmlagarna \\(\\ln(3*4)\\) \\(\\ln(3) + \\ln(4)\\) \\(\\ln(3/4)\\) \\(\\ln(3) - \\ln(4)\\) \\(\\ln e\\) \\(\\ln e^5\\) \\(e^{5+6}\\) \\(e^5*e^6\\) $5 5 + 6 6 Visa svar I R kan uttrycken enkelt beräknas. log(3*4) [1] 2.484907 log(3) + log(4) [1] 2.484907 log(3/4) [1] -0.2876821 log(3) - log(4) [1] -0.2876821 log(exp(1)) [1] 1 log(exp(5)) [1] 5 exp(5+6) [1] 59874.14 exp(5)*exp(6) [1] 59874.14 5*log(5) + 6*log(6) [1] 18.79775 Övning 2.6 Låt observationerna \\(4,-2,5,6,8\\) vara obundet slumpmässigt urval från en normalfördelad population. Genomför en hypotesprövning på 5% signifikansnivå för att testa medelvärdet i population är skild från 1. Visa svar Vi observerar \\(x=\\{4,-2,5,6,8\\}.\\) Hypoteser: \\(H_0:\\mu=0\\) vs \\(H_1:\\mu \\neq 0\\) Antaganden: Variabeln \\(x\\) är normalfördelad i populationen. Populationsvariansen \\(\\sigma^2\\) är okänd i populationen. Vi har ett litet stickprov, \\(n=5\\). Testfunktionen ges av \\(t=\\dfrac{\\bar{x}-\\mu}{\\sqrt{s^2/n}}\\). Denna teststatistika är \\(t\\)-fördelad med \\(n-1\\) frihetsgrader om nollhypotesen är sann. Beslutregel: \\(\\alpha=0.05\\). Tvåsidigt test, förkasta därför \\(H_0\\) om \\(|t_{obs}| &gt; t_{krit} = t_{4,\\alpha/2=0.025} = 2.776\\) ( (4 + (-2) + 5 + 6 + 8)/5 - 1 )/sqrt( ( 4^2 + (-2)^2 + 5^2 + 6^2 + 8^2 - (4 + (-2) + 5 + 6 + 8)^2/5 )/ (5-1)/5 ) [1] 1.898851 Eftersom \\(t_{obs}=\\) 1.8988507 \\(&lt; 2.776 = t_{krit}\\) kan vi inte förkasta nollhypotesen. Svar: Vi kan på 5% signifikansnivå inte påvisa att medelvärdet i populationen är skilt från 1. Notera att detta inte innebär att vi visar att medelvärdet är 1. Övning 2.7 Du observerar följande datapunkter \\(x = \\{4,7,2,4,6\\}\\) och $y={7,3, 2, 5,6}$. Använd minsta-kvadratmetoden och beräkna koefficienterna \\(a\\) och \\(b\\) i regressionslinjen \\(y=a + bx\\). Använd koefficienterna och ge en prediktion för \\(y\\) givet att \\(x=7\\). Beräkna residualen för \\(x=7\\) Beräkna residualspridningen. Visa svar Riktningskoefficienten ges av \\[b=\\dfrac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\] # Direkt tillämpning av formeln ger ( (4 - (4 + 7 + 2 + 4 + 6)/5) * (7 - (7 + 3 + 2 + 5 + 6)/5) + (7 - (4 + 7 + 2 + 4 + 6)/5) * (3 - (7 + 3 + 2 + 5 + 6)/5) + (2 - (4 + 7 + 2 + 4 + 6)/5) * (2 - (7 + 3 + 2 + 5 + 6)/5) + (4 - (4 + 7 + 2 + 4 + 6)/5) * (5 - (7 + 3 + 2 + 5 + 6)/5) + (6 - (4 + 7 + 2 + 4 + 6)/5) * (6 - (7 + 3 + 2 + 5 + 6)/5) ) / ( (4 - (4 + 7 + 2 + 4 + 6)/5)^2 + (7 - (4 + 7 + 2 + 4 + 6)/5)^2 + (2 - (4 + 7 + 2 + 4 + 6)/5)^2 + (4 - (4 + 7 + 2 + 4 + 6)/5)^2 + (6 - (4 + 7 + 2 + 4 + 6)/5)^2 ) [1] 0.2105263 # Det går att räkna ut detta i flera steg genom att # t ex beräkna täljare och nämnare separat. # Alternativt använda beräkningsformeln ( 4*7 + 7*3 + 2*2 + 4*5 + 6*6 - (4+7+2+4+6)*(7+3+2+5+6)/5 )/ ( (4^2 + 7^2 + 2^2 + 4^2 + 6^2) - (4 + 7 + 2 + 4 + 6)^2/5 ) [1] 0.2105263 # En kommentar: Dessa beräkningar kommer förenklas betydligt i R, vilket vi ska se senare. Interceptet är \\(a=\\bar{y} - b\\bar{x}\\) (7 + 3 + 2 + 5 + 6)/5 - 0.2105*(4 + 7 + 2 + 4 + 6)/5 [1] 3.6317 Svar: Riktningskoefficienten beräknas till \\(b=0.2105\\), vilket tolkas som att om \\(x\\) ökar en enhet så ökar \\(y\\) i genomsnitt med \\(0.2105\\) enheter. Interceptet beräknas till \\(a=3.632\\), vilket tolkas som medelvärdet för \\(y\\) när \\(x=0\\). Använd koefficienterna från regressionslinjen och sätt in värdet \\(x=7\\). 3.6316 + 0.2105*7 [1] 5.1051 Svar: Prediktionen \\(\\hat{y}=\\) 5.1051. Detta är punkten på regressionslinjen när \\(x=7\\) och vår bästa gissning för det \\(y\\)-värde en individ med värdet \\(x=7\\) kommer att ha. En residual är skillnaden mellan ett predicerat värde och det faktiska observerade värdet, \\(\\hat{\\varepsilon}=y_i - \\hat{y}\\). Eftersom \\(y=3\\) när \\(x=7\\) så residualen 3 - (3.6316 + 0.2105*7) [1] -2.1051 Svar: Residualen för \\(x=7\\) är -2.1051. Residualspridningen ges av \\[s_\\varepsilon=\\sqrt{\\dfrac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}}= \\sqrt{\\dfrac{\\sum_{i=1}^n\\hat{\\varepsilon}_i^2}{n-2}}\\]. Vi beräknar på samma sätt som i c) övriga residualer, kvadrerar och summerar. sqrt( ( (7 - (3.6316 + 0.2105*4))^2 + (3 - (3.6316 + 0.2105*7))^2 + (2 - (3.6316 + 0.2105*2))^2 + (5 - (3.6316 + 0.2105*4))^2 + (6 - (3.6316 + 0.2105*6))^2 ) / (5 - 2) ) [1] 2.347077 Svar: Residualspridningen är 2.347 (Notera att \\(\\sum_{i=1}^n \\hat{\\varepsilon}_i^2\\) kallas för residualkvadratsumman.) Övning 2.8 Installera paketet MASS som innehåller funktioner som kan vara användbara senare på kursen. Aktivera det installerade paketet MASS. Visa svar # Installera paket install.packages(&quot;psych&quot;) # Aktivera paket library(&quot;psych&quot;) "],
["data-objekt-och-funktioner.html", "Kapitel 3 Data, objekt och funktioner 3.1 Data och objekt 3.2 Vektorer 3.3 Matriser 3.4 Data frames 3.5 Funktioner 3.6 Sammanfattning 3.7 Övningar", " Kapitel 3 Data, objekt och funktioner För att kunna arbeta med statistik och dataanalys är det viktigt att inte enbart förstå den statistiska metoden och kunna lösa problem med hjälp av en miniräknare. I praktiken är det även nödvändigt att förstå hur data hanteras, lagras och struktureras. I detta kapitel introduceras typer av data som normalt hanteras i R, sedan följer avsnitt om de olika typer av objekt som finns i R. Kapitlet avslutas med se på vad en funktion i R är för något och hur funkioner kan användas för att hantera objekt. Detta är ett omfattande kapitel, men det är viktigt att du kan hantera allt som presenteras. Avsikten med kaptitlet är nämligen att ta upp de allra vanligaste. 3.1 Data och objekt Utan data är statistik innehållslöst. På samma sätt är data grundläggande för arbete i R. De vanligaste datatyperna i R är character (text), som anges med citationstecken t ex “a”, “3”. numeric (decimaltal), t ex är 3, 32.1. Notera att 3 kan skriva 3.0. integer (heltal). 3, 32. Skillnaden mellan numeric och integer är att inga decimaler sparas, vilket spar minne. logical (data indikerar om något är sant eller falskt, TRUE/FALSE). Observera att dessa datatyper beskriver hur data är lagrad och hur R ska tolka data. Det säger sig kanske självt att det inte går att använda räkneoperation om data är character (text). Datatyper ska inte förväxlas med de datanivåer (nominal, ordinal, intervall och kvotskala) som man normalt förknippar med statistiska analyser. Datatyper ska inte heller förväxlas med om data är diskreta, kontinuerliga, kategorier eller kvantitativa. Det är mycket viktigt för alla som arbetar med statistiska analyser av data att kunna tillämpa alla ovanstående begrepp på rätt situation. Ofta överlappar begreppen, men det är vanligt att begreppen inte gör det. Tabellen nedan ger en översikt av begreppen som används, men notera att det finns undantag från denna klassificering och det finns andra sätt att klassificera. Mätskala Variabeltyp Datatyp i R Nominal Kategori, kvalitativ Character, factor med ordered = FALSE Ordinal Kategori, kvalitativ Character, factor med ordered = TRUE Intervall Kvantitativ, kontinuerlig, heltal, diskret Numeric, integer Kvot Kvantitativ, kontinuerlig, heltal, diskret Numeric, integer Data hanteras och sparas som objekt. För att skapa ett objekt används assignment-operatorn &lt;-. Objektet sparas därmed i minnet i R, men inget resultat redovisas i Console. Om R stängs ner måste objektet skapas på nytt såvida användaren inte har angett att objektet ska sparas. I regel arbetar man i R med flera olika objekt samtidigt. Objekten måste därför namnges och precis som Vid all programmering är noggrannhet a och o. Objektnamn inleds med en bokstav och får endast innehålla bokstäver, siffror, _ och .. Dessutom skiljer R på versaler och gemener. Det är inte alltid enkelt att namnge objekt, men det viktigaste är att vara konsekvent. På denna kurs rekommenderas följande principer för namngivning av objekt. Använd endast gemener. korta och logiska namn, t ex kan objektet population förkortas till pop. gärna understreck _ för sammanbinda långa objektnamn. Objektet ålder för kvinnor skulle kunna betecknas age_women och motsvarande för män är då age_men. Använd inte å, ä och ö. inte namn som redan är upptagna i R, t ex exp eller log. Det tre vanligaste objekten för hantering av data är: vektorer, matriser, data frames. 3.2 Vektorer En vektor är ett dataobjekt som är endimensionellt och består av \\(n\\) element. En vektor skapas med kommandot c() (‘’Combine Values into a Vector’’). Anta att vi observerar värdena \\(3,-1,1,5,0\\). Med hjälp av nedanstående kod skapas ett vektor-objekt med med 5 element: # Skapa din första numeriska vektor my__first_vec &lt;- c(3, -1, 1, 5, 0) Notera att inget visas i Console, men att objektet finns sparat i minnet upptäcker man i RStudio genom att observera den övre högra panelen under fliken Environment. Där listas alla objekt som finns sparade i minnet i R. För att titta på objektet exekveras objektet genom att köra nedanstående kod. &gt; # Visa din första numeriska vektor &gt; my__first_vec &gt; [1] 3 -1 1 5 0 Du ska nu skapa ett antal vektorobjekt som sedan på olika sätt ska manipuleras. Skapa ett script som heter kap3_objekt_och_funktioner.R genom att välja File &gt; New File &gt; R Script och sedan direkt spara scriptet med File &gt; Save As i mappen A5Rkod. Skriv in koden nedan i scriptet och spara med File &gt; Save. Det är bra att få rutin på att ofta spara sitt script så att inte kod råkar försvinna. # Skapar två numeriska vektorer x &lt;- c(3, 1, 1, 5, 0) y &lt;- c(2, 3, 5, 6, 9) # Kombinera vektorer till en ny vektor z &lt;- c(x, y) Generellt gäller i R att om \\(x\\) är en vektor bestående av \\(k\\) element \\[x = (x_1,x_2,\\ldots,x_k)\\] och \\(y\\) är en vektor bestående av \\(l\\) element \\[y = (y_1,y_2,\\ldots,y_l)\\] så skapar kommandot z &lt;- c(x,y) en vektor med \\(k + l\\) element, \\[z= (x_1,x_2,\\ldots,x_k,y_1,y_2,\\ldots,y_l)=(z_1,z_2,\\ldots,z_{k+l}).\\] För att se om detta stämmer tittar vi på objekten genom att exekvera dem. Fortsätt scriptet genom att skriva in nedanstående kod. Spara och kör koden. x y z I Console ser du då följande: &gt; x &gt; [1] 3 1 1 5 0 &gt; y &gt; [1] 2 3 5 6 9 &gt; z &gt; [1] 3 1 1 5 0 2 3 5 6 9 Både \\(x\\), \\(y\\) och \\(z\\) är numeriska vektorer. Det går även att skapa en vektor bestående av bokstäver. För att skapa en sådan vektor (character vector) sätts de enskilda elementen inom citationstecken. Fortsätt scriptet och skriv in nedanstående kod i scriptet, spara och kör koden. # Skapar en vektor med ord nordic_countries &lt;- c(&quot;Denmark&quot;, &quot;Finland&quot;, &quot;Iceland&quot;, &quot;Norway&quot;, &quot;Sweden&quot;) nordic_countries I Console ser du då följande resultat. &gt; # Skapar en vektor med ord &gt; nordic_countries &lt;- c(&quot;Denmark&quot;, &quot;Finland&quot;, &quot;Iceland&quot;, &quot;Norway&quot;, &quot;Sweden&quot;) &gt; nordic_countries &gt; [1] &quot;Denmark&quot; &quot;Finland&quot; &quot;Iceland&quot; &quot;Norway&quot; &quot;Sweden&quot; Kombineras en numerisk och en character-vektor blir hela vektorn en character-vector. Skriv följande kod i scriptet, spara och kör koden. # Kombinera en numerisk vektor med en vektor med ord x_nordic_countries &lt;- c(x, nordic_countries ) x_nordic_countries I Console erhålls följande output och vi ser att de tidigare numeriska värdena nu omges av citationstecken. &gt; # Kombinera en numerisk vektor med en vektor med ord &gt; x_nordic_countries &lt;- c(x, nordic_countries ) &gt; x_nordic_countries &gt; [1] &quot;3&quot; &quot;1&quot; &quot;1&quot; &quot;5&quot; &quot;0&quot; &quot;Denmark&quot; &quot;Finland&quot; &gt; [8] &quot;Iceland&quot; &quot;Norway&quot; &quot;Sweden&quot; Om en numerisk vektor kombineras med en vektor med bokstäver så blir hela vektorn en character-vektor. R tolkas alltså siffrorna som bokstäver/tecken utan relation till numeriska värden. Det ser vi genom att det finns finns citationstecken kring siffrorna. Vi ska nu se introducera hur man på andra sätt kan skapa vektorer typer av vektorer. Skriv in nedanstående kod i scriptet och spara. Kör koden. # Skapar en vektor med värdena 1,2,3,4,5 v &lt;- 1:5 # Skapar en vektor med endast ett element u &lt;- 150 # Skapar en vektor med ett bortfall. ymis &lt;- c(3, NA, 6, 3, 6) I Console visas &gt; # Skapar en vektor med värdena 1,2,3,4,5 &gt; v &lt;- 1:5 &gt; # Skapar en vektor med endast ett element &gt; u &lt;- 150 &gt; # Skapar en vektor med ett bortfall. &gt; ymis &lt;- c(3, NA, 6, 3, 6) För att sammanfatta så har vi har hittills skapat numeriska vektorer, vektorer som enbart innehåller bokstäver och vektorer som skapats genom sekvenser. Vidare finns vektorer med bortfall anges med NA (Not Available). div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} En vektor som innehåller enbart en datatyp kallas för atomic. Detta kan vara värt att känna till eftersom eftersom det är vanligt att felmeddelande referar till just att en vektor inte är atomic. Inled en rad med # för att kommentera kod. Kommentera alltid kod!. Vid all programmering är det viktigt att förklara kod så att du själv och andra snabbt förstår vad koden gör. Det är viktigt att få rutin på att kommentera, kommentera därför även enkel kod. Nya vektorer kan skapas med räkneoperationer. Beräkningarna sker då elementvis, till exempel adderas elementvärden i en vektor till elementvärden i en annan vektor som har motsvarade position. Vektorerna måste antingen ha lika många element eller att den enda vektorna består av en konstant. Skriv in nedanstående i ditt script, spara och kör. # Addition av x och y x + y # Multiplikation av x och y x * y # Potenser skrivs med a^b y^2 # En konstant u adderas till alla element i vektorn x + u # Räkneoperationer med NA ger NA x + ymis # Division med 0 är ej definierat. R anger det som Inf (infinity) # eller NaN (Not a Number) om det är 0/0. x/0 # Exempel på längre räkneoperationer. # Notera att alla beräkningar är elementvisa. w &lt;- x + (y^2 - u)/v w I Console visas &gt; # Addition av x och y &gt; x + y &gt; [1] 5 4 6 11 9 &gt; # Multiplikation av x och y &gt; x * y &gt; [1] 6 3 5 30 0 &gt; # Potenser skrivs med a^b &gt; y^2 &gt; [1] 4 9 25 36 81 &gt; # En konstant u adderas till alla element i vektorn &gt; x + u &gt; [1] 153 151 151 155 150 &gt; # Räkneoperationer med NA ger NA &gt; x + ymis &gt; [1] 6 NA 7 8 6 &gt; # Division med 0 är ej definierat. R anger det som Inf (infinity) &gt; # eller NaN (Not a Number) om det är 0/0. &gt; x/0 &gt; [1] Inf Inf Inf Inf NaN &gt; # Exempel på längre räkneoperationer. &gt; # Notera att alla beräkningar är elementvisa. &gt; w &lt;- x + (y^2 - u)/v &gt; w &gt; [1] -143.00000 -69.50000 -40.66667 -23.50000 -13.80000 Ovanstående illustrerar att genom att användning av objekt kan beräkningar förenklas. Nu ska vi se vad som händer om elemementen består av olika antal element. Skriv i Console in nedanstående kod och tryck enter. x + c(2,5,6) I Console visas &gt; x + c(2,5,6) &gt; Warning in x + c(2, 5, 6): longer object length is not a multiple of &gt; shorter object length &gt; [1] 5 6 7 7 5 Detta innebär att om vektorn \\(x\\) (innehållande 5 element) adderas till en vektor bestående av endast 3 element, dvs antalet element skiljer sig åt, erhålls ett felmeddelande. Det gäller oavsett räknesätt. Om däremot den ena vektorn är en konstant, som i exemplet med vektorn \\(u\\) ovan, fungerar beräkningarna genom att konstanten beräknas för alla element i den större vektorn. 3.2.1 Vektorer och indexering Vi ska nu presentera hur enskilda element kan väljas ut i vektorer. Eftersom data i praktiken alltid måste anpassas för planerade analyser är detta nödvändigt. Det mest grundläggande i hantering av vektorer är att konstatera att varje element i en vektor har en position. Med hakparenteser [] erhålls åtkomst till ett eller flera element. Skriv in nedanstående i ditt script, spara och kör. # Visa element nummer 2 i vektorn x x[2] # Visa element 2, 3 och 4 i vektorn y y[c(2,3,4)] I Console redovisas &gt; # Visa element nummer 2 i vektorn x &gt; x[2] &gt; [1] 1 &gt; # Visa element 2, 3 och 4 i vektorn y &gt; y[c(2,3,4)] &gt; [1] 3 5 6 Det går även att spara utvalda element till en ny vektor. Skriv in nedanstående i ditt script. # Spara element nummer 2 i vektorn x2 x2 &lt;- x[2] x2 # Visa element 2, 3 och 4 i vektorn y234 y234 &lt;- y[c(2,3,4)] y234 I Console redovisas &gt; # Spara element nummer 2 till vektorn x2 &gt; x2 &lt;- x[2] &gt; x2 &gt; [1] 1 &gt; # Spara element 2, 3 och 4 till vektorn y234 &gt; y234 &lt;- y[c(2,3,4)] &gt; y234 &gt; [1] 3 5 6 Det går att tillämpa negativ indexering för att exkludera angivna element. Resterande element i en vektor behålls då. Skriv in nedanstående i scriptet, spara, och kör. # Spara element nummer 1,3,4,5 till vektorn x1345 x1345 &lt;- x[-2] x1345 # Spara element 1 och 5 till vektorn y15 y15 &lt;- y[-c(2,3,4)] y15 I Console redovisas nedanstående. &gt; # Spara element nummer 1,3,4,5 till vektorn x1345 &gt; x1345 &lt;- x[-2] &gt; x1345 &gt; [1] 3 1 5 0 &gt; # Spara element 1 och 5 till vektorn y15 &gt; y15 &lt;- y[-c(2,3,4)] &gt; y15 &gt; [1] 2 9 En viktigt skäl till att identifiera element är att användaren då på ett enkelt sätt kan hantera värden som identifierade element har. Skriv i nedanstående i scriptet, spara och kör. # Ändra element 3 från 1 till 4 x_new &lt;- x x_new[3] &lt;- 4 x_new # Ändra element 3 från &quot;Iceland&quot; till 4 nordic_countries_new &lt;- nordic_countries nordic_countries_new[3] &lt;- 4 nordic_countries_new I Console redovisas nedanstående. &gt; # Ändra element 3 från 1 till 4 &gt; x_new &lt;- x &gt; x_new[3] &lt;- 4 &gt; x_new &gt; [1] 3 1 4 5 0 &gt; # Ändra element 3 från &quot;Iceland&quot; till 4 &gt; nordic_countries_new &lt;- nordic_countries &gt; nordic_countries_new[3] &lt;- 4 &gt; nordic_countries_new &gt; [1] &quot;Denmark&quot; &quot;Finland&quot; &quot;4&quot; &quot;Norway&quot; &quot;Sweden&quot; Ovanstående kod illustrerar två vanliga företeelser: Vektorerna x_new och nordic_countries_new skapas på grund av att användaren ofta önskar behålla originalvektorerna x och nordic_countries. Detta är ofta önskvärt. Om ett numeriskt värde läggs till en vektor med bokstäver så tolkas det numeriska värdet som ett tecken, dvs “4”. Det illustrerar vikten av vara noga med om vektorerna är numeriska eller character 3.2.2 Vektorer och logiska operatorer Istället för att direkt identifiera positionen i vektorn kan man använda logiska operatorer. Några vanliga och viktiga logiska operatorer är: &gt; är större än. &lt; är mindre än. &gt;= större än eller lika med &lt;= mindre än eller lika med == lika med. != är ej lika med x|y \\(x\\) eller \\(y\\) x &amp; y \\(x\\) och \\(y\\) Genom att använda dessa kan användaren direkt hantera data i vektorn. Fortsätt scriptet genom att skriva in nedanstående kod. Spara och kör koden. # Visa element i vektor y som är större än 6 y[y &gt; 6] # Visa element i vektor y som är större än eller lika med 6 y[y &gt;= 6] # Visa element i vektor y från positioner där x har värden lika med 1. # (Kräver att x och y har lika många element) y[x == 1] # Visa element i vektor där x är ej lika med 1. y[x != 1] # Visa element i vektor y från positioner där nordic_countries == &quot;Finland&quot; y[nordic_countries == &quot;Finland&quot;] I Console visas &gt; # Visa element i vektor y som är större än 6 &gt; y[y &gt; 6] &gt; [1] 9 &gt; # Visa element i vektor y som är större än eller lika med 6 &gt; y[y &gt;= 6] &gt; [1] 6 9 &gt; # Visa element i vektor y från positioner där x har värden lika med 1. &gt; # (Kräver att x och y har lika många element) &gt; y[x == 1] &gt; [1] 3 5 &gt; # Visa element i vektor där x är ej lika med 1. &gt; y[x != 1] &gt; [1] 2 6 9 &gt; # Visa element i vektor y från positioner där nordic_countries == &quot;Finland&quot; &gt; y[nordic_countries == &quot;Finland&quot;] &gt; [1] 3 Precis som förut skapas i regel nya vektorer när logiska operatorer tillämpas. Skriv in nedanstående i scriptet, spara och kör koden. # Välj vektorn som är större än eller lika med 6 ysub &lt;- y[y &gt;= 6] # Skapa en binär vektor x_bin som är 1 om x är större än eller lika med 3 och 0 # om x är mindre än 3. Börja med att skapa en tom vektor med motsvarande antal element # och fyll sedan denna med saknade värden. x_bin &lt;- c(NA, NA, NA, NA, NA) x_bin[x &gt;=3] &lt;- 1 x_bin[x &lt; 3] &lt;- 0 # Skapa en tom vektor med 5 element och fyll därefter denna vektor med # data om landet är skandinaviskt eller ej scandinavia &lt;- c(NA, NA, NA, NA, NA) scandinavia[nordic_countries == &quot;Finland&quot;] &lt;- &quot;Not scandinavia&quot; scandinavia[nordic_countries == &quot;Denmark&quot;] &lt;- &quot;Scandinavia&quot; scandinavia[nordic_countries == &quot;Sweden&quot;] &lt;- &quot;Scandinavia&quot; scandinavia[nordic_countries == &quot;Norway&quot;] &lt;- &quot;Scandinavia&quot; scandinavia[nordic_countries == &quot;Iceland&quot;] &lt;- &quot;Not scandinavia&quot; scandinavia I Console visas &gt; # Välj vektorn som är större än eller lika med 6 &gt; ysub &lt;- y[y &gt;= 6] &gt; &gt; # Skapa en binär vektor x_bin som är 1 om x är större än eller lika med 3 och 0 &gt; # om x är mindre än 3. Börja med att skapa en tom vektor med motsvarande antal element &gt; # och fyll sedan denna med saknade värden. &gt; x_bin &lt;- c(NA, NA, NA, NA, NA) &gt; x_bin[x &gt;=3] &lt;- 1 &gt; x_bin[x &lt; 3] &lt;- 0 &gt; x &gt; [1] 3 1 1 5 0 &gt; x_bin &gt; [1] 1 0 0 1 0 &gt; # Skapa en tom vektor med 5 element och fyll därefter denna vektor med &gt; # data om landet är skandinaviskt eller ej &gt; scandinavia &lt;- c(NA, NA, NA, NA, NA) &gt; scandinavia[nordic_countries == &quot;Finland&quot;] &lt;- &quot;Not scandinavia&quot; &gt; scandinavia[nordic_countries == &quot;Denmark&quot;] &lt;- &quot;Scandinavia&quot; &gt; scandinavia[nordic_countries == &quot;Sweden&quot;] &lt;- &quot;Scandinavia&quot; &gt; scandinavia[nordic_countries == &quot;Norway&quot;] &lt;- &quot;Scandinavia&quot; &gt; scandinavia[nordic_countries == &quot;Iceland&quot;] &lt;- &quot;Not scandinavia&quot; &gt; scandinavia &gt; [1] &quot;Scandinavia&quot; &quot;Not scandinavia&quot; &quot;Not scandinavia&quot; &quot;Scandinavia&quot; &gt; [5] &quot;Scandinavia&quot; OVanstående moment är viktigt. Här illustreras nämligen en grundläggande princip för skapandet av nya variabel, dvs först skapa en tom vektor som sedans fylls med information. Även om det finns alternativa kompaktare sätt att koda om vektorer (och följaktligen variabler), är det ovanstående tillvägagångssätt som rekommenderas starkt på denna kurs. Nästa steg är att använda den logiska operatorn &amp;. Skriv in nedanstående i scriptet, spara och kör koden. # Skapa en vektor z_trinary som är # 1 om z är mindre än eller lika med 1 # 2 om z är större än 1 eller mindre än eller lika med 5 # 3 om z är större än 5 z_trinary &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) z_trinary[z &lt;= 1] &lt;- 1 z_trinary[(z &gt; 1) &amp; (z &lt;=5)] &lt;- 2 z_trinary[z &gt; 5] &lt;- 3 z z_trinary # Skapa en binära variabler z1, z2 och z3 z1 &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) z1[z_trinary == 1] &lt;- 1 z1[z_trinary == 2] &lt;- 0 z1[z_trinary == 3] &lt;- 0 z2 &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) z2[z_trinary == 1] &lt;- 0 z2[z_trinary == 2] &lt;- 1 z2[z_trinary == 3] &lt;- 0 z3 &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) z3[z_trinary == 1] &lt;- 0 z3[z_trinary == 2] &lt;- 0 z3[z_trinary == 3] &lt;- 1 z1 z2 z3 I Console redovisas följande. &gt; # Skapa en vektor z_trinary som är &gt; # 1 om z är mindre än eller lika med 1 &gt; # 2 om z är större än 1 eller mindre än eller lika med 5 &gt; # 3 om z är större än 5 &gt; z_trinary &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) &gt; z_trinary[z &lt;= 1] &lt;- 1 &gt; z_trinary[(z &gt; 1) &amp; (z &lt;= 5)] &lt;- 2 &gt; z_trinary[z &gt; 5] &lt;- 3 &gt; z &gt; [1] 3 1 1 5 0 2 3 5 6 9 &gt; z_trinary &gt; [1] 2 1 1 2 1 2 2 2 3 3 &gt; &gt; # Skapa en binära variabler z1, z2 och z3 &gt; z1 &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) &gt; z1[z_trinary == 1] &lt;- 1 &gt; z1[z_trinary == 2] &lt;- 0 &gt; z1[z_trinary == 3] &lt;- 0 &gt; &gt; z2 &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) &gt; z2[z_trinary == 1] &lt;- 0 &gt; z2[z_trinary == 2] &lt;- 1 &gt; z2[z_trinary == 3] &lt;- 0 &gt; &gt; z3 &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) &gt; z3[z_trinary == 1] &lt;- 0 &gt; z3[z_trinary == 2] &lt;- 0 &gt; z3[z_trinary == 3] &lt;- 1 &gt; z1 &gt; [1] 0 1 1 0 1 0 0 0 0 0 &gt; z2 &gt; [1] 1 0 0 1 0 1 1 1 0 0 &gt; z3 &gt; [1] 0 0 0 0 0 0 0 0 1 1 Ett par viktiga punkter att komma ihåg är Arbetsgången är att en ny vektor skapas, vilken sedan fylls på. För en binär variabel skulle vi teoretiskt kunna använda operatorn !=, men detta kan dels leda till att NA i en vektor kodas till 0, dels att datatvätten blir mindre noggrann. Ovanstående metodik för att skapa ny variabler är transparent. Använd parenteser för att undvika eventuella fel, som till exempel var fallet med (z &gt; 1) &amp; (z &lt;= 5). Avslutningsvis ska vi använda den logiska operatorn |. Skriv in nedanstående i scriptet, spara och kör koden. # Om z1 = 1 eller z3 = 1, så ska w_bin = 1. # Om z2 = 1 så ska d_bin = 0. # Skapa en tom vektor w_bin d_bin &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) d_bin[(z1 == 1) | (z3 == 1)] &lt;- 1 d_bin[z2 == 1] &lt;- 0 z1 z2 z3 w_bin # Om landet är Norge eller Island och x &gt; 4 eller w &gt; -50 så ska vi sätta NA y_new &lt;- y y_new[( (nordic_countries == &quot;Iceland&quot;) | (nordic_countries == &quot;Norway&quot;) ) &amp; ( (x &gt; 4) | (w &gt; -50) ) ] &lt;- NA nordic_countries x w y_new I Console ser vi utskrifterna. Om du inte har förstått koden, så kan du jämföra vektorerna och se varför w_bin och y_new har fått de värden som de har. # Om z1 = 1 eller z3 = 1, så ska w_bin = 1. # Om z2 = 1 så ska d_bin = 0. # Skapa en tom vektor w_bin d_bin &lt;- c(NA,NA,NA,NA,NA,NA,NA,NA,NA,NA) d_bin[(z1 == 1) | (z3 == 1)] &lt;- 1 d_bin[z2 == 1] &lt;- 0 z1 z2 z3 w_bin # Om landet är Norge eller Island och x &gt; 4 eller w &gt; -50 så ska vi sätta NA y_new &lt;- y y_new[( (nordic_countries == &quot;Iceland&quot;) | (nordic_countries == &quot;Norway&quot;) ) &amp; ( (x &gt; 4) | (w &gt; -50) ) ] &lt;- NA nordic_countries x w y_new Ovanstående sätt att förändra och skapa vektorer används mycket ofta i R och kan hantera mycket av den praktiska datahantering som du kommer att stöta på under denna kurs, men också ute i arbetslivet. Som tidigare nämnts finns andra sätt att åstadkomma samma resultat, som kanske till och med i specifika avseenden bättre, men utgå på denna kurs från kod som presenteras här. Det bör nämnas att det naturligtvis finns mycket mer att lära sig om hur logiska operatorer fungerar. Till exempel skapar nedanstående kod den sista datatypen som nämndes inledningsvis, dvs logical data. Skriv in nedanstående i scriptet, spara och kör koden. # Ger en logisk vektor (x &gt; 4) ## [1] FALSE FALSE FALSE TRUE FALSE # Multiplikation med en logisk vektor 1*(x &gt; 4) ## [1] 0 0 0 1 0 4*(x &gt; 4) ## [1] 0 0 0 4 0 Spara scriptet kap3_objekt_och_funktioner.R. 3.3 Matriser En matris är ett tvådimensionellt dataobjekt bestående av rader och kolumner. Notera ordningen, dvs en matris storlek anges först med rader, sedan med kolumner. Analogt med c(), som kombinerar element till en vektor, används rbind() och cbind() för att binda ihop vektorer radvis eller kolumnvis till matriser. En matris måste innehålla element av samma datatyp, vilket innebär att det inte går att binda samman numeriska vektorer som med vektorer som innehåller bokstäver. En matris kan även skapas direkt med kommandot matrix() som transformerar en vektor med \\(k\\) antal element till en matris bestående motsvarande antal element fördelat på antal rader och kolumner. Fortsätt scriptet kap3_objekt_och_funktioner.R och skriv in nedanstående kod. Spara scriptet och kör. # Skapa en matris genom att binda samman x och y radvis. Matrisen får 2 rader och 5 kolumner m1 &lt;- rbind(x, y) m1 # Skapa en matris genom att binda samman x, y, n och x radvis. Matrisen får 5 rader och 4 kolumner. m2 &lt;- cbind(x, y, n, x) m2 # Skapa en matris genom att binda samman x och ymis radvis. Matrisen får 5 rader och 2 kolumner. m3 &lt;- rbind(x, ymis) m3 # Skapa med matrix() en matris med två rader och 5 kolumner. # Matrisen fylls på kolumnvis och notera att detta inte blir samma som m1. m4 &lt;- matrix(z, 2, 5) m4 # Skapa med matrix() en matris med fem rader och 2 kolumner. # I detta fall är de två första kolumnerna i m2 samma som m5. m5 &lt;- matrix(z, 5, 2) m5 I Console visas &gt; # Skapa en matris genom att binda samman x och y radvis. Matrisen får 2 rader och 5 kolumner &gt; m1 &lt;- rbind(x, y) &gt; m1 &gt; [,1] [,2] [,3] [,4] [,5] &gt; x 3 1 1 5 0 &gt; y 2 3 5 6 9 &gt; # Skapa en matris genom att binda samman x, y, n och x radvis. Matrisen får 5 rader och 4 kolumner. &gt; m2 &lt;- cbind(x, y, u, x) &gt; m2 &gt; x y u x &gt; [1,] 3 2 150 3 &gt; [2,] 1 3 150 1 &gt; [3,] 1 5 150 1 &gt; [4,] 5 6 150 5 &gt; [5,] 0 9 150 0 &gt; # Skapa en matris genom att binda samman x och ymis radvis. Matrisen får 5 rader och 2 kolumner. &gt; m3 &lt;- rbind(x, ymis) &gt; m3 &gt; [,1] [,2] [,3] [,4] [,5] &gt; x 3 1 1 5 0 &gt; ymis 3 NA 6 3 6 &gt; # Skapa med matrix() en matris med två rader och 5 kolumner. &gt; # Matrisen fylls på kolumnvis och notera att detta inte blir samma som m1. &gt; m4 &lt;- matrix(z, 2, 5) &gt; m4 &gt; [,1] [,2] [,3] [,4] [,5] &gt; [1,] 3 1 0 3 6 &gt; [2,] 1 5 2 5 9 &gt; # Skapa med matrix() en matris med fem rader och 2 kolumner. &gt; # I detta fall är de två första kolumnerna i m2 samma som m5. &gt; m5 &lt;- matrix(z, 5, 2) &gt; m5 &gt; [,1] [,2] &gt; [1,] 3 2 &gt; [2,] 1 3 &gt; [3,] 1 5 &gt; [4,] 5 6 &gt; [5,] 0 9 div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Använd på denna kurs rbind() och cbind() vid skapande av matriser. Det är då mindre risk för för missförstånd var elementen hamnar i matrisen. För åtkomst till element krävs nu, eftersom matriser består av rader och kolumner, att bägge dimensionerna anges. Först anges radnummer, sedan kolumnnummer. Skriv in nedanstående kod i scriptet, spara och kör. # Visa element på rad 2 och kolumn 3 m1[2,3] # Visa element på rad 2 och alla kolumner m1[2,] # Visa element på alla rader och kolumner 3 m1[,3] # Visa m2[c(1,2),] I Console visas &gt; # Visa element på rad 2 och kolumn 3 &gt; m1[2,3] &gt; y &gt; 5 &gt; # Visa element på rad 2 och alla kolumner &gt; m1[2,] &gt; [1] 2 3 5 6 9 &gt; # Visa element på alla rader och kolumner 3 &gt; m1[,3] &gt; x y &gt; 1 5 &gt; # Visa &gt; m2[c(1,2),] &gt; x y u x &gt; [1,] 3 2 150 3 &gt; [2,] 1 3 150 1 Precis som vad gäller vektorer går det att utföra elementvisa beräkningar. Det kräver att matriserna har samma antal rader och kolumner. Det går även att utföra räkneoperationer med en konstant. Observera att elementvis multiplikation inte är detsamma som matematikens matrismultiplikation. Det är naturligtvis inga problem att i R använda matrismultiplikation, men detta går utanför kursens avgränsning. För att exemplfiera räkneoperationer med matriser, skriv in nedanstående kod i scriptet, spara och kör. # Addera element i matris 1 med element i matris 3 m1 + m3 # Multiplicera element i matris 1 med element i matris 3. OBS! Detta är inte matrismultiplikation! m1 * m3 # Dividera element i matris 1 med en konstant u m1 / u # Nedanstående är INTE det som inom matematiken benämns inversen av en matris, utan är 1/elementvärde 1/m1 I Console visas &gt; # Addera element i matris 1 med element i matris 3 &gt; m1 + m3 &gt; [,1] [,2] [,3] [,4] [,5] &gt; x 6 2 2 10 0 &gt; y 5 NA 11 9 15 &gt; # Multiplicera element i matris 1 med element i matris 3. OBS! Detta är inte matrismultiplikation! &gt; m1 * m3 &gt; [,1] [,2] [,3] [,4] [,5] &gt; x 9 1 1 25 0 &gt; y 6 NA 30 18 54 &gt; # Dividera element i matris 1 med en konstant n &gt; m1 / u &gt; [,1] [,2] [,3] [,4] [,5] &gt; x 0.02000000 0.006666667 0.006666667 0.03333333 0.00 &gt; y 0.01333333 0.020000000 0.033333333 0.04000000 0.06 &gt; # Nedanstående är INTE det som inom matematiken benämns inversen av en matris, utan är 1/elementvärde &gt; 1/m1 &gt; [,1] [,2] [,3] [,4] [,5] &gt; x 0.3333333 1.0000000 1.0 0.2000000 Inf &gt; y 0.5000000 0.3333333 0.2 0.1666667 0.1111111 Spara scriptet kap3_objekt_och_funktioner.R. Det går att tillämpa logiska operatorer även på matriser, men den extra dimensionen gör detta omständligt. Dessutom konstaterade vi att matrisen endast kan hantera en datatyp. Därför introduceras en tredje typ av dataobjekt som bättre sätt hanterar datamaterial. Det är dock bra att känna till att vid mer avancerad användning av R är matriser dock ett mycket viktigt verktyg. 3.4 Data frames En data frame är i praktiken det vanligaste objektet för dataanalys. En data frame har två dimensioner (rader och kolumner), men kan till skillnad från matrisen måste inte kolumnerna ha samma datatyp. Vad som dock krävs är att en kolumn består av en och samma datatyp. Vidare innehåller en data frame detaljerad information om exempelvis variabelnamn och variabeltyp. För att skapa en data frame används data.frame() och vi ska nu se på några exempel. Observera att en data frame även anger information om radnummer. Dessa nummer är dock inte definierade som en sepearat kolumn. Skriv nedanstående kod i kap3_objekt_och_funktioner.R, spara och kör. # Skapa en data frame genom att ange vektorer df &lt;- data.frame(x, y, nordic_countries) df # Skapa en data frame genom att transformera en matris. data.frame(m3) I Console erhålls följande resultat. &gt; # Skapa en data frame genom att ange vektorer &gt; df &lt;- data.frame(x, y, nordic_countries) &gt; df &gt; x y nordic_countries &gt; 1 3 2 Denmark &gt; 2 1 3 Finland &gt; 3 1 5 Iceland &gt; 4 5 6 Norway &gt; 5 0 9 Sweden &gt; # Skapa en data frame genom att transformera en matris. &gt; data.frame(m3) &gt; X1 X2 X3 X4 X5 &gt; x 3 1 1 5 0 &gt; ymis 3 NA 6 3 6 För åtkomst till element finns nu flera alternati och vi ska se på de två vanligaste: Precis som för matriser kan användaren använda hakparenteserna ´[]´ Genom att använda $ väljs en variabel i en dataframe. Det går sedan att använda hakparentes för att välja ett element i denna variabel. Nedanstående kod illustrerar de bägge metoderna. Skriv nedanstående kod i kap3_objekt_och_funktioner.R, spara och kör. # Visa kolumn 3 df[,3] # Visa variabeln nordic countries, dvs kolumn 3 df$nordic_countries # Visa värdet i rad 2 och kolumn 1 df[2,1] # Visa värdet för element 2 i variabeln x. df$x[2] I Console erhålls följande resultat. &gt; # Visa kolumn 3 &gt; df[,3] &gt; [1] Denmark Finland Iceland Norway Sweden &gt; Levels: Denmark Finland Iceland Norway Sweden &gt; df$nordic_countries &gt; [1] Denmark Finland Iceland Norway Sweden &gt; Levels: Denmark Finland Iceland Norway Sweden &gt; # Visa värdet i rad 2 och kolumn 1 &gt; df[2,1] &gt; [1] 1 &gt; df$x[2] &gt; [1] 1 Användning av enbart hakparentes är alltså ekvivalent med datahantering med hjälp av $ och sedan position. Även om koden med $ ofta blir längre, så blir koden mer lättförståelig jämfört med indexering för kolumn. Dessutom slipper man problemet med att indexeringen kan ändras om nya variabler adderas till det data frame man arbetar med eller om det på något annat sätt förändras. Med $ går det även enkelt att addera nya variabler till en data frame. Skriv nedanstående kod i kap3_objekt_och_funktioner.R, spara och kör. # Skapa variabeln sample_size baserat på n som bara har ett värde df$sample_size &lt;- u df # Skapa en variabel som heter ysq baserat på y i samma data frame. df$ysq &lt;- df$y^2 df # Skapa en tom variabel som heter x_cat df$x_cat &lt;- NA df I Console visas nedanstående. &gt; # Skapa variabeln sample_size baserat på n som bara har ett värde &gt; df$sample_size &lt;- u &gt; df &gt; x y nordic_countries sample_size &gt; 1 3 2 Denmark 150 &gt; 2 1 3 Finland 150 &gt; 3 1 5 Iceland 150 &gt; 4 5 6 Norway 150 &gt; 5 0 9 Sweden 150 &gt; # Skapa en variabel som heter ysq baserat på y i samma data frame. &gt; df$ysq &lt;- df$y^2 &gt; df &gt; x y nordic_countries sample_size ysq &gt; 1 3 2 Denmark 150 4 &gt; 2 1 3 Finland 150 9 &gt; 3 1 5 Iceland 150 25 &gt; 4 5 6 Norway 150 36 &gt; 5 0 9 Sweden 150 81 &gt; # Skapa en tom variabel som heter x_bin &gt; df$x_bin &lt;- NA &gt; df &gt; x y nordic_countries sample_size ysq x_bin &gt; 1 3 2 Denmark 150 4 NA &gt; 2 1 3 Finland 150 9 NA &gt; 3 1 5 Iceland 150 25 NA &gt; 4 5 6 Norway 150 36 NA &gt; 5 0 9 Sweden 150 81 NA Med $ förenklas även användningen av de logiska operatorerna och det blir enkelt att transformera variabler och även skapa mindre data frames. Skriv nedanstående kod i kap3_objekt_och_funktioner.R, spara och kör. # Ändra värdet på sample_size för Danmark från 150 till 300 df$sample_size[df$nordic_countries == &quot;Denmark&quot;] &lt;- 300 df # Ändra värden från NA till 1 i x_cat om x är större än 2 df$x_cat[x &gt; 2] &lt;- 1 df # Ändra värden från NA till 0 i x_cat om x är mindre än eller lika 2 df$x_cat[x &lt;= 2] &lt;- 0 df # Skapa ett nytt data frame som vi kallas df_sweden bestående av bara rader för Sverige df_sweden &lt;- df[df$nordic_countries== &quot;Sweden&quot;, ] df_sweden I Console visas nedanstående. &gt; # Ändra värdet på sample_size för Danmark från 150 till 300 &gt; df$sample_size[df$nordic_countries == &quot;Denmark&quot;] &lt;- 300 &gt; df &gt; x y nordic_countries sample_size ysq x_bin &gt; 1 3 2 Denmark 300 4 NA &gt; 2 1 3 Finland 150 9 NA &gt; 3 1 5 Iceland 150 25 NA &gt; 4 5 6 Norway 150 36 NA &gt; 5 0 9 Sweden 150 81 NA &gt; # Ändra värden från NA till 1 i x_cat om x är större än 2 &gt; df$x_cat[x &gt; 2] &lt;- 1 &gt; df &gt; x y nordic_countries sample_size ysq x_bin x_cat &gt; 1 3 2 Denmark 300 4 NA 1 &gt; 2 1 3 Finland 150 9 NA NA &gt; 3 1 5 Iceland 150 25 NA NA &gt; 4 5 6 Norway 150 36 NA 1 &gt; 5 0 9 Sweden 150 81 NA NA &gt; # Ändra värden från NA till 0 i x_cat om x är mindre än eller lika 2 &gt; df$x_cat[x &lt;= 2] &lt;- 0 &gt; df &gt; x y nordic_countries sample_size ysq x_bin x_cat &gt; 1 3 2 Denmark 300 4 NA 1 &gt; 2 1 3 Finland 150 9 NA 0 &gt; 3 1 5 Iceland 150 25 NA 0 &gt; 4 5 6 Norway 150 36 NA 1 &gt; 5 0 9 Sweden 150 81 NA 0 &gt; # Skapa ett nytt data frame som vi kallas df_sweden bestående av bara rader för Sverige &gt; df_sweden &lt;- df[df$nordic_countries== &quot;Sweden&quot;, ] &gt; df_sweden &gt; x y nordic_countries sample_size ysq x_bin x_cat &gt; 5 0 9 Sweden 150 81 NA 0 Vi kommer senare under kursen gång upprepade gånger att återkomma till data frames och titta närmare olika typer av sätt att hantera detta objekt. Vi avslutar med några grundläggande för att hatnera data frame. Skriv in nedanstående i scriptet kap3_objekt_och_funktioner.R. Spara och kör. # Med names() anges namnen i ett dataframe. names(df) # Med colnames() namnges variablerna i en data frame colnames(df) &lt;- c(&quot;age&quot;, &quot;income&quot;, &quot;nordic_countries&quot;) names(df) Vi ser nu i Console att variabelnamnen har ändrats. &gt; # Med names() anges namnen i ett dataframe. &gt; names(df) &gt; [1] &quot;x&quot; &quot;y&quot; &quot;nordic_countries&quot; &gt; [4] &quot;sample_size&quot; &quot;ysq&quot; &quot;x_bin&quot; &gt; [7] &quot;x_cat&quot; &gt; # Med colnames() namnges variablerna i en data frame &gt; colnames(df) &lt;- c(&quot;age&quot;, &quot;income&quot;, &quot;nordic_countries&quot;) &gt; names(df) &gt; [1] &quot;age&quot; &quot;income&quot; &quot;nordic_countries&quot; &gt; [4] NA NA NA &gt; [7] NA div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Hantering av data är av lättförklarliga skäl väldigt viktigt i R. Det tar inledningsvis tid att lära, men är samtidigt något som varje användare måste vara trygg med. Värt att nämna är att nästan alltid finns alternativa sätt arbeta med data i R och vad som presentas här är är endast ett alternativ. På denna kurs rekommenderas starkt att ni följer den metodik som presenteras här. Visserligen är den inte effektivast, varken i termer av beräkningstid eller längd på kod, men det är ett transparent arbetssätt som minimerar risken för att fel uppkommer. Datahanteringen är ofta en tidskrävande del i statistisk undersökning och stor noggrannhet är viktigt. Det går inte att tillräckligt betona hur betydelsefull datahanteringen är i en undersökning. En korrekt analys kräver ju korrekt data. 3.5 Funktioner En funktion utför operationer på objekt. Exakt vad funktionen gör beror på funktionen. Det vara allt från att utföra enkla räkneoperationer på data i en vektor, till komplicerade beräkningar och förändringar av data. Oftast sparas resultatet från en funktion som ett nytt objekt. En funktion har i regel också olika argument som gör det möjligt för användaren att anpassa vad funktionen gör. Den något mer avancerade R-användaren kan även enkelt skapa egna funktioner, vilket är styrka eftersom R då blir väldigt flexibelt. Att skapa egna funktioner ingår emellertid inte på denna kurs utan analyserna som utförs på kurser kommer hanteras av redan implementerade funktioner i R. Denna introduktionen till funktioner är därför relativt kortfattad och det enklaste sättet att introducera funktion blir med hjälp av exempel. Skriv in nedanstående kod i scriptet kap3_objekt_och_funktioner.R, spara och kör. # sum() är en funktion för att summera värdera i en vektor. Summan sparas i objektet summax summax &lt;- sum(x) summax # length() beräknar antalet element i en vektor och spara i objektet n n &lt;- length(x) n I Console får erhålls följande. &gt; # sum() är en funktion för att summera värdera i en vektor. Summan sparas i objektet sumx &gt; sumx &lt;- sum(x) &gt; sumx &gt; [1] 10 &gt; # length() beräknar antalet element i en vektor och spara i objektet n &gt; n &lt;- length(x) &gt; n &gt; [1] 5 Du har nu tillämpat funktionen sum() som summerar alla elementvärden i en vektor, dvs \\(\\sum_{i=1}^n x_i=x_1 + x_2 + \\cdots + x_k\\). Funktionen length() räknar antalet element. Med hjälp av dessa funktioner går det nu att på enkelt sätt att beräkna medelvärdet, \\(\\bar{x}=\\dfrac{1}{n}\\sum_{i=1}^n x_i\\), och stickprovsvarians, \\(s^2=\\dfrac{1}{n-1}\\sum_{i=1}^n(x_i - \\bar{x})^2\\). Notera att standardavvikelsen är \\(s=\\sqrt{s^2}\\). Skriv in nedanstående kod i scriptet kap3_objekt_och_funktioner.R, spara och kör. # Beräkna medelvärdet av en vektor sample.mean &lt;- (1/n)*sumx sample.mean # Beräkna stickprovsvarians s^2 med det sum() samt de sparade objekten xbar och n sample.variance &lt;- (1/(n-1))*sum( (x - xbar)^2 ) sample.variance I Console visas nedanstående. &gt; # Beräkna medelvärdet av en vektor &gt; sample.mean &lt;- (1/n)*sumx &gt; sample.mean &gt; [1] 2 &gt; &gt; # Beräkna stickprovsvarians s^2 med hjälp av sum() samt de sparade objekten xbar och n &gt; sample.variance &lt;- (1/(n-1))*sum( (x - sample.mean)^2 ) &gt; sample.variance &gt; [1] 4 Naturligtvis finns i R färdiga funktioner för både medelvärde och stickprovsvarians. Skriv in nedanstående kod i scriptet kap3_objekt_och_funktioner.R, spara och kör. # Beräkna medelvärdet av en vektor xbar &lt;- mean(x) xbar # Beräkna stickprovsvariansen av en vektor s2 &lt;- var(x) s2 I Console visas nedanstående. &gt; # Beräkna medelvärdet av en vektor &gt; xbar &lt;- mean(x) &gt; xbar &gt; [1] 2 &gt; # Beräkna stickprovsvariansen av en vektor &gt; s2 &lt;- var(x) &gt; s2 &gt; [1] 4 Resultatet är samma som det tidigare, enda skillnaden är att funktionerna mean(x) och var() förenklar ytterligare. Men vi genom detta också en förståelse för vilka formler som mean() och var() använder sig av. Skriv in nedanstående kod i scriptet kap3_objekt_och_funktioner.R, spara och kör. # Beräkna medelvärdet av ymis, en vektor med att bortfall ymis.mean &lt;- mean(ymis) ymis.mean # Beräkna medelvärdet av ymis, en vektor med att bortfall # ymisbar &lt;- mean(ymis, na.rm = TRUE) ymisbar I Console presenteras följande. &gt; # Beräkna medelvärdet av ymis, en vektor med att bortfall &gt; ymis.mean &lt;- mean(ymis) &gt; ymis.mean &gt; [1] NA &gt; # Beräkna medelvärdet av ymis, en vektor med att bortfall &gt; # &gt; ymisbar &lt;- mean(ymis, na.rm = TRUE) &gt; ymisbar &gt; [1] 4.5 Eftersom R ger att \\(y_1 + y_2 + NA + \\cdots + y_k = NA\\) blir även medelvärdet NA. Vi kan dock använda ett argument i funktionen som heter na.rm som vi sätter till TRUE. Om detta argument sätts till TRUE så tar funktionen före beräkning bort saknade värden. Default-inställningen är dock att detta argument är satt till FALSE. Det innebär att medelvärdet ymisbar är beräknat på de fyra värden som har observationer. För att veta vilka argument en funktion har skriver använd funktionen help(). I exemplet med medelvärdet så skriver du help(mean). I nedre högra panelen i Rstudio under fliken Help visas nu information om den funktion som vi ville veta mer om. I hjälpfilen står under Usage hur funktionen kan användas mean(x, trim = 0, na.rm = FALSE) och under Arguments hittar beskrivs vad argumenten betyder. Till exempel står det na.rm a logical value indicating whether NA values should be stripped before the computation proceeds.. Grundinställningen (default) satt till FALSE efter detta är angivet i Usage. Hjälpfilerna är ofta svåra att förstå, men exemplen längst ner i hjälpfilerna är i regel klargörande. På denna kurs kommer funktioner att introduceras efterhand. Funktioner är nämligen något som man lär sig genom tillämpning och inte genom att lära sig utantill i förväg. Dock kan det vara bra att ha en lista över alla de vanliga funktionerna så man vet vilka möjligheter som finns. https://cran.r-project.org/doc/contrib/Short-refcard.pdf Vi börjar här med några grundläggande funktioner som är användbara. Skriv in nedanstående kod i scriptet kap3_objekt_och_funktioner.R, spara och kör. # Skapa en vektor som repeterar värde 3 fem gånger x1 &lt;- rep(3, 5) x1 # Skapa en vektor som repeterar NA 10 fem gånger xNA &lt;- rep(NA, 5) xNA # Funktion som skapar en sekvens från 2 till 3 med steglängd 0.25 x2 &lt;- seq(from = 2, to = 3, by = 0.25) x2 # Skapa en en vektor av element som repeterats x3 &lt;- c(rep(1, 3), rep(4, 2), rep(9, 10)) x3 # Funktion för att summera information i ett objekt summary(ymis) # Funktion skapar ett histogram hist(x) # Funktion som skapar ett spridningsdiagram plot(x, y) I Console visas &gt; # Skapa en vektor som repeterar värde 3 fem gånger &gt; x1 &lt;- rep(3, 5) &gt; x1 &gt; [1] 3 3 3 3 3 &gt; # Skapa en vektor som repeterar NA 10 fem gånger &gt; xNA &lt;- rep(NA, 5) &gt; xNA &gt; [1] NA NA NA NA NA &gt; # Funktion som skapar en sekvens från 2 till 3 med steglängd 0.25 &gt; x2 &lt;- seq(from = 2, to = 3, by = 0.25) &gt; x2 &gt; [1] 2.00 2.25 2.50 2.75 3.00 &gt; # Skapa en en vektor av element som repeterats &gt; x3 &lt;- c(rep(1, 3), rep(4, 2), rep(9, 10)) &gt; x3 &gt; [1] 1 1 1 4 4 9 9 9 9 9 9 9 9 9 9 &gt; # Funktion för att summera information i ett objekt &gt; summary(ymis) &gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s &gt; 3.0 3.0 4.5 4.5 6.0 6.0 1 &gt; # Funktion skapar ett histogram &gt; hist(x) &gt; # Funktion som skapar ett spridningsdiagram &gt; plot(x, y) Avslutningsvis finns det ett antal frekvent använda samt viktiga funktioner för dataobjekt. Bekanta dig med dessa. &gt; # Funktion för att beskriva datatyp &gt; class(y) &gt; [1] &quot;numeric&quot; &gt; class(nordic_countries) &gt; [1] &quot;character&quot; &gt; # Funktion för att beskriva objekt &gt; str(y) &gt; num [1:5] 2 3 5 6 9 &gt; str(nordic_countries) &gt; chr [1:5] &quot;Denmark&quot; &quot;Finland&quot; &quot;Iceland&quot; &quot;Norway&quot; &quot;Sweden&quot; &gt; # Funktion för att ta reda på storleken på matris eller data frame &gt; dim(m1) &gt; [1] 2 5 &gt; dim(df) &gt; [1] 5 7 &gt; dim(df)[1] &gt; [1] 5 &gt; dim(df)[2] &gt; [1] 7 &gt; # Funktion för att beräkna längden av en vektor &gt; length(x) &gt; [1] 5 &gt; # Funktionen ls() listar alla objekt i minnet &gt; ls() &gt; [1] &quot;df&quot; &quot;df_sweden&quot; &quot;m1&quot; &gt; [4] &quot;m2&quot; &quot;m3&quot; &quot;m4&quot; &gt; [7] &quot;m5&quot; &quot;my__first_vec&quot; &quot;n&quot; &gt; [10] &quot;nordic_countries&quot; &quot;nordic_countries_new&quot; &quot;s2&quot; &gt; [13] &quot;sample.mean&quot; &quot;sample.variance&quot; &quot;scandinavia&quot; &gt; [16] &quot;sumx&quot; &quot;u&quot; &quot;v&quot; &gt; [19] &quot;w&quot; &quot;x&quot; &quot;x_bin&quot; &gt; [22] &quot;x_new&quot; &quot;x_nordic_countries&quot; &quot;x1&quot; &gt; [25] &quot;x1345&quot; &quot;x2&quot; &quot;x3&quot; &gt; [28] &quot;xbar&quot; &quot;xNA&quot; &quot;y&quot; &gt; [31] &quot;y15&quot; &quot;y234&quot; &quot;ymis&quot; &gt; [34] &quot;ymis.mean&quot; &quot;ymisbar&quot; &quot;ysub&quot; &gt; [37] &quot;z&quot; &quot;z_trinary&quot; &quot;z1&quot; &gt; [40] &quot;z2&quot; &quot;z3&quot; &gt; # Funktionen rm() raderar ett objekt &gt; rm(y) &gt; # Se om objektet y finns kvar &gt; ls() &gt; [1] &quot;df&quot; &quot;df_sweden&quot; &quot;m1&quot; &gt; [4] &quot;m2&quot; &quot;m3&quot; &quot;m4&quot; &gt; [7] &quot;m5&quot; &quot;my__first_vec&quot; &quot;n&quot; &gt; [10] &quot;nordic_countries&quot; &quot;nordic_countries_new&quot; &quot;s2&quot; &gt; [13] &quot;sample.mean&quot; &quot;sample.variance&quot; &quot;scandinavia&quot; &gt; [16] &quot;sumx&quot; &quot;u&quot; &quot;v&quot; &gt; [19] &quot;w&quot; &quot;x&quot; &quot;x_bin&quot; &gt; [22] &quot;x_new&quot; &quot;x_nordic_countries&quot; &quot;x1&quot; &gt; [25] &quot;x1345&quot; &quot;x2&quot; &quot;x3&quot; &gt; [28] &quot;xbar&quot; &quot;xNA&quot; &quot;y15&quot; &gt; [31] &quot;y234&quot; &quot;ymis&quot; &quot;ymis.mean&quot; &gt; [34] &quot;ymisbar&quot; &quot;ysub&quot; &quot;z&quot; &gt; [37] &quot;z_trinary&quot; &quot;z1&quot; &quot;z2&quot; &gt; [40] &quot;z3&quot; Avslutningsvis finns en viktig funktion som används för att radera alla objekt. Det är rm(list = ls()). Var försiktig med denna funktion eftersom alla objekt i minnet försvinner! Emellertid är god idé inleda ett script för en dataanlys med denna kod för att säkerställa att minnet är tomt innan ny data läses in. På så vis undviker vi konflkter mellan objekt. Förslagsvis används denna funktion inför varje ny övningsuppgift, såvida inte uppgiftern bygger på information från tidigare uppgifter. 3.6 Sammanfattning div.red{ background-color:#F5B7B1; border-radius: 5px; padding: 20px;} Du ska kunna känna till de viktigaste datatyperna som R arbetar med. känna till de tre olika typerna av dataobjekt. genomföra enklare datahantering, till exempel förändra ett specifikt elements värde i ett dataobjekt eller att med logiska operationer välja ut data från ett objekt. genomföra logiska operationer på vektorer och data frames. använda $ i data frames. tillämpa några vanliga funktioner i R samt även informera dig om vad en funktion gör genom att använda hjälp-filen. div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Bortfall komplicerar analyser och kodas på olika sätt. Det hanteras separat i kapitlet om bortfall. På denna kurs används baspaketen i R för datahantering. I R-universumet finns även en uppsättning paket som tillhör det så kallade tidyverse(). Här finns paket med en mängd funktioner som förenklar avancerad datahantering betydligt och som också följer en logik som många uppskattar. På denna kurs och för de flesta användare är dock baspaketen i R fullt tillräckligt. Kategorivariabler kallas faktorer och kommer att hanteras utförligt i kapitlet om faktorer. Att ha en förståelse för hur man hanterar faktorer är nödvändigt inom all dataanlys. I R används även typiska programmeringssatser innehållande for, if, else, while. Detta är emellertid inte något som vi kommer att arbeta med på denna kurs. 3.7 Övningar Övning 3.1 Du har ett stickprov betående av observationerna \\(4,-2,5,6,8\\). Beräkna medelvärdet. Beräkna standardavvikelsen. Beräkna variationsbredden. Beräkna det geometriska medelvärdet för de positiva värden \\(4, 5, 6, 8\\). Beräkna det geometriska medelvärdet för alla värden \\(4, -2, 5, 6, 8\\). Visa svar # Töm minnet inför denna Övning 3.1 rm(list = ls()) x &lt;- c(4,-2,5,6,8) mean(x) [1] 4.2 Svar: Medelvärdet är 4.2 Standardavvikelsen \\(s=\\sqrt{\\dfrac{\\sum_{i=1}^n (x_i -\\bar{x})^2}{n-1}}\\) beräknas med sd(x) [1] 3.768289 Svar: Standardavvikelsen är 3.768 Variationsbredden, dvs skillnaden mellan det största och det minsta värdet är max(x) - min(x) ## [1] 10 Svar: Variationsbredden är är 10. Det geometriska medelvärdet \\(\\bar{x}_g=(x_1\\cdot x_2 \\cdot \\cdots \\cdot x_n)^{1/n}\\) kan i R beräknas med # Välj enbart positiva värden xpos &lt;- x[x &gt; 0] # Du kan beräkna det geometriska medelvärdet med exp( mean(log(xpos)) ) ## [1] 5.566315 # Alternativt kan du funktionen geometric.mean() # i paketet psych. Aktivera paketet och beräkna. library(&quot;psych&quot;) geometric.mean(xpos) ## [1] 5.566315 Svar: Det geometriska medelvärdet är 3.95. Det geometriska medelvärdet \\[\\bar{x}_g=(x_1\\cdot x_2 \\cdot \\cdots \\cdot x_n)^{1/n}\\] kan i R beräknas med (4 * (-2) * 5 * 6 * 8)^(1/5) ## [1] NaN geometric.mean(x) ## Warning in log(x): NaNs produced ## [1] 5.566315 Svar: Eftersom en observation är negativ blir NaN, vilket betyder ‘’Not a Number’’. Det går alltså inte att beräkna. Övning 3.2 Ett slumpmässigt urval ger följande observationer \\(0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1\\),där \\(1=Arbetslös\\) och \\(0=Förvärvsarbetande\\). Beräkna andelen arbetslösa i stickprovet. Visa svar Andelen arbetslösa beräkna i R med # Töm minnet inför denna Övning 3.2 rm(list = ls()) x &lt;- c(0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1) mean(x) ## [1] 0.3846154 Svar: Andelen arbetslösa i stickprovet är 0.38. Övning 3.3 Kosumentpriset 2006-2011 är Table 3.1: Konsumentprisindex (KPI) 2006-2011 2006 284.2 2007 290.5 2008 300.6 2009 299.7 2010 303.5 2011 311.4 Med hur många procent har prisnivån förändrats från 2007 till 2010? Visa svar Beräkning i R ger # Töm minnet inför denna Övning 3.2 rm(list = ls()) year &lt;- c(2006, 2007, 2008, 2009, 2010, 2011) kpi &lt;- c(284.22, 290.51, 300.61, 299.66, 303.46, 311.423) percent_change &lt;- 100*(kpi[year == 2010]/kpi[year == 2007])-100 Svar: Prisnivån har ökat med 4.458%. Övning 3.4 Låt observationerna \\(4,-2,5,6,8\\) vara obundet slumpmässigt urval från en normalfördelad population. Genomför en hypotesprövning på 5% signifikansnivå för att testa medelvärdet i population är skild från 1. Visa svar Vi observerar \\(x=\\{4,-2,5,6,8\\}.\\) Hypoteser: \\(H_0:\\mu=1\\) vs \\(H_1:\\mu \\neq 1\\) Antaganden: Variabeln \\(x\\) är normalfördelad i populationen. Populationsvariansen \\(\\sigma^2\\) är okänd i populationen. Vi har ett litet stickprov, \\(n=5\\). Testfunktionen ges av \\(t=\\dfrac{\\bar{x}-\\mu}{\\sqrt{s^2/n}}\\). Denna teststatistika är \\(t\\)-fördelad med \\(n-1\\) frihetsgrader om nollhypotesen är sann. Beslutregel: \\(\\alpha=0.05\\). Tvåsidigt test, förkasta därför \\(H_0\\) om \\(|t_{obs}| &gt; t_{krit} = t_{4,\\alpha/2=0.025} = 2.776\\) # Töm minnet inför uppgift 3.4 rm(list = ls()) # Vi ska lösa uppgiften först illusterat med objekt i R # Sedan löser vi den med den inbyggda funktionen för t-test # Bestäm värden som ska in i testfunktionen x &lt;- c(4,-2,5,6,8) n &lt;- length(x) xbar &lt;- mean (x) s2 &lt;- var(x) mu &lt;- 1 # Beräkna testfunktionen tobs &lt;- (xbar - mu)/sqrt(s2/n) # Se var testfunktionensvärde hamnar i en t-fördelning med n-1 frihetsgrader # Funktionen pt() ger för ett givet t-värde vänstersvanssannolikheter i en t-fördelning med n-1 frihetsgrader # Eftersom vi vill ha sannolikheten i högra svansen måste vi därför ta 1-pt(). # Slutligen, eftersom mothypotesen är två-sidig multipliceras p-värdet med 2. p_value &lt;- 2*(1 - pt(tobs, (n-1))) p_value [1] 0.1304116 t.test(x, mu = 1) One Sample t-test data: x t = 1.8989, df = 4, p-value = 0.1304 alternative hypothesis: true mean is not equal to 1 95 percent confidence interval: -0.4789485 8.8789485 sample estimates: mean of x 4.2 t.test(x, mu = 1)$p.value [1] 0.1304116 Svar: Efterom \\(p=0.13\\) kan vi på 5% signifikansnivå inte påvisa att medelvärdet i populationen är skilt från 1. Notera att detta inte innebär att vi visar att medelvärdet är 1. Övning 3.5 Du observerar följande vektorer \\(x = \\{4,7,2,4,6,NA,89\\}\\) och \\(y=\\{7,3, 2, 5,6, 5 , 7\\}\\) och \\(z=\\{Alfa, bravo, Charlie, delta, Echo, Foxtrot, Golf\\}\\) Använd indexering för att summera element 2 och 3 i \\(x\\) med element 6 och 7 i \\(y\\). Använd indexering för att ändra NA i \\(x\\) till 999. Använd indexering för att korrigera så att bravo och delta inleds med versaler. Exkludera Echo och Foxtrot från \\(z\\). Visa svar # Töm minnet inför uppgift 3.5 rm(list = ls()) # a) x &lt;- c(4,7,2,4,6,NA,89) y &lt;- c(7,3,2,5,6,5,7) sumxy &lt;- x[c(2,3)] + y[c(6,7)] sumxy [1] 12 9 # b) x[6] &lt;- 999 x [1] 4 7 2 4 6 999 89 # c) z &lt;- c(&quot;Alfa&quot;, &quot;Bravo&quot;, &quot;Charlie&quot;, &quot;Delta&quot;, &quot;Echo&quot;, &quot;Foxtrot&quot;, &quot;Golf&quot;) z[2] &lt;- &quot;Bravo&quot; z[4] &lt;- &quot;Delta&quot; z [1] &quot;Alfa&quot; &quot;Bravo&quot; &quot;Charlie&quot; &quot;Delta&quot; &quot;Echo&quot; &quot;Foxtrot&quot; &quot;Golf&quot; # d) zsub &lt;- z[-c(5,6)] zsub [1] &quot;Alfa&quot; &quot;Bravo&quot; &quot;Charlie&quot; &quot;Delta&quot; &quot;Golf&quot; Övning 3.6 Du observerar följande datapunkter \\(x = \\{4,7,2,4,6\\}\\) och \\(y=\\{7,3, 2, 5,6\\}\\). Använd minsta-kvadratmetoden och beräkna koefficienterna \\(a\\) och \\(b\\) i regressionslinjen \\(y=a + bx\\). Använd koefficienterna och ge en prediktion för \\(y\\) givet att \\(x=7\\). Beräkna residualen för \\(x=7\\) Beräkna residualspridningen. Visa svar Riktningskoefficienten ges av \\[b=\\dfrac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\] och interceptet ges av \\[ a = \\bar{y} - b \\bar{x}\\]. Vi tillämpar formlerna i R. # Töm minnet inför uppgift 3.5 rm(list = ls()) x &lt;- c(4,7,2,4,6) y &lt;- c(7,3, 2, 5,6) xbar &lt;- mean(x) ybar &lt;- mean(y) b &lt;- sum( (x - xbar)*(y - ybar))/sum( (x - xbar)^2) b [1] 0.2105263 a &lt;- ybar - b*xbar a [1] 3.631579 # Det finns en inbyggd funktion i R för regressionsanalys, vilken används senare på kursen. Svar: Riktningskoefficienten beräknas till \\(b=0.2105\\), vilket tolkas som att om \\(x\\) ökar en enhet så ökar \\(y\\) i genomsnitt med \\(0.2105\\) enheter. Interceptet beräknas till \\(a=3.632\\), vilket tolkas som medelvärdet för \\(y\\) när \\(x=0\\). Notera att det i beräkningarna Använd koefficienterna från regressionslinjen och sätt in värdet \\(x=7\\). xp &lt;- 7 yhat &lt;- a + b*xp yhat [1] 5.105263 Svar: Prediktionen \\(\\hat{y}=\\) 5.105. Detta är punkten på regressionslinjen när \\(x=7\\) och vår bästa gissning för det \\(y\\)-värde en individ med värdet \\(x=7\\) kommer att ha. En residual är skillnaden mellan ett predicerat värde och det faktiska observerade värdet, \\(\\hat{\\varepsilon}=y_i - \\hat{y}\\). Eftersom \\(y=3\\) när \\(x=7\\) så residualen residual &lt;- y[x == xp] - yhat Svar: Residualen för \\(x=7\\) är -2.105. Residualspridningen ges av \\[s_\\varepsilon=\\sqrt{\\dfrac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{n-2}}= \\sqrt{\\dfrac{\\sum_{i=1}^n\\hat{\\varepsilon}_i^2}{n-2}}\\]. Vi beräknar på samma sätt som i c) övriga residualer, kvadrerar och summerar. residuals &lt;- y - (3.6316 + 0.2105*x) n &lt;- length(residuals) residual_spridning &lt;- sqrt( sum(residuals^2)/(n-2) ) residual_spridning [1] 2.347077 Svar: Residualspridningen är 2.347 (Notera att \\(\\sum_{i=1}^n \\varepsilon_i^2\\) kallas för residualkvadratsumman.) Övning 3.7 Du observerar följande data frame income &lt;- c(4,7,2,3,6,7,8,6) education &lt;- c(&quot;Low&quot;, &quot;Medium&quot;, &quot;Low&quot;, &quot;High&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;) df &lt;- data.frame(income, education) Skapa en ny variabel som heter high_edu som tar värdet 1 om education är “High” och 0 annars. Visa svar # Töm minnet inför uppgift 3.6 rm(list = ls()) income &lt;- c(4,7,2,3,6,7,8,6) education &lt;- c(&quot;Low&quot;, &quot;Medium&quot;, &quot;Low&quot;, &quot;High&quot;, &quot;High&quot;, &quot;Low&quot;, &quot;Medium&quot;, &quot;High&quot;) df &lt;- data.frame(income, education) df$high_edu &lt;- NA df$high_edu[df$education == &quot;High&quot;] &lt;- 1 df$high_edu[df$education == &quot;Low&quot;] &lt;- 0 df$high_edu[df$education == &quot;Medium&quot;] &lt;- 0 df income education high_edu 1 4 Low 0 2 7 Medium 0 3 2 Low 0 4 3 High 1 5 6 High 1 6 7 Low 0 7 8 Medium 0 8 6 High 1 Övning 3.8 Ett oljebolag är intresserat av att för ett äldre bostadsområde med \\(2\\,000\\) hus skatta andelen hus utan oljeeldning. Sakkunskapen säger att det sanna antalet hus utan oljeeldning är mellan 300 och 800 stycken. Precisionskravet är formulerat så att ett 95% konfidensintervall för andelen hus utan oljeeldning inte får bli längre än 0.05 procentenheter. Beräkna urvalsstorleken vid OSU om dragningen sker med återläggning. Visa svar Mål: Beräkna den nödvändiga stickprovsstorleken \\(n\\) om längden för ett 95% konfidensintervall för andelen i populationen får vara maximalt 0.05. Parameter: \\(p\\) = andelen hus utan oljeeldning i populationen. Estimator: \\(\\hat{p}\\) = andelen hus utan oljeeldning i stickprovet. Förutsättningar: OSU-MÅ ger att \\(E(\\hat{p})=p\\). Detta säger oss att andelen i stickprovprovet kan skatta andelen i populationen väntevärdesriktigt. \\(V(\\hat{p})=\\frac{p(1-p)}{n}\\). Detta är variansen i andelsestimatorns samplingfördelning. Vi antar att \\(p=\\dfrac{800}{2000}=0.4\\) eftersom detta ger störst varians givet den information vi har. Vi utgår från att \\(np(1-p)&gt;5\\) kommer att vara uppfyllt. Vi måste sedan kontrollera att antagandet faktiskt är uppfyllt! Annars gäller inte CGS och approximativ normalfördelning. Precisionskravet i termer av konfidensintervallets längd kan nu formuleras \\[ 0.05\\geq 2\\cdot 1.96\\sqrt{\\frac{0.4(1-0.4)}{n}}. \\] Det går att ändra värdena på \\(n\\) i R för att se vilket \\(n\\) som ger vår önskade minsta stickprovsstorlek. Vi vill att uttrycket nedan ska vara lika med eller mindre än 0.05. # Töm minnet inför uppgift 3.7 rm(list = ls()) n &lt;- seq(10, 10000, 1) p &lt;- 0.4 # Z-värdet från fördelning N(0,1) med sannolikheten 0.025 i högre svansen. z &lt;- qnorm(0.975) # Längden för ett konfidensintervall ges av följande formel: KIlength &lt;- 2 * z * sqrt( ( p*(1-p) ) / n ) # Illustration över olika KIlength för olika värden stickprovsstorlekar n plot(n, KIlength, type = &quot;l&quot;) # Välj den minsta stickprovsstorleken som uppfyller precisionskravet KIlength &lt; 0.05 min( n[KIlength &lt; 0.05] ) [1] 1476 Svar: För att uppnå precisionskravet behövs ett stickprov med minst 1476 hus. Glöm inte att kontrollera CGS: \\(np(1-p)=1476\\cdot 0.4(1-0.4)=354.24 &gt; 5\\) så antagandet är uppfyllt. Det går även att lösa denna uppgift algebraiskt, genom att lösa ut $n i formeln ovan. Övning 3.9 En rikstäckande butikskedja säljer bland annat kompletta datorpaket. För ett visst paket tillåter man butikscheferna att själva sätta priset. För att centralt i företaget få en uppfattning om hur efterfrågan påverkas av priset gör man ett slumpmässigt urval om åtta butiker och inhämtar uppgifter om pris och försäljning under den närmast föregående månaden: pris &lt;- c(5500, 6000, 6500, 6000, 5000, 6500, 4500, 5000) antal &lt;- c(41, 38, 35, 40, 44, 38, 45, 42) Beräkna korrelationskoefficienten. Visa svar Korrelationskoefficentens ges av \\[r=\\dfrac{\\sum_{i=1}^n(x_i - \\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\bar{x})^2 \\sum_{i=1}^n(y_i - \\bar{y})^2}}.\\] Vi kan enkelt tillämpa formeln. # Töm minnet inför uppgift 3.8 rm(list = ls()) x &lt;- c(5500, 6000, 6500, 6000, 5000, 6500, 4500, 5000) y &lt;- c(41, 38, 35, 40, 44, 38, 45, 42) xbar &lt;- mean(x) ybar &lt;- mean(y) r &lt;- sum( (x - xbar)*(y - ybar) ) /sqrt( sum( (x - xbar)^2)*sum( (y - ybar)^2) ) r [1] -0.9426412 Svar: Pearsons produktmomentkorrelationskoefficient är \\(-0.94\\), vilket tyder på ett mkt starkt negativt samband mellan pris och antal. Övning 3.10 Betrakta nedanstående vektor: some_letters &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;D&quot;, &quot;A&quot;) Använd R för att räkna hur många B det finns i vektorn. Visa svar # Töm minnet inför uppgift 3.8 rm(list = ls()) some_letters &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;D&quot;, &quot;A&quot;) length( some_letters[some_letters == &quot;B&quot;] ) [1] 2 Övning 3.11 Betrakta nedanstående vektorer: some_numbers &lt;- c(&quot;1&quot;, &quot;3&quot;, &quot;1&quot;, &quot;3&quot;, &quot;3&quot;) some_numbers_and_letters &lt;- c(&quot;2&quot;, &quot;4&quot;, &quot;-1&quot;, &quot;3&quot;, &quot;3&quot;, &quot;A&quot;, &quot;D&quot;) Använd R för att summera alla värdena i respektive vektor. Tips: Använd funktionen as.numeric(). Visa svar # Töm minnet inför uppgift 3.10 rm(list = ls()) some_numbers &lt;- c(&quot;1&quot;, &quot;3&quot;, &quot;1&quot;, &quot;3&quot;, &quot;3&quot;) some_numerics &lt;- as.numeric( some_numbers ) class(some_numbers) [1] &quot;character&quot; class(some_numerics) [1] &quot;numeric&quot; sum(some_numerics) [1] 11 some_numbers_and_letters &lt;- c(&quot;2&quot;, &quot;5&quot;, &quot;-1&quot;, &quot;3&quot;, &quot;3&quot;, &quot;A&quot;, &quot;D&quot;) some_numerics_2 &lt;- as.numeric(some_numbers_and_letters) Warning: NAs introduced by coercion sum(some_numerics_2, na.rm = TRUE) [1] 12 Övning 3.12 Betrakta nedanstående vektorer. x1 &lt;- c(0.39, 0.76, -1.25, 0.28, 0.60, 0.66, 0.94, -0.18, -0.26, -1.83, -1.13, 0.45, 0.11, -1.03, 1.06, -0.08, 1.68, -1.02, 1.36, 1.58) x2 &lt;- c(-1.0, 1.5, 0.2, -0.5, -1.1, -0.2, -1.0, -1.3, -1.6, -1.2, -0.4, -1.3, -0.3, -0.7, 0.7, -2.5, -1.0, 2.1, 1.3, -1.3) x3 &lt;- c(5.94, -2.38, -0.16, 0.44, 0.70, 2.54, 2.12, 8.33, 0.57, 1.24, 0.05, -1.78, 2.53, -1.60, 2.77, 0.26, 1.48, 1.10, -8.00, 4.57) Skapa variabeln \\(x = x_1 + x_2 + x_3\\). Skapa variabeln \\(z\\), där \\(z=1\\) om \\(x &lt; 0\\), \\(z=2\\) om \\(0 \\leq x &lt; 5\\) och \\(z=3\\) om \\(x \\geq 5\\). Skapa de binära variblerna \\(v_1\\) som är 1 om \\(x1 &gt; 0\\) och 0 annars, \\(v_2\\) som är 1 om \\(x2 &gt; 0\\) och 0 annars, och \\(v_3\\) som är 1 om \\(x3 &gt; 0\\) och 0 annars Skapa variabeln \\(v = v_1 + v_2 + v_3\\) som är en summa av de binära variablerna. Skapa en frekvenstabell för \\(v\\). Visa svar # Töm minnet inför uppgift 3.10 rm(list = ls()) x1 &lt;- c(0.39, 0.76, -1.25, 0.28, 0.60, 0.66, 0.94, -0.18, -0.26, -1.83, -1.13, 0.45, 0.11, -1.03, 1.06, -0.08, 1.68, -1.02, 1.36, 1.58) x2 &lt;- c(-1.0, 1.5, 0.2, -0.5, -1.1, -0.2, -1.0, -1.3, -1.6, -1.2, -0.4, -1.3, -0.3, -0.7, 0.7, -2.5, -1.0, 2.1, 1.3, -1.3) x3 &lt;- c(5.94, -2.38, -0.16, 0.44, 0.70, 2.54, 2.12, 8.33, 0.57, 1.24, 0.05, -1.78, 2.53, -1.60, 2.77, 0.26, 1.48, 1.10, -8.00, 4.57) # a) x &lt;- x1 + x2 + x3 # b) # Skapa en variabeln som består av NA som är lika lång som x z &lt;- rep(NA, length(x)) z[x &lt; 0] &lt;- 1 z[(x &gt;= 0) &amp; (x &lt; 10) ] &lt;- 2 z[x &gt; 10] &lt;- 3 z [1] 2 1 1 2 2 2 2 2 1 1 1 1 2 1 2 1 2 2 1 2 # c) v1 &lt;- rep(NA, length(x1)) v1[x1 &gt; 0] &lt;- 1 v1[x1 &lt;= 0] &lt;- 0 v2 &lt;- rep(NA, length(x1)) v2[x2 &gt; 0] &lt;- 1 v2[x2 &lt;= 0] &lt;- 0 v3 &lt;- rep(NA, length(x1)) v3[x3 &gt; 0] &lt;- 1 v3[x3 &lt;= 0] &lt;- 0 # d) v &lt;- v1 + v2 + v3 v [1] 2 2 1 2 2 2 2 1 1 1 1 1 2 0 3 1 2 2 2 2 # e) sumv0 &lt;- sum(v == 0) sumv1 &lt;- sum(v == 1) sumv2 &lt;- sum(v == 2) sumv3 &lt;- sum(v == 3) frequencies &lt;- c(sumv0, sumv1, sumv2, sumv3) values &lt;- c(0, 1, 2, 3) frequency.table &lt;- cbind(values, frequencies) frequency.table values frequencies [1,] 0 1 [2,] 1 7 [3,] 2 11 [4,] 3 1 # Det finns i R också en inbyggd funktion table(), som vi ska använda oss av senare på kursen. Övning 3.13 Denna övning syftar till att förtydliga skillnaden mellan ett par summor som används ofta i statistiken, dessa är \\(\\sum_{i = 1}^{n}x_{i}^{2}\\) och \\(\\left(\\sum_{i = 1}^{n} x_{i}\\right)^{2}\\). Företäll dig att du har dragit ett stickprov av något slag, och att du samlat informationen i ditt stickprov i vektorn x &lt;- c(2, 4, 5, 3, 8, 4) Föreställ dig även att du vill beräkna standardavvikelsen i vektorn, men att du inte känner till funktionen sd(). Därför behöver du beräkna de båda summorna som presenteras ovan. Din uppgift är nu att Beräkna de båda summorna manuellt i R, utan att använda funktionen sum() Visa svar Börja med att rensa minnet och mata in vektorn i R rm(list = ls()) # Rensar minnet x &lt;- c(2, 4, 5, 3, 8, 4) # Matar in vektor I beräkningen av \\(\\sum_{i = 1}^{n}x_{i}^{2}\\) är det viktigt att komma ihåg att kvadreringen sker först, och summeringen sedan. Summan räknas alltså ut som # Kvadrera elementen först, summera sen x[1]^(2) + x[2]^(2) + x[3]^(2) + x[4]^(2) + x[5]^(2) + x[6]^(2) ## [1] 134 I beräkningen av \\(\\left(\\sum_{i = 1}^{n} x_{i}\\right)^{2}\\) sitter summan inom parenteser, och därför sker summering här innan kvadrering. Summan beräknas som # Summera elementen först, kvadrera sen (x[1] + x[2] + x[3] + x[4] + x[5] + x[6])^(2) ## [1] 676 Förenkla nu beräkningarna i a genom att använda sum() och räkna på vektorerna i sin helhet Visa svar Kom ihåg att \\(\\sum_{i = 1}^{n}x_{i}^{2}\\) kräver kvadrering innan summering. Börja därför med att kvadrera alla element i x. Resultatet blir x^(2) # Ser att elementen kvadreras var för sig ## [1] 4 16 25 9 64 16 För att slutföra beräkningen av den första summan återstår bara att stoppa in ovanstående uttryck i summeringsfunktionen sum(x^(2)) # Summerar över kvadrerade x ## [1] 134 Som synes blir resultatet samma som i a, men koden är mer kompakt och lättare att skriva För att beräkna den andra summan summeras värdena först, och sedan kvadreras hela summan. Detta innebär att kvadraten i detta fall måste sättas utanför summeringsfunktionen, precis som i koden här nedan x # Skriver ut x ## [1] 2 4 5 3 8 4 sum(x) # Summerar över alla x ## [1] 26 (sum(x))^(2) # Summerar alla x och kvadrerar summan ## [1] 676 Beräkningen ger samma resultat som i a, men koden är återigen mer kompakt och lättare att skriva Övning 3.14 Denna uppgift rör beräkningen av en stickprovsvarians, och syftar till att tydliggöra att likheten \\[ \\frac{\\sum_{i = 1}^{n}(x_{i} - \\bar{x})^{2}}{n-1} = \\frac{\\sum_{i = 1}^{n}x_{i}^{2} - \\frac{\\left(\\sum_{i = 1}^{n} x_{i}\\right)^{2}}{n}}{n-1} \\] faktiskt håller. Uttrycket till vänster kan, genom några delsteg, skrivas om och bli uttrycket som står till höger om likhetstecknet. Din uppgift är nu att beräkna värdet på varje del i utvecklingen, och på så sätt se att uttrycken är lika. Betrakta samma stickprov som i uppgift 3.13 x &lt;- c(2, 4, 5, 3, 8, 4) och utför följande beräkningar: Beräkna stickprovsmedelvärdet för x, och även antal element som finns i vektorn Visa svar Börja med att rensa minnet och mata in vektorn i R rm(list = ls()) # Rensar minnet x &lt;- c(2, 4, 5, 3, 8, 4) # Matar in vektor Medelvärdet beräknas nu som x_streck &lt;- mean(x) x_streck ## [1] 4.333333 och antalet element som n &lt;- length(x) n ## [1] 6 Beräkna värdet på \\(\\frac{1}{n - 1} \\sum_{i = 1}^{n} (x_{i} - \\bar{x})^{2}\\) Visa svar Använd \\(n\\) och \\(\\bar{x}\\) från a, och kom ihåg att kvadrering sker innan summan beräknas (1/(n-1)) * sum((x - x_streck)^(2)) ## [1] 4.266667 Beräkna värdet på \\(\\frac{1}{n - 1} \\sum_{i = 1}^{n} (x_{i} - \\bar{x})(x_{i} - \\bar{x})\\) Visa svar Ta bort kvadraten och multiplicera \\((x_{i} - \\bar{x})\\) med sig självt (1/(n-1)) * sum((x - x_streck) * (x - x_streck)) ## [1] 4.266667 Beräkna värdet på \\(\\frac{1}{n-1}\\sum_{i = 1}^{n} \\left(x_{i}^{2} - 2x_{i} \\bar{x} + \\bar{x}^{2} \\right)\\) Visa svar Multiplicera ut parenteserna innanför summan (1/(n-1)) * sum(x^(2) - 2*x*x_streck + x_streck^(2)) ## [1] 4.266667 Beräkna värdet på \\(\\frac{1}{n-1}\\left(\\left(\\sum_{i = 1}^{n} x_{i}^{2}\\right) - 2n\\bar{x} \\cdot \\bar{x} + n\\bar{x}^{2} \\right)\\) Visa svar Notera att summan enbart opererar på \\(x_{i}^{2}\\) (1/(n-1)) * (sum(x^(2)) - 2*n*x_streck*x_streck + n*x_streck^(2)) ## [1] 4.266667 Beräkna värdet på \\(\\frac{1}{n-1}\\left(\\left(\\sum_{i = 1}^{n} x_{i}^{2}\\right) - 2n\\bar{x}^{2} + n\\bar{x}^{2} \\right)\\) Visa svar Notera att summan enbart opererar på \\(x_{i}^{2}\\) (1/(n-1)) * (sum(x^(2)) - 2*n*x_streck^(2) + n*x_streck^(2)) ## [1] 4.266667 Beräkna värdet på \\(\\frac{1}{n-1}\\left(\\left(\\sum_{i = 1}^{n} x_{i}^{2}\\right) - n\\bar{x}^{2} \\right)\\) Visa svar Notera att summan enbart opererar på \\(x_{i}^{2}\\) (1/(n-1)) * (sum(x^(2)) - n*x_streck^(2)) ## [1] 4.266667 Beräkna värdet på \\(\\frac{\\sum_{i = 1}^{n} x_{i}^{2} - \\frac{\\left(\\sum_{i = 1}^{n} x_{i} \\right)^{2}}{n} }{n-1}\\) Visa svar Notera att summan enbart opererar på \\(x_{i}^{2}\\) (sum(x^(2)) - (sum(x)^(2))/n)/(n - 1) ## [1] 4.266667 Kontrollera att beräkningarna stämmer genom att jämföra med funktionen var() Visa svar Notera att summan enbart summerar över \\(x_{i}^{2}\\) var(x) ## [1] 4.266667 p.comment { background-color: #DBDBDB; padding: 10px; border: 1px solid black; margin-left: 25px; border-radius: 5px; font-style: italic; } "],
["läsa-in-och-spara-data.html", "Kapitel 4 Läsa in och spara data 4.1 Principer för organiserade datamaterial 4.2 Working directory 4.3 Läsa in datamaterial med hjälp av kod 4.4 Läsa in datamaterial med hjälp av menyerna i RStudio 4.5 Spara datamaterial med hjälp av R 4.6 Övningar", " Kapitel 4 Läsa in och spara data Avsikten med detta kapitel är att beskriva principerna för hur datamaterial är organiserade, hur datamaterial bör organiseras samt presentera de vanligaste formaten för att att importera och exportera data i R. För nybörjaren i R kan det vara uppmuntrande att känna till att datainläsning i en del fall kan vara omständligt och frustrerande, framförallt om datamaterialet inte är organiserat på ett konsekvent sätt. Misströsta därför inte ifall det dyker upp svårigheter. Det krävs mycket erfarenhet för att blir trygg med att arbeta med data. På denna kurs rekommenderas två format för att importera och spara datamaterial: textfiler (.txt eller .csv), vilket innebär att data sparas i textformat. R Data format (.RDS), vilket är det dataformat som R använder. I praktiken är det däremot nödvändigt att kunna importera och spara filer i Excel-format (.xlsx eller motsvarande), detta på grund av att många icke-statistiker använder Excel för att handskas med och analysera data. Vad gäller import och export av dataformat som är kopplade till andra statistikprogram (så som SAS, SPSS, Minitab) finns R-paket (t.ex. foreign och haven) avsedda för detta. När det gäller hantering av stora dataset (\\(&gt;10\\) Gigabyte i storlek) kan paket som data.table vara till hjälp. 4.1 Principer för organiserade datamaterial För att göra det så lätt som möjligt att importera och handskas med data i R är det en bra idé att följa principen om tidy data. Tidy kan i denna mening översättas som städat eller organiserat, och innebär att datamaterialet är strukturerat på ett specifikt sätt som gör det lätt att hantera. Hadley Wickham, som är chefsforskare på RStudio och adjungerad professor i statistik vid bland annat Standforduniversitetet i USA, har tagit fram tre regler som bör följas för att få ett städat datamaterial. Dessa är att Varje variabel måste ha en egen kolumn Varje observation måste ha sin egen rad Varje värde måste ha sin egen cell. På grund av det sätt som R – och i stort sett alla andra statistikprogram – arbetar med data blir risken för felberäkningar eller förvirringar mindre när ett datamaterial är strukturerat efter de tre punkterna som ges ovan. Som synes är data organiserat så att varje kolumn hör till en enskild variabel, varje rad hör till en enskild individ (observation), och varje cell hör till ett enskilt värde. För göra detta mer konkret kan det vara värt att betrakta en situation där du som analytiker blir ombedd att analysera ett datamaterial som har med Stockholms bostadsmarknad att göra. I detta datamaterial finns observationer som rör 1500 olika lägenheter i Stockholms innerstad, och informationen som delges är boarea, antal rum, avstånd till närmsta tunnelbana, avstånd till vattnet, och månadsavgift. Enligt principerna för städade datamaterial bör information för en specifik lägenhet finnas på en enskild rad. Varje rad bör även korsas av fem olika kolumner, som var och en innehåller information gällande en specifik variabel. På så sätt kommer varje cell i datamaterialet innehålla ett enskilt värde, och det kommer utan problem gå att utgöra vilken lägenhet samt vilken variabel varje cell hör till. För att ytterligare klargöra skillnaden mellan datamaterial som är städade och datamaterial som inte är städade följer ett par tabeller här nedan. Studera gärna dessa en stund, och fundera kring varför varje tabell innehåller ett städat/ostädat datamaterial. Boarea Rum, T-bana Vatten Avgift 52 2, 400 1500 3300 24 1, 150 2500 3967 Datamaterialet som presenteras i tabellen ovan är inte tidy, detta eftersom variablerna Rum och T-bana står skrivna i samma kolum, vilket medför att varje cell inte innehåller ett enskilt värde. För att datamaterialet ovan ska räknas som städat krävs att det ser ut som i tabellen här nedan. Boarea Rum T-bana Vatten Avgift 52 2 400 1500 3300 24 1 150 2500 3967 I tabellen ovan finns en klar struktur som följer det som förväntas av ett städat datamaterial. Utöver dessa tre grundläggande strukturer finns en del rekommendationer för att underlätta programmeringen, göra den mer intuitiv, och ge den ett bättre flyt. Dessa ges i följande punktlista: Många program (t ex Excel) gör det möjligt att spara data som ren text istället för i progammets eget format. Spara alltid en kopia i textformat. Använd semi-kolon för att avgränsa kolumner när datamaterial sparas i textformat. Eftersom kommatecken används som decimaltecken på svenska, och avstånd eller TAB är svåra att se i en textfil då de påminner om blanksteg, undviks ofta enkla problem genom att använda semikolon. Försök att inte ändra något i ursprungsfilen där datamaterialet är sparat. Det är bättre att importera data till R och göra ändringar där om så är möjligt. Undvik att använda variabelnamn som innehåller blanksteg. Blanksteg har en specifik funktion i R, och om de används i variabelnamn blir dator lätt förvirrad, vilket leder till att beräkningarna inte fungerar som de ska. Istället rekommenderas att använda understreck eller punkt som avskiljare. Alltså bör en variabel döpas till antal_rum eller antal.rum snarare än bara antal rum. Låt bli att använda variabelnamn som innehåller specielle symboler, som t.ex. ?, $, *, +, #, (, ), -, /, }, {, |, &gt;, &lt; etc. Även sådana symboler kan ha specielle funktioner i R, och om de inkluderas i variabelnamn finns risk att R inte kan hantera dem. Gör det till en vana att bara använda understreck eller punkt. Inled aldrig ett variabelnamn med en siffra. Siffror är tillåtna i variabelnamn, men inte som första tecken. Namnen på kolumnerna i ett datamaterial måste alltid vara unike. Det får alltså inte finnas två kolumner med samma namn i ett och samma datamaterial. R är ett skiftlägeskänsligt språk, vilket innebär att det gör skillnad mellan versaler och gemener. Detta medför att variabler vid namn Husdjur och husdjur sparas som två olika objekt, eftersom ett versalt H i det första namnet skiljer variablerna åt. Om ett datamaterial innehåller tomma rader bör dessa raderas innan någon analys påbörjas. Tomma rader kan lätt betraktas som missing values av R, och kan därför komma att snedvrida analysen som ska utföras. Ersätt alla tomma celler med NA. NA står för not available i R, och celler som är kodade som NA är i regel relativt enkla att utesluta ur en analys. Radera alla kommentarer som finns i det ursprungliga datamaterialet. Ofta förekommer kommentarer antingen längst upp i själva datafilen, eller någonstans vid sidan av det data som är av intresse. För att dessa kommentarer inte ska störa analysen är det viktigt att radera dem. Även om datamaterialen i denna kursen i stort sett alltid kommer vara textfiler eller formaterade som R-data är det högst sannolikt att många av er kommer behöva samla in och strukturera egna datamaterial i arbetslivet. Om (eller när) detta händer finns en artikel, skriven av Karl Broman och Kara Woo, som ger en bra sammanfattning av vad som bör tas i åtankte i sådana situationer. Nog om städade datamaterial. Resten av detta kapitel kommer handla om hur olika typer av datamaterial bör läsas in, för att sedan kunna använda dem i diverse statistiska analyser. 4.2 Working directory För att underlätta datainläsning är det bra att anrätta ett så kallat working directory som R kan utgå ifrån. Även om namnet working directory får det att låta komplicerat är det i grund och botten ett väldigt simpelt koncept. Ett working directory är helt enkelt en mapp i datorn som R använder som “hem-mapp”. Fördelen med ett working directory är att R alltid utgår ifrån det, vilket medför att datamaterial som finns i mappen blir lättare att läsa in. Det är även så att script och figurer som produceras i R automatiskt sparas i denna mapp, vilket gör det lättare att hålla ordning på allt arbete som görs i R. Det finns två sätt att bestämma vilken fil som ska räknas som ett workning directory. Den ena går ut på att skriva kod som anger sökvägen till mappen som är menad att vara directory, och den andra går ut på att använda menyer i R för att klicka sig fram till ett directory. De båda sätten är likvärdiga, och det är bra för varje enskild person att använda det sätt som verkar mest intuitivt. Faktum är att menyerna används för att generera kod som körs i Console, så i grund och botten är det samma operation som utförs. För att anrätta ett working directory är det första som behövs en mapp att använda. Skapa därför en mapp på skrivbordet som heter “Statistik A5”. Detta krävs oavsett vilken metod som används för att göra mappen till ett directory. För att bestämma working directory med hjälp av kod används funktionen setwd(), och för att göra mappen Statistik A5 till directory skrivs sökvägen in mellan parenteserna i funktionen. Koden som används blir alltså följande setwd(&quot;/Users/valentinzulj/Desktop/Statistik A5&quot;) Notera att sökvägen är unik för alla datorer. I just detta fall används min personliga dator, och sökvägen kommer inte att fungera på andra datorer än just min. Det är inte alltid självklart hur sökvägen till en mapp ser ut, men som tur är finns ett par knep för att lätta komma åt sökvägen. För Mac-användare är det lättast att leta upp mappen som ska bli directory, högerklicka på den (för att få fram en lista med olika alternativ), och hålla in alt-knappen på tangentbordet. När detta är gjort ändras ett alternativ till Copy “namn på filen” as Pathname, och genom att klicka på detta alternativ kopieras sökvägen så att den går att klistra in direkt i setwd(), exempelvis med hjälp av CTRL + C. För Windows-användare är processen snarlik, det gäller då att hålla ner Shift-tangenten och högerklicka på mappen som ska användas, för att sedan använda alternativet Copy as Path (Kopiera sökväg). Efter det kan sökvägen klistras in i setwd() precis som ovan. För att bestämma directory med hjälp av menyer gäller det att klicka på Session längst upp i RStudio. Sedan är det bara att gå till Set Working Directory och Choose Directory för att bläddra efter en mapp i datorn. Notera att en rad kod skrivs ut i Console när mappen som ska bli directory har valts, denna kod kan vara bra att kopiera och klistra in i det script som används för att göra analysen. Detta eftersom R återställer directory varje gång det stängs ner, och därför måste mappen anges varje gång R startas. Om datamaterialet som ska läsas in finns i den mapp som är satt som directory behöver enbart filnamnet användas för att läsa in den, men om materialet inte finns i mappen behövs hela sökvägen. Därför kan det vara bra att ha det datamaterial som ska analyseras i en mapp som är (eller görs till) working directory. Använd nu panelen som finns längst ner till höger i R (precis till höger om Console). Börja med att klicka på fliken Files, och klicka sedan på kugghjulet som har texten More bredvid sig. Välj nu alternativet Go To Working Directory i listan. När detta är gjort dyker allt innehåll i mappen som är satt som working directory upp i panelen längst ner till höger. Med hjälp av dessa filer kan datamaterial läsas in på ett smidigt sätt. Detta kommer att diskuteras vid ett senare skede i denna text. 4.3 Läsa in datamaterial med hjälp av kod I R finns två huvudsakliga sätt att importera datamaterial, båda med sina egna för och nackdelar. Ett sätt är att skriva kod som får R att importera datamaterialet, och det andra är att använda menyerna som finns i RStudio för att generera kod och läsa in datamaterialet genom att bara klicka (ungefär som i Minitab eller SPSS). I denna del av kapitlet kommer dataimport med hjälp av programmering att diskuteras. Fördelen med att importera datamaterial med hjälp av kod är att koden kan sparas i ett script, och därmed blir det lätt att sprida ut analysarbetet över flera tillfällen utan att behöva ödsla onödig tid på dataimport i början av varje tillfälle. Det medföljer alltså ingen klickföljd att memorera – som är fallet då menyer används – och det är relativt smidigt. Nackdelen är att det finns väldigt många olika sätt att formatera datamaterial, vilket medför att det krävs många olika funktioner och argument att lära sig och hålla reda på. Detta problem är inte lika framträdande när menyer används för att importera data. Som nämnts ovan kommer tre olika dataformat att diskuteras i detta kapitel. De två huvudsakliga är text-och CSV-filer och datafiler som är lagrade i R:s eget format RDS. Dessutom tillkommer datamaterial som är lagrade i Excelark. 4.3.1 Text- och CSV-filer Ett par format som ofta används för att lagra datamaterial är text- och CSV-filer. Textfiler har oftast .txt efter filnamnet, och CSV-filer har ändelsen .csv. CSV står för comma separated values, vilket betyder att kommatecken används för att skilja mellan kolumner på samma rad. Eftersom det finns många länder som använder kommatecken för att skriva ut decimaltal innefattar ordet comma i fallet CSV även semikolon. Strukturen i denna typen av filer är relativt enkel, och ett par exempel kommer att redovisas längre ner. De två funktionerna som används för att läsa in CSV-filer är read.csv() och read.csv2(). Båda dessa är varianter av funktionen read.table(), fast med argument som är förspecificerade för att passa specifika typer av datastruktur. I grund och botten går det alltid att använda read.table() så länge argumenten specificeras korrekt, men det går ofta att spara lite tid genom att istället anropa read.csv() eller read.csv2() direkt. CSV.filer är textfiler och mer generellt kan text-filer läsas in med read.table(). De bägge read.csv() och read.csv2() baseras nämligen på read.table(), men med förspecificerade argument. Funktionernas vanligaste argument presenteras nedan, men det går att specificera funktionerna i stor detalj beroende på hur datafilen ser ut. De fem huvudsakliga argument som används är file anger filnamnet på filen (datamaterialet) som ska läsas in header specificerar om namnet på varje variabel finns på första raden i datamaterialet sep anger vilken typ av tecken som används för att skilja kolumner åt quote anger vilken typ av tecken som används som citationstecken för textvariabler dec anger vilket teckan som används som decimaltecken. Standardinställningarna för de tre funktionernas vanligaste argument anges nedan. read.csv(file, header = TRUE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;) read.csv2(file, header = TRUE, sep = &quot;;&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;,&quot;) read.table(file, header = TRUE, sep= &quot; &quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;) Som syns i kodsnutten är det standard för alla tre funktionerna att läsa in första raden i ett datamaterial som variabelnamn, och de använder alla samma typ av citationstecken. Det som skiljer dem åt är vilka tecken so används för att åtskilja kolumner samt för att skriva ut decimaltal. Funktionen read.csv() använder kommatecken för att skilja mellan kolumner, och punkt för att dela upp decimaltal, samtidigt som read.csv2() använder semikolon för att skilja mellan kolumner och kommatecken för att dela upp decimaltal. read.table(), däremot, använder ett blanksteg för att skilja mellan kolumner, och en punkt för att dela upp decimaltal. För att lära sig läsa in text- och CSV-filer är det bra att gå igenom punktlistan för varje datamaterial som ska läsas in, och på så sätt ta reda på hur argumenten är specificerade i det specifika datamaterialet. Här nedan finns ett utdrag ur textfilen animals1.csv. Titta gärna närmare på datamaterialet och försök identifiera hur vart och ett av argumenten i punktlistan ovan är specificerade. Försök sedan komma fram till vilken av de tre inläsningsfunktionerna som lämpar sig bäst för att läsa in datamaterialet. Svaret finns att läsa under kodsnutten. &quot;&quot;,&quot;animal&quot;,&quot;body&quot;,&quot;brain&quot; &quot;1&quot;,&quot;Lesser short-tailed shrew&quot;,0.005,0.14 &quot;2&quot;,&quot;Little brown bat&quot;,0.01,0.25 &quot;3&quot;,&quot;Big brown bat&quot;,0.023,0.3 &quot;4&quot;,&quot;Mouse&quot;,0.023,0.4 &quot;5&quot;,&quot;Musk shrew&quot;,0.048,0.33 &quot;6&quot;,&quot;Star-nosed mole&quot;,0.06,1 &quot;7&quot;,&quot;E. American mole&quot;,0.075,1.2 &quot;8&quot;,&quot;Ground squirrel&quot;,0.101,4 &quot;9&quot;,&quot;Tree shrew&quot;,0.104,2.5 &quot;10&quot;,&quot;Golden hamster&quot;,0.12,1 I animals.csv är argumenten specificerade som header = TRUE eftersom variabelnamnen anges i den första raden sep = &quot;,&quot; eftersom ett kommatecken används för att skilja cellerna i varje rad åt quote = &quot;\\&quot;&quot; eftersom helt vanliga citationstecken används för textvariabler dec = &quot;.&quot; eftersom en vanlig punkt används som decimaltecken Dessa argument kan stämmas av med kodsnutten där standardargument anges, och då framkommer att funktionen read.csv() bör användas för att läsa in datamaterialet. Skriv därför in df1 &lt;- read.csv(file=&quot;D:/animals1.csv&quot;) för att läsa in datamaterialet i R (notera att det räcker att bara skriva file = &quot;animals1.csv&quot; om filen finns i den mapp som är working directory). Eftersom animals.csv är en textfil kan filen öppnas i Notepad eller Textredigerare (eller mosvarande), och på så sätt kan alla text- och CSV-filer öppnas för att inspektera hur de är organiserade. Märk väl att de tecken som används för att skilja mellan celler, hantera textvariabler, och dela upp decimaltal alla är angivna inom citationstecken – t.ex. står det alltså sep = &quot;,&quot; istället för bara sep = ,. Detta är standard i R, och det är något som är viktigt att komma ihåg. Notera även att citationstecken anges som &quot;\\&quot;&quot;, detta eftersom två uppsättningar av citationstecken skulle förvirra datorn. Betrakta nu utdraget ur animals2.csv som finns här nedan, och försök återigen identifiera hur argumenten är specificerade, och vilken funktion som bör användas för att läsa in datamaterialet. Svaret finns än en gång att läsa under datamaterialet. &quot;&quot;;&quot;animal&quot;;&quot;body&quot;;&quot;brain&quot; &quot;1&quot;;&quot;Lesser short-tailed shrew&quot;;0,005;0,14 &quot;2&quot;;&quot;Little brown bat&quot;;0,01;0,25 &quot;3&quot;;&quot;Big brown bat&quot;;0,023;0,3 &quot;4&quot;;&quot;Mouse&quot;;0,023;0,4 &quot;5&quot;;&quot;Musk shrew&quot;;0,048;0,33 &quot;6&quot;;&quot;Star-nosed mole&quot;;0,06;1 &quot;7&quot;;&quot;E. American mole&quot;;0,075;1,2 &quot;8&quot;;&quot;Ground squirrel&quot;;0,101;4 &quot;9&quot;;&quot;Tree shrew&quot;;0,104;2,5 &quot;10&quot;;&quot;Golden hamster&quot;;0,12;1 I animals2.csv är argumenten specificerade som header = TRUE eftersom variabelnamnen anges i den första raden sep = &quot;;&quot; eftersom ett semikolon används för att skilja cellerna i varje rad åt quote = &quot;\\&quot;&quot; eftersom helt vanliga citationstecken används för textvariabler dec = &quot;,&quot; eftersom ett kommatecken används som decimaltecken Efter avstämning med standardargumenten framgår att animals2.csv bör läsas in med funktionen read.csv2(), och koden df2 &lt;- read.csv2(file=&quot;D:/animals2.csv&quot;) kan därför användas för att importera datamaterialet till R. Studera nu utdraget ur datamaterialet animals.txt som visas här nedanför, och försök identifiera argument och agöra vilken funktion som bör användas för att importera datamaterialet till R. &quot;animal&quot; &quot;body&quot; &quot;brain&quot; &quot;Lesser short-tailed shrew&quot; 0.005 0.14 &quot;Little brown bat&quot; 0.01 0.25 &quot;Big brown bat&quot; 0.023 0.3 &quot;Mouse&quot; 0.023 0.4 &quot;Musk shrew&quot; 0.048 0.33 &quot;Star-nosed mole&quot; 0.06 1 &quot;E. American mole&quot; 0.075 1.2 &quot;Ground squirrel&quot; 0.101 4 &quot;Tree shrew&quot; 0.104 2.5 I animals.csv är argumenten specificerade som header = TRUE eftersom variabelnamnen anges i den första raden sep = &quot; &quot; eftersom ett blanksteg används för att särskilja cellerna i varje rad quote = &quot;\\&quot;&quot; eftersom helt vanliga citationstecken används för textvariabler dec = &quot;.&quot; eftersom en punkt används som decimaltecken För att läsa in animals.txt är alltså read.table() mest lämplig, och datamaterialet kan importeras med hjälp av koden df3 &lt;- read.table(file=&quot;D:/animals.txt&quot;, header=TRUE). Återgå nu till animals1.csv, och försök läsa in datamaterialet med hjälp av df4 &lt;- read.table(file=&quot;D:/animals1.csv&quot;, header=TRUE, sep=&quot;,&quot;, dec=&quot;.&quot;) Studera såväl df4 som df1, finns det någon skillnad mellan de två datamaterialen? Syftet med df4 är att visa att read.table() också kan användas för att läsa in filer som inte använder de standardargument som presenterades i början av detta delkapitel. Istället för att använde read.csv() går det alltså att använda read.table(), och inom parenteserna specificera de argument som gäller för det datamaterial som ska läsas in. Det går lika bra att använda read.table() med egenspecificerade argument som att använda någon av funktionerna som har förspecificerade argument, och det är helt enkelt upp till varje individuell användare att avgöra vilken approach som är snabbast och lättast. 4.3.2 Excel-filer Eftersom många möjliga uppdragsgivare använder Excel-ark för att lagra och hantera data är det i praktiken nödvändigt att veta hur data från Excel kan importeras till R. Precis som för text-och CSV-filer finns ett antal tips som är bra att tänka på när data matas in i Excel Första raden i varje ark ska innehåla variabelnamn Första kolumnen bör bestå av observationsid Undvik namn och värden med mellanslag. Risken är att det tolkas som två olika kolumner. Korta variabelnamn är bättre än långa. Undvik tecken som ?, $,%, ^, &amp;, *, (, ),-,#, ?,,,&lt;,&gt;, /, |, , [ ,] ,{, och } Radera kommentarer som du har i Excelfilen så att dessa inte tolkas som extra data. Många punkter på listan ovan finns även med i listan över saker som är värda att ta i beaktning när det rör sig om text- och CSV-filer. Det faktum att det finns ett relativt stort överlap kan ses som ett tecken på att många av dessa punkter är övergripande och gäller för nästan alla format som datamaterial kan sparas i. Det finns alltså en generell konvention för hur datamaterial bör struktureras för att göra analysen så smidig som möjligt. I resten av detta avsnitt är målet att importera datamaterialen som finns in Excel-filerna animal3.xlsx och animal4.xlsx. För att importera data som lagras i Excel-filer krävs ett nytt paket i R. Paketet heter readxl, och det lättaste sättet att installera det är att skriva install.packages(&quot;readxl&quot;) i Console och sedan trycka enter. När paketet väl är installerat är det viktigt att även köra koden library(readxl) för att paketet ska aktiveras i R-sessionen. Paketet behöver bara installeras en gång, men det måste aktiveras varje gång R har varit stängt och öppnas på nytt. Det kan därför vara bra att ha library(readxl) längst upp i ett script där Excel-filer läses in. Den första av Excel-filerna, animals3.xlsx, är en vanlig Excel-fil med bra struktur, där all data finns i det första arket. Datamaterialet som finns i filen kan därför enkelt läsas in genom att använda koden som finns i kodsnutten här nedan. df5 &lt;- read_excel(&quot;animal3.xlsx&quot;) Använd samma ansats för att läsa in animal4.xlsx, denna ska alltså läsas in som df6 &lt;- read_excel(&quot;animal3.xlsx&quot;) Jämför df5 och df6 visar båda tecken på att datamaterialen har lästs in på ett korrekt sätt? df5 ser bra ut, och datamaterialet verkar ha importerats på ett bra sätt. För df6, däremot, är det något som har gått fel i inläsningen. Öppna filen animal4.xlsx och fundera på vad det kan vara som orsakar detta fel. När filen är öppen framgår direkt att den består av flera olika kalkylblad, men att datamaterialet som är av intresse finns lagrat i blad 2. Utöver detta är det även så att datamaterialet inte börjar på första raden, utan det finns även annan text i kalkylbladet. För att R ska kunna importera data från animal4.xlsx på ett korrekt sätt krävs att två inställningar specificeras i read_excel(), nämligen sheet och range. Inställningen sheet används för att bestämma vilket blad R ska använda när det importera data från Excel-filer. I fallet animal4.xlsx finns det intressanta datamaterialet i blad 2, vilkt innebär att inställningen bör specificeras som sheet = &quot;Blad2&quot;, eftersom detta är namnet på bladet. Den andra inställningen, range, används för att bestämma vilken del av kalkylbladet som ska läsas in. I detta fall finns det en del text som stör inläsningen, och datamaterialet börjar först på rad 3. Inställningen bör specificeras som range = &quot;A3:D68&quot; eftersom cellerna A3 och D68 kan användas för att bilda en rektangel som innefattar hela datamaterialet (tänkt på det som att dra ett lodrätt och ett vågrätt streck från var och en av cellerna, då kommer alla data finnas inom rektangeln som bildas av strecken). Notera att den första cellen i inställningen ska vara den som är längst upp till vänster i datamaterialet, och den andra cellen ska vara den som finns längt ner till höger. Läs nu in datamaterialet som df7 &lt;- read_excel(&quot;animal4.xlsx&quot;, sheet = &quot;Blad2&quot;, range = &quot;A3:D68&quot;) Studera df7 närmare. Ser den likadan ut som df6, eller har specificeringen av inställningar gjort datainläsningen bättre? Denna typ av inställningar kan användas för att förenkla importen av datamaterial från Excel-filer, därför är det bra att öppna Excel-filer och titta på deras struktur innan de ska importeras till R. read_excel() har som standard att importera data från det första bladet i en Excel-fil, och att importera alla celler som har någon typ av information lagrad i sig (det spelar ingen roll om det är meningslös text eller viktiga data). Därför går det bra att använda funktionen rakt av för datamaterial som är strukturerade som animals3.xlsx, eftersom datamaterialet börjar på första raden och alla celler är fyllda med relevant information. I alla övriga fall är det alltså värt att fundera över hur inställningarna kan användas för att underlätta inläsningen av data. 4.3.3 Övriga format Utöver de format som diskuterats ovan finns ett flertal andra sätt att lagra data. Eftersom dessa inte är lika vanligt förekommande, och eftersom de inte kommer utgöra någon del i denna kurs, kommer majoriteten av dem inte att behandlas här. Det finns, bland annat, en rad programspecifika datalagringsformat som kan dyka upp ibland. Programspecifikt innebär att formatet är strukturerat på ett sätt som passar ett specifikt statistikprogram väldigt bra, till exempel finns speciella format för att lagra data för bruk i SPSS, Minitab, Stata och dylikt. En fördel med programspecifik datalagring är att den kan göras väldigt effektiv, och på sätt kräva mycket mindre minne än t.ex. textfiler. En nackdel som gör att denna typ av datalagring ofta undviks är att datamaterial måste formatteras om när de ska användas i program som inte är standard, och detta kan ofta vara en omständlig process som lätt går fel. R har ett eget datalagrinsformat, och filer som lagras i detta format brukar ha .rds efter filnamnet. Eftersom ett mål med kursen är att lära ut programmering med hjälp av R diskuteras användning av .rds-filer i detta avsnitt. Med hjälp av R:s egna format går det alltså att lagra data mer effektivt när det kommer till minnesanvändning. Formatet gör också att importen av data blir väldigt smidig, eftersom strukturen i datamaterialet är skräddarsydd för att passa de krav som R ställer på ett datamaterial. Funktionen som används för att läsa in datamaterial som sparats i R:s eget format finns direkt tillgänglig i R, och den heter readRDS(). Syntaxen som används för att läsa in datamaterial som finns lagrade i .rds-format är relativt simpel, och kan sammanfattas i kodsnutten nedan. readRDS(file = &quot;filnamn.rds&quot;) För att läsa in datamaterialet som är sparat i filen OVB_data.rds (finns tillgänglig i Studentportalen) används koden som visas här nedanför. df8 &lt;- readRDS(file = &quot;OVB_data.rds&quot;) Som sagt är syntaxen relativt enkel, det enda som krävs är namnet på filen som datamaterialet är lagrat i. Om datamaterialet är del av ett större projekt krävs dock att alla som arbetar med det använder R om det är lagrat i en .rds-fil. Därför kan det vara bra att undvika detta format i sammanhang där flera personer ska jobba med ett och samma datamaterial. 4.4 Läsa in datamaterial med hjälp av menyerna i RStudio Det finns två enkla sätt att läsa in data genom att använda de menyer som finns att tillgå i RStudio. Ett av dem handlar om att använda panelen längst ner till höger för att klicka på en fil som finns i R:s working directory, och det handlar om att använda menyn Import Dataset som finns längst upp till höger i RStudio-fönstret. Båda dessa tillvägagångssätt kommer diskuteras i denna del av Kapitel 4. Den stora fördelen med att läsa in datamaterial med hjälp av RStudios menyer är att det ofta kan vara väldigt lätt att göra, och att inställningar kan ändras flera gånger för att ser hur datamaterialet kommer se ut när det väl har importerats. Det kan alltså vara lättare att ordna en bra import redan vid första försöket. Den största nackdelen är dock att det är lätt att glömma att spara koden som skrivs ut i Console, och att det därför kan bli så att processen måste genomföras varje gång RStudio startas på nytt. Om olika inställningar används varje gång datamaterialet läses in kan det ge snedvridande effekter på den statistika analys som ska genomföras. 4.4.1 Läsa in data från working directory Börja med att set till så att filerna i R:s working directory syns i panelen längst ner till vänster. Instruktioner för hur detta ordnas finns i sista stycket under rubriken Working directory i detta kapitel. Flytta nu filen OVB_data.rds till mappen som är working directory, och vänta tills det att den dyker upp i panelen längst ner till vänster. Klicka på filens namn när den har dykt upp, så att en dialogruta dyker upp. I denna ruta anges det namn som datamaterialet ska ha när det importeras till R. Ange ett namn och klicka på OK så importeras datamaterialet direkt till R. När filen som ska läsas in inte är av .rds-format kan det bli lite krångligare att använda denna approach, men i de flesta fall så går det att ändra grundinställningarna precis som när data importeras med hjälp av kod. Ladda nu ner filen OVB_data.csv och flytta den till working directory. Testa att klicka på dess namn i panelen längst ner till vänster, och sedan klicka på Import Dataset. När detta är gjort öppnas ett fönster där datamaterialet visas, detta fönster illustreras i bilden nedan. Som synes ser datamaterialet väldigt väl organiserat ut, men det behöver inte alltid vara fallet. Ibland kan det vara så att datamaterialet ser väldigt konstigt ut, och detta kan bero på att grundinställningarna i inläsningen inte är anpassade efter datamaterialet i fråga. När det rör sig om text- och CSV-filer finns det, precis som när data importeras med kod, fyra inställningar som kan ändras för att datamaterialet ska importeras korrekt. Dessa inställningar kan ändras i rutan Import Options, som finns precis under datamaterialet. Med hjälp av rutan vid First Row as Names kan inställningen header justeras. Om rutan har en bock i sig har inställningen specifierats som header = TRUE, annars är inställningen satt till FALSE. Till höger om Delimeter: finns en rullista som kan användas för att avgöra vilket tecken som används för att skilja mellan kolumner, och Till höger om Quotes: finns en rullista som kan användas för att avgöra hur textvariabler hanteras. Dessa båda motsvarar inställningarna sep respektive quote från tidigare. Slutligen kan knappen Configure till höger om Locale användas för att få upp en ruta där alternativet dec kan användas för att avgöra vilken typ av decimaltecken som används i datamaterialet. En sak som är särskilt bra med detta sätt att importera data är att det går att ange vilken datanivå varje variabel har (eller är tänkt att ha). Under varje variabel namn finns i bilden ovan en liten pil (med texten (double) bredvid). Klicka gärna på denna fil för att få upp en lista med olika datanivåer, en sådan lista visas i bilden som följer. Det första allternativet i listan ovan är Guess, vilket innebär att R läser av värdena som finns i kolumnen och “gissar” vilken datanivå variabeln har. Om variabeln i fråga är en faktor variabel med numeriska nivåer, till exempel de binära nivåerna 0 och 1, är det lätt hänt att R gissar fel och klassa variabeln som Integer. För att undvika detta rekommenderas att byta datanivån till Factor, detta kommer visas sig vara till stor hjälp i analysen av datamaterialet. Notera även att alternativen Skip och Only finns längst ner i listan. Alternativet Skip medför att den valda variabeln inte importeras, och Only medför att bara den valda variabeln importeras. Med hjälp av dessa fem inställningar bör det vara möjligt att läsa in datafiler på ett ordentligt sätt. 4.4.2 Läsa in data med “Import Dataset” Längst upp till höger i RStudio finns en knapp där det står Import Dataset. Klicka på denna för att få upp en rullista med alternativ (se bild nedan). I listan går det att välja vilket format datamaterialet som ska läsas in har. För text- och CSV-filer rekommenderas From Text (base). Klicka på From Text (base) för att få upp ett fönster med alla filer som finns i R:s working directory. Notera att det även går att navigera runt i datorn för att hitta datamaterial som finns i mappar som inte är working directory. Välj nu filen OVB_data.csv för att få upp rutan som visas i bilden nedan. I rutan finns tre paneler. I panelen med rubrik Input File visas filen som ska läsas in, med andra ord ger den en blick över det rådata som finns. Det som är bra med denna panel är att det går väldigt lätt att undersöka hur det ligger till med grundinställningarna som diskuterats ovan, det vill säga vilken typ av decimalteceken som använs och så vidare. I panelen som heter Data Frame visas strukturen på den data frame som kommer läsas in med de inställningar som råder för tillfället. I detta fall ser datamaterialet bra strukturerat ut, men så är inte alltid fallet. När det som visas under Data Frame ser dåligt strukturerat ut är det en bra idé att ändra på inställningarna till vänster om de två panelerna. De vanligaste inställningarna ändras med hjälp av Heading som anger huruvida den första raden innehåller variabelnamn, Separator som anger vilket tecken som används för att skilja mellan kolumner, Decimal som anger vilken typ av decimaltecken som används, och Quote som används för att specificera textvariabler. Testa att byta inställningen för Heading till Yes, vad händer? Ser materialet som visas under Data Frame bättre ut. Prova även att ändra de andra inställningarna för att se vad som händer, och fundera över varför det blir som det blir. När datamaterialet som visas under Data Frame ser bra ut importeras det genom att trycka på Import. Notera att ett kommando skrivs ut och körs i Console när datamaterialet importeras. Denna kod kan vara värd att kopiera och spara i den scriptfil där datamaterialet är tänkt att analyseras, eftersom koden då bara kan köras för att importera datamaterialet nästa gång R startas. Om koden redan finns i scriptet är det inte nödvändigt att importera det genom att använda Import Data-menyn en gång till. 4.5 Spara datamaterial med hjälp av R Många gånger kan det vara fördelaktigt att exportera ett datamaterial från R, och spara det på datorn i någon sorts text- eller excel-fil. Till exemple kan det vara så att R har använts för att städa ett datamaterial, göra olika ändringar i ett datamaterial, eller slå ihop två eller flera datamaterial. Då är det smidigt att kunna spara det förändrade datamaterialet för att sedan kunna arbeta med det direkt, och inte behöva genomföra samma förändringar varje gång analysarbete ska utföras. De kommandon som används för att exportera datamaterial i R är snarlika de som används för att importera datamaterial. Funktionerna har nästan samma namn, och deras struktur är uppbygd på i stort sett sätt. För att spara datamaterial i text-filer finns tre huvudsakliga funktioner. Dessa är write.csv(x, file = &quot; &quot;, header = TRUE, sep = &quot;,&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;) write.csv2(x, file = &quot; &quot;, header = TRUE, sep = &quot;;&quot;, quote = &quot;\\&quot;&quot;, dec = &quot;,&quot;) write.table(x, file = &quot; &quot;, header = TRUE, sep= &quot; &quot;, quote = &quot;\\&quot;&quot;, dec = &quot;.&quot;) Notera att funktionsnamnen är likadana, med skillnaden att det nu står write istället för read framför punkten. Grundinställningarna i funktionerna är samma som de för motsvarande funktion som används för dataimport. I funktionerna representerar x det material som ska exporteras, och inom de citationstecken som finns efter file = anges namnet på den fil som datamaterialet ska sparas i. Datamaterialet kommer per automatik sparas i det working directory som är angivet när kodsnutten körs. För att visa hur exportfunktionerna kan komma till nytta används de två datamaterialen exp_dat1.csv och exp_dat2.csv. De båda datamaterialen är simulerade vilked medför att de inte är särskilt intressanta i sig själva, utan det intressanta är hur de kan manipuleras och sedan sparas. Ladda ner de två datamaterialet till ett R:s working directory och läs in dem som exp_dat1 &lt;- read.csv(&quot;exp_dat1.csv&quot;) exp_dat2 &lt;- read.csv(&quot;exp_dat2.csv&quot;) Sätt sedan ihop datamaterialen till ett stort material genom att använda rbind() exp_sam &lt;- rbind(exp_dat1, exp_dat2) För att kontrollera huruvida de två materialen har satts ihop på ett korrekt sätt går det att använda View(exp_sam) Det nya datamaterialet kan nu exporteras med hjälp av funktionerna ovan. För att exportera det till en textfil där cellerna separeras av semikolon används write.csv2(exp_sam, file = &quot;exp_sam.csv&quot;) I detta fall sparas en textfil vid namn exp_sam.csv i det working directory som har angivits. Notera att filen som sparas inte måste ha samma namn som datamaterialet har i R. Om det, av någon anledning, anses att sammanslagna_data.csv är ett bättre namn på filen som ska sparas används helt enkelt write.csv2(exp_sam, file = &quot;sammanslagna_data.csv&quot;) 4.6 Övningar Övning 4.1 Denna uppgift kretsar kring att importera data från sjätte vågen av World Values Survey. Datamaterialet är begränsat till svar från de intevjuer som utförts i Sverige under år 2011, och innehåller 1206 observationer. Alla svar är omkodade till siffror, och ett utdrag ur datamaterialet innehåller svar på frågor gällande Äktenskaplig status Antal barn Huruvida responenten skulle vara villig att försvara Sverige vid ett eventuellt krigsutbrott Ålder Frågorna är sorterade så att varje punkt i listan ovan motsvarar respektive kolumn i datamaterialet (alltså finns äktenskaplig status i första kolumnen, antal barn i andra kolumnen, etc.). Uppgiften är nu att: Ladda ner datamaterialet som finns lagrat i VWS.csv från Studentportalen. Öppna filen som datamaterialet är lagrad i med hjälp av Notepad, TextEdit, eller någon annan textredigerare. Fundera på hur datamaterialet materialet är strukturerat, och ange hur de fyra grundinställningarna är specificerade i filen. Visa svar I datamaterialet är header = FALSE eftersom inga variabelnamn ges i första raden sep = &quot;;&quot; eftersom semikolon används för att skilja mellan kolumner quote = &quot;\\&quot;&quot; detta går egentligen inte att se, eftersom inga textvariabler finns med dec = &quot;.&quot; detta går inte heller att se, eftersom inga decimaltal finns i datamaterialet Avgör vilken av funktionerna read.csv() och read.csv2() som är bäst lämpad för att importera datamaterialet till R, och skriv sedan en kodsnutt som kan användas för att importera datamaterialet. Visa svar Eftersom semikolon används för att skilja mellan kolumner är read.csv2() bäst lämpad för att läsa in datamaterialet. Notera dock att header = FALSE, och att denna inställning måste ändras i koden. Kodsnutten som används för att läsa in datameterialet blir så wvs &lt;- read.csv2(&quot;WVS1.csv&quot;, header = FALSE) Använd nu read.table() för att importera samma datamaterial genom att ange egna specifikationer för alla inställningar. Visa svar För att använda read.table() måste inställningarna för header och sep specificeras så att wvs2 &lt;- read.table(&quot;WVS1.csv&quot;, header = FALSE, sep = &quot;;&quot;) Ge varje kolumn ett meningsfullt namn. Visa svar Vad som räknas som bra namn är till viss del subjektivt, och det är inget krav att namnen ska vara exakt samma som de namn som anges här. Vad som är viktigt är att namnen är i linje med rekommendationerna som ges i texten. Exampel på variabelnamn colnames(wvs) &lt;- c(&quot;ID&quot;, &quot;marital_status&quot;, &quot;children&quot;, &quot;defend_country&quot;, &quot;age&quot;) View(wvs) Läs in datamaterialet genom att använda Import Dataset-menyn. Blir resultatet likadant som ovan? Övning 4.2 Denna övning använder samma datamaterial som övningen ovan, dock i ett annat format. Utför följande uppgifter: Ladda ner filen WVS.xlsx från Studentportalen och studera den i ett Excel-fönster. Finns det något som kan orsaka svårigheter i datainläsningen? Finns det några celler som innehåller information som inte är relevant i sammanhanget? Visa svar I datamaterialet finns tre saker som är värda att notera All data finns i det andra arket, vid namn Sheet2 Ovanför datamaterialet finns en informationstext som berättar var datamaterialet har hämtats och vad det innehåller för information Till höger om datamaterialet finns ett index som visar vad varje kolumn innehåller data för Använd funktionen read_excel() för att läsa in datamaterialet. Vilka inställningar är viktiga att ändra för att inläsningen ska gå korrekt till? Visa svar För att datainläsningen ska gå korrekt till finns två inställningar som behöver ändras. Den ena är sheet, som bestämmer vilket ark som ska läsas in, och den andra är range som anger vilken del av Excel-arket som ska läsas in. I detta fall bör sheet = &quot;Sheet2&quot;, och range = &quot;A4:D1210&quot;, och koden blir wvs3 &lt;- read_excel(&quot;WVS.xlsx&quot;, sheet = &quot;Sheet2&quot;&quot;, range = &quot;A4:D1210&quot;) Notera att indexet över vilken variabel som hör till vilken kolumn kan vara bra att spara på annat sätt, men inte i själva datamaterialet. Använd valfri meny i RStudio for att importera datamaterialet som finns i WVS.xlsx. Var noga med att bara importera den del av materialet som kan komma att bli relevant för en framtida analys. Övning 4.3 I textfilen covid_19.csv finns information gällande antalet bekräftade fall av Covid-19 i hela Sverige, samt regionsspecifik information för Dalarna och Uppsala. Skriv en kodsnutt som på lämligt sätt importerar datamaterialet till R Visa svar Börja med att öppna filen i textedit eller notepad (beroende på vilken typ av dator du har). Det första som finns i datamaterialet är en informationstext som kan ställa till det vid datainläsning. För att komma runt denna informationstext finns två olika alternativ Radera texten manuellt, spara om filen, och sedan läsa in den som vanligt Använda inställningen skip och få R att hoppa över de första raderna när datamaterialet importeras. I vilket fall som helst kan konstateras att header = TRUE sep = &quot;,&quot; quote = &quot;\\&quot;&quot; egentligen finns ingen text-data i materialet, men detta är ett antagende som kan göras dec = &quot;.&quot; här gäller samma sak som ovan Det är alltså lämplig att använda read.csv() för att importera datamaterialet. Om den inledande texten har raderats, och om filen finns i ett aktuellt working directory, kan materialet läsas in som covid_19 &lt;- read.csv(&quot;covid_19.csv&quot;) Om informationstexten ligger kvar är det viktigt att notera att de 8 första raderna i textfilen antingen innehåller text eller är tomma. Därför kan alternativet skip sättas till 8, så börjar R läsa in data från den nionde raden i filen. Koden skrivs då som covid_19 &lt;- read.csv(&quot;covid_19.csv&quot;, skip = 8) Undersök datamaterialet för att se om det finns några konstigheter, så som konstiga eller orimliga värden. Koda i sådana fall om de konstiga värdena till NA Visa svar För att få en sammanfattning av datamaterialet kan summary() användas summary(covid_19) ## X Statistikdatum Totalt_antal_fall Dalarna ## Min. : 1.0 2020-02-04: 1 Min. : -99.0 Min. : 0 ## 1st Qu.: 67.5 2020-02-05: 1 1st Qu.: 144.0 1st Qu.: 3 ## Median :134.0 2020-02-06: 1 Median : 330.0 Median : 9 ## Mean :134.0 2020-02-07: 1 Mean : 419.3 Mean : 11685 ## 3rd Qu.:200.5 2020-02-08: 1 3rd Qu.: 655.5 3rd Qu.: 18 ## Max. :267.0 2020-02-09: 1 Max. :1980.0 Max. :999999 ## (Other) :261 NA&#39;s :10 ## Uppsala ## Min. : 0.00 ## 1st Qu.: 4.00 ## Median : 13.00 ## Mean : 20.81 ## 3rd Qu.: 33.00 ## Max. :173.00 ## Som synes finns konstiga värden på två olika stället I variabeln Totalt_antal_fall är det minsta värdet -99. Eftersom variabeln mäter antal som bekräftats smittade är negativa tal inte möjliga, och därför bör alla tal som är mindre än noll kodas om till NA I kolumnen som mäter antalet som bekräftats smittade i Dalarna finns minst ett värde som är 999999. Eftersom Dalarnas folkmängd är cirka 285 000 borde detta vara en ren omöjlighet. Därför används koden covid_19$Totalt_antal_fall[covid_19$Totalt_antal_fall &lt; 0] &lt;- NA covid_19$Dalarna[covid_19$Dalarna == 999999] &lt;- NA för att koda om de konstiga värdena. För att kontrollera att altt nu står rätt till anropas summary() en gång till summary(covid_19) ## X Statistikdatum Totalt_antal_fall Dalarna ## Min. : 1.0 2020-02-04: 1 Min. : 0.0 Min. : 0.00 ## 1st Qu.: 67.5 2020-02-05: 1 1st Qu.: 166.5 1st Qu.: 3.00 ## Median :134.0 2020-02-06: 1 Median : 347.5 Median : 9.00 ## Mean :134.0 2020-02-07: 1 Mean : 441.6 Mean :12.06 ## 3rd Qu.:200.5 2020-02-08: 1 3rd Qu.: 668.8 3rd Qu.:17.00 ## Max. :267.0 2020-02-09: 1 Max. :1980.0 Max. :64.00 ## (Other) :261 NA&#39;s :11 NA&#39;s :13 ## Uppsala ## Min. : 0.00 ## 1st Qu.: 4.00 ## Median : 13.00 ## Mean : 20.81 ## 3rd Qu.: 33.00 ## Max. :173.00 ## Denna gång ser allt bra ut. p.comment { background-color: #DBDBDB; padding: 10px; border: 1px solid black; margin-left: 25px; border-radius: 5px; font-style: italic; } "],
["binära-variabler.html", "Kapitel 5 Binära variabler 5.1 Deskription av en binär variabel 5.2 Tabeller och en binär variabel 5.3 Figurer och en binär variabel 5.4 Inferens för binär variabel 5.5 Deskription av två binära variabler 5.6 Tabeller och två binära variabler 5.7 Kvantifiering av samband mellan två binära variabler 5.8 Figurer och två binära variabler 5.9 Inferens för två binära variabler 5.10 Övningar 5.11 Referenser", " Kapitel 5 Binära variabler En nödvändig färdighet vid arbete med data är att kunna hantera och analysera kategorivariabler. Vi börjar i detta kapitel med det enkla fallet binära variabler för att i ett senare kapitel övergå till att studera hur man arbetar med variabler som har fler än två kategorier. 5.1 Deskription av en binär variabel Detta avsnitt fokuserar på analys av binära kategorivariabler. I princip alla datamaterial innehåller variabler med två kategorier och även om data inledningsvis inte innehåller binära variabler är det vanligt att av olika skäl omkoda kvantitativa variabler till variabler med två kategorier. För nybörjaren kan det vara förvirrande att det finns åtminstone två alternativ, som bägge är viktiga, för hur man arbetar med binära variabler. Alternativ 1. En binär kategorivariabel hanteras som en numerisk variabel efter att kategorierna tilldelats numeriska värden. Exempelvis kan vi ange att värdena 0 och 1 representerar två kategorier. Observera att val värden påverkar hur variabeln används i analysen. Alternativ 2. En binär kategoriabel definieras med funktionen factor()som datatypen faktor. En faktors kategorier benämns i R för levels (nivåer). Fördelen med att definiera en variabel som faktor är att R kan använda information om den binära variabeln i analyser och resultat. Till exempel kan kategoriernas namn presenteras i resultat. Dessutom kräver en del metoder i R en faktor-variabel. Observera att det, av förklarliga skäl, inte går att utföra räkneoperationer på variabler definierade som datatypen faktor. Eftersom bägge varianterna har för- och nackdelar återfinns ofta bägge varianter av kodning för en och samma binära variabel i ett dataset — en numerisk version kodad 0-1 kallad för variabelnamn_bin och version kodad som faktor kallad variabelnamn_cat. Oavsett om en binär variabel har kategorier som inte går att rangordna (till exempel variabeln \\(kön\\) med kategorierna \\(kvinna\\) och \\(man\\)) eller har kategorier som går att rangordna (till exempel \\(utbildning\\) med kategorierna \\(låg\\) och \\(hög\\)) beskrivs en binär variabel på samma sätt. Vi ska nu presentera visa hur man beskriver en binär variabel, utifrån de tidigare två nämnda alternativen. Vi exemplifierar med att beskriva variabel som heter \\(education\\) som har två kategorier, \\(low\\) och \\(high\\) och som vi läser in nedan. Med funktionen str() identifieras att \\(education\\) är en variabel med datatypen character. Det är alltid viktigt att undersöka variablers datatyp, emellertid är detta ingen kod som sedan sparas i scriptet. Efter datatypen är undersökt kan denna rad med kod tas bort från scriptet. Funktionen str() är användbar för att undersöka alla typer av objekt i R, till exempel variabler, dataframes och objekt som innehåller sparade resultat. # Ursprungsvariabel, data du har erhållit. education &lt;- c(&quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;high&quot;, &quot;high&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;, &quot;high&quot;, &quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;, &quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;,&quot;low&quot;) # Undersök hur R identifierar variabelns datatyp str(education) &gt; chr [1:280] &quot;high&quot; &quot;high&quot; &quot;low&quot; &quot;high&quot; &quot;high&quot; &quot;low&quot; &quot;high&quot; &quot;low&quot; ... Med Alternativ 1 tilldelas de två kategorierna i den binära variabeln numeriska värden och variabeln analyseras sedan som en numerisk variabel. Det är vanligast att ge kategorierna värdena 0 och 1. En anledning är tolkningen blir i termer av andelar av den kategori som är kodad 1. Exemplet nedan illustrerar hur man med det numeriska alternativet kan beskriva den ursprungliga variabeln \\(education\\) som har kategorierna \\(low\\) och \\(high\\). Den uppenbara fördelen med att kodningen 0-1, jämfört med 1-2, är att 0-1 ger en bekväm tolkning eftersom medelvärdet då är proportionen. Kommandot str() identifierar nu att både edu_bin och edu_12 är av typen numeric. Med mean() och summary() erhålls information som beskriver edu_bin och edu_12. Vi ser att 41% har hög utbildning. Däremot ser vi inte hur många som har låg respektive hög utbildning. # Numerisk kodning: 0 = low, 1 = high edu_bin &lt;- rep(NA, length(education)) edu_bin[education == &quot;high&quot;] &lt;- 1 edu_bin[education == &quot;low&quot;] &lt;- 0 str(edu_bin) &gt; num [1:280] 1 1 0 1 1 0 1 0 0 1 ... phat &lt;- mean(edu_bin) phat &gt; [1] 0.4142857 summary(edu_bin) &gt; Min. 1st Qu. Median Mean 3rd Qu. Max. &gt; 0.0000 0.0000 0.0000 0.4143 1.0000 1.0000 # Numerisk kodning: 1 = low, 2 = high edu_12 &lt;- rep(NA, length(education)) edu_12[education == &quot;high&quot;] &lt;- 2 edu_12[education == &quot;low&quot;] &lt;- 1 summary(edu_12) &gt; Min. 1st Qu. Median Mean 3rd Qu. Max. &gt; 1.000 1.000 1.000 1.414 2.000 2.000 Med Alternativ 2 används funktionen factor() för skapa en faktorvariabel edu_cat Kommandot str() identifierar nu att edu_cat har två nivåer med kategorinamnen “low” and “high”. R tilldelar automatiskt kategorierna nivåer, där “high” är level 1 och “low” är level 2. Observera att nivåer används för att bestämma en rangordning och kan inte användas i aritmetiska beräkningar. Även om valet av nominal- eller ordinalskala i teorin saknar betydelse för en binär variabel är det viktigt att veta ordningen på nivåerna om man hanterar variabeln som en faktor.Det finns nämligen analyser i R där ordningen spelar roll. Nivåerna bestäms utifrån den ordning kategorierna dyker upp i variabeln såvida inte en numerisk variabel görs om till en faktor. Faktorvariabeln kan beskrivas med summary() som redovisar antalet inom respektive utbildningskategori. Däremot kan vi inte använda mean() och därmed inte fram andelen med denna funktion. Det går att i funktionen factor() använda argumentet levels för att manuellt ange nivåerna. Dessutom kan det i detta exempel uppfattas som förvirrande för användaren att “high” har tilldelats nivå 1 medan “low” är nivå 2. Av dessa skäl ändras därför ordningen med hjälp av argumentet levels. Vid arbete med faktorer används ofta en funktion (ej att förväxla med argumententet levels() för att ändra kategorinamn.I exemplet nedan används denna funktion för att ändra kategorinamn på \\(edu_cat\\). Koden för att ändra namn är inte uppenbar för nybörjaren och det är enklast om du kopierar koden nedan och ändrar den efter dina behov. # Skapa en faktorvariabel edu_cat &lt;- factor(education) str(edu_cat) &gt; Factor w/ 2 levels &quot;high&quot;,&quot;low&quot;: 1 1 2 1 1 2 1 2 2 1 ... mean(edu_cat) &gt; Warning in mean.default(edu_cat): argument is not numeric or logical: &gt; returning NA &gt; [1] NA summary(edu_cat) &gt; high low &gt; 116 164 # Test att utföra en räkneoperation på en faktorvariabel mean(edu_cat) &gt; Warning in mean.default(edu_cat): argument is not numeric or logical: &gt; returning NA &gt; [1] NA # Ändra ordningen på nivåerna edu_cat &lt;- factor(education, levels = c(&quot;low&quot;, &quot;high&quot;)) str(edu_cat) &gt; Factor w/ 2 levels &quot;low&quot;,&quot;high&quot;: 2 2 1 2 2 1 2 1 1 2 ... summary(edu_cat) &gt; low high &gt; 164 116 # Ändra för valt element namn i vektor levels(education_cat) levels(edu_cat)[levels(edu_cat) == &quot;low&quot;] &lt;- &quot;Låg utbildning&quot; levels(edu_cat)[levels(edu_cat) == &quot;high&quot;] &lt;- &quot;Hög utbildning&quot; edu_cat &gt; [1] Hög utbildning Hög utbildning Låg utbildning Hög utbildning &gt; [5] Hög utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [9] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [13] Hög utbildning Hög utbildning Hög utbildning Låg utbildning &gt; [17] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [21] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [25] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [29] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [33] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [37] Låg utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [41] Hög utbildning Hög utbildning Låg utbildning Hög utbildning &gt; [45] Hög utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [49] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [53] Hög utbildning Hög utbildning Hög utbildning Låg utbildning &gt; [57] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [61] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [65] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [69] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [73] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [77] Låg utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [81] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [85] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [89] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [93] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [97] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [101] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [105] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [109] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [113] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [117] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [121] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [125] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [129] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [133] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [137] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [141] Hög utbildning Hög utbildning Låg utbildning Hög utbildning &gt; [145] Hög utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [149] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [153] Hög utbildning Hög utbildning Hög utbildning Låg utbildning &gt; [157] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [161] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [165] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [169] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [173] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [177] Låg utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [181] Hög utbildning Hög utbildning Låg utbildning Hög utbildning &gt; [185] Hög utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [189] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [193] Hög utbildning Hög utbildning Hög utbildning Låg utbildning &gt; [197] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [201] Hög utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [205] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [209] Hög utbildning Låg utbildning Hög utbildning Hög utbildning &gt; [213] Låg utbildning Hög utbildning Hög utbildning Hög utbildning &gt; [217] Låg utbildning Låg utbildning Hög utbildning Låg utbildning &gt; [221] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [225] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [229] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [233] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [237] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [241] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [245] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [249] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [253] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [257] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [261] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [265] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [269] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [273] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; [277] Låg utbildning Låg utbildning Låg utbildning Låg utbildning &gt; Levels: Låg utbildning Hög utbildning Avslutningsvis ska vi på betydelsen av bortfall. I exemplet nedan skapas bortfall genom att på några ställen lägga bortfall kodat NA för observation 3 och 10. Vi ser att med summary() hanteras bortfallet i bägge fallen, men med mean() måste argumentet na.rm användas. # Skapa en variabel med missing data (NA) i element 3, 10 i den numeriska # variabeln edu_bin och genomför samma analys som förut edu_bin_mis &lt;- edu_bin edu_bin_mis[3] &lt;- NA edu_bin_mis[10] &lt;- NA mean(edu_bin_mis) &gt; [1] NA # Medelvärde baserat på 278 observationer mean(edu_bin_mis, na.rm = TRUE) &gt; [1] 0.4136691 summary(edu_bin_mis) &gt; Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s &gt; 0.0000 0.0000 0.0000 0.4137 1.0000 1.0000 2 # Skapa en variabel med missing data (NA) i element 3, 10 i faktor-variabeln # edu_cat och genomför samma analys som förut edu_cat_mis &lt;- edu_cat edu_cat_mis[3] &lt;- NA edu_cat_mis[10] &lt;- NA summary(edu_cat_mis) &gt; Låg utbildning Hög utbildning NA&#39;s &gt; 163 115 2 5.2 Tabeller och en binär variabel Tabeller och kategorivariabler är direkt relaterade och det går att redovisa en binär variabel med hjälp av tabell-funktionen table(). Denna funktion hanterar både en och flera variabler med olika antal kategorier. Vi börjar med att använda table() på de tidigare skapade binära variablerna. Vi ser att table() ger frekvenser oavsett om variabeln är numerisk eller en faktor. Det gäller dock att vara uppmärksam på bortfall när table() används och för att presentera frekvenser även för bortfall används argumentet useNA. table(edu_bin) &gt; edu_bin &gt; 0 1 &gt; 164 116 table(edu_cat) &gt; edu_cat &gt; Låg utbildning Hög utbildning &gt; 164 116 table(edu_bin_mis) &gt; edu_bin_mis &gt; 0 1 &gt; 163 115 table(edu_bin_mis, useNA = &quot;ifany&quot;) &gt; edu_bin_mis &gt; 0 1 &lt;NA&gt; &gt; 163 115 2 table(edu_cat_mis) &gt; edu_cat_mis &gt; Låg utbildning Hög utbildning &gt; 163 115 table(edu_cat_mis, useNA = &quot;ifany&quot;) &gt; edu_cat_mis &gt; Låg utbildning Hög utbildning &lt;NA&gt; &gt; 163 115 2 Varför använda table()? Genom att skapa ett tabell-objekt erhålls en flexibilitet genom att funktioner anpassade för tabeller kan användas. Den vanligaste funktionen är prop.table() som beräknar andelar (relativa frekvenser, proportioner) baserat på tabellobjektets frekvenser. Att enbart redovisa frekvenser är nämligen inte tillräckligt ur ett analysperspektiv. Vi skapar nedan ett tabell-objekt med frekvenser, sedan appliceras prop.table() för att erhålla andelarna (0.414 och 0.586) för respektive utbildningsnivå. &gt; # Skapa tabell-objekt med frekvenser från tabell-objektetet &gt; freq_table_edu_cat &lt;- table(edu_cat) &gt; freq_table_edu_cat &gt; edu_cat &gt; Låg utbildning Hög utbildning &gt; 164 116 &gt; &gt; # Skapa tabell med andelar från tabell-objektetet &gt; prop_table_edu_cat &lt;- prop.table(freq_table_edu_cat) &gt; prop_table_edu_cat &gt; edu_cat &gt; Låg utbildning Hög utbildning &gt; 0.5857143 0.4142857 Som nämnt är det i regel viktigt att beskriva både frekvenser och andelar. Nedan görs detta genom använda cbind() och kombinera tabell-objektet med frekvenser och objektet med andelar med andelar. Sedan namnges kolumnerna colnames(). Eftersom edu_cat, då det är en faktorvariabel redan har kategorierna namngivna behöver raderna inte namnges. Om så inte vore fallet kunde vi använt rownames() för att namnge rader. &gt; # Kombinera frekvenser och andelar. Passa samtidigt på att avrunda till en decimal och göra om variabeln till procent. &gt; table_edu &lt;- cbind(freq_table_edu_cat, round(100*prop_table_edu_cat, 1)) &gt; table_edu &gt; freq_table_edu_cat &gt; Låg utbildning 164 58.6 &gt; Hög utbildning 116 41.4 &gt; # Ge tabellens kolumner namn &gt; colnames(table_edu) &lt;- c(&quot;Frekvens&quot;, &quot;Procent (%)&quot;) &gt; table_edu &gt; Frekvens Procent (%) &gt; Låg utbildning 164 58.6 &gt; Hög utbildning 116 41.4 5.3 Figurer och en binär variabel Ett alternativ till tabeller är figurer och för att illustrera kategorivariabler används ofta stapeldiagram. R konstrueras sådana med funktionen barplot(). Undvik cirkeldiagram såvida ett sådant diagram inte är välmotiverat. Det går att betrakta stapeldiagram som en grafisk representation av en tabell och därför är utgångspunkten ofta (men inte alltid) ett tabell-objekt när man använder barplot(). Nedan konstrueras två figurer, en baserad på tabell-objektet med frekvenser och en baserad på den med andelar. Observera att nedanstående är avsett att illustrera stapeldiagram och ett stapeldiagram tillför i fallet med en enda binär variabel ingen information. Det räcker nästan alltid med att istället bara ange numeriska värden. Det du också ska uppmärksamma i exemplet är axlarna på ett tydligt sätt namngivna! Glöm inte ange axlarna! Det går naturligtvis även att ändra färger, men vi väntar med detta tills figur-kapitlet. # stapeldiagram baserat på tabellen med frekvenser barplot(freq_table_edu_cat, ylab = &quot;Antal&quot;) # stapeldiagram baserat på tabellen med andelar barplot(prop_table_edu_cat, ylab = &quot;Procent (%)&quot;) 5.4 Inferens för binär variabel Hittills har vi ägnat oss åt att beskriva en variabel i stickprovet, men ofta önskar vi också baserat på vårt stickprov uttala oss egenskaper i en population. Det första är att beräkna konfidensintervall för med viss säkerhet få en uppfattning om andelen i populationen, \\(p\\). Det andra är att med hypotesprövning undersöka i vilken utsträckning vårt data stämmer överens med hypotes om populationen, \\(H_0: p =p_0\\). Huruvida urvalet är gjort med eller utan återlägning saknar praktisk betydelse då urvalsstorleken antas vara liten relativt populationsstorleken. Vi börjar med att se hur vi kan konstruera ett konfidensintervall för andelen \\(p\\) i en stor population. Stickprovsandelen är \\(\\hat{p}\\) kan definieras som \\(\\hat{p}=\\dfrac{k}{n}\\) där \\(n\\) är antal försök (antal 0or och 1or) och \\(k\\) är antalet lyckade försök (antal 1or). Givet OSU och \\(np(1-p)&gt;5\\) är andelsestimatorn approximativt normalfördelad och ett konfidensintervall ges av \\[ \\hat{p}\\pm z_{\\alpha/2}\\sqrt{\\hat{V}(\\hat{p})}, \\] där \\(\\hat{V}(\\hat{p}) = \\dfrac{\\hat{p}(1-\\hat{p})}{n}\\) är skattningen av stickprovsandelens varians och \\(z_{\\alpha/2}\\) är ett värde från den standardnormalfördelningen baserat på konfidensgraden \\(100(1-\\alpha)\\%\\). Notera att felmarginalen är \\(z_{\\alpha/2}\\sqrt{\\hat{V}(\\hat{p})}\\). Anta variabeln education består av mätningar på individer dragna med OSU från en stor population. Målet är att beräkna ett 95% konfidensintervall för andelen med högutbildning i populationen, \\(p\\). Genom att implementera ovanstående formler kan detta enkelt beräknas i R. # Beräkna antalet lyckade försök k (antal 1or) k &lt;- freq_table_edu_cat[2] # Beräkna antal försök (1or or 0r). Denna kodning gör att eventuella NA inte tas med i beräkningen av n n &lt;- sum(freq_table_edu_cat) # Skattning av andelen med hög utbildning. Det går även att använda mean(edu_bin) phat &lt;- k/n # Skatta variansen vphat &lt;- phat*(1-phat)/n # Välja konfidensgrad 100*(1-alpha)% alpha &lt;- 0.05 # Detta ger värdet för från z-fördelningen med 2.5% i högre svansen z_alpha &lt;- qnorm((1-alpha/2)) # Konfidensintervallets nedre gräns (lower limit) ll &lt;- phat - z_alpha*sqrt(vphat) # Konfidensintervallets övre gräns (upper limit) ul &lt;- phat + z_alpha*sqrt(vphat) p_KI &lt;- c(ll, ul) p_KI Hög utbildning Hög utbildning 0.3565876 0.4719839 # Undersöker förutsättningen np(1-p) &gt;5. Vi använder phat istället för p eftersom det är det enda vi # har. Man måste alltid undersöka om resultaten går att lita på! n*phat*(1-phat) Hög utbildning 67.94286 Vi skattar att 41.4% är högutbildade i populationen. Med 95% säkerhet är andelen högutbildade i populationen mellan 35.7% och 47.2% Vi ska nu se på hur inferens kan göras i form av hypotesprövning. Givet OSU och samma förutsättningar som för skapandet av konfidensintervall gäller vid hypotesprövning av \\(H_0: p = p_{H_0}\\) test-statistikan \\[z = \\dfrac{\\hat{p} - p_{H_0}}{\\sqrt{\\dfrac{p_{H_0}(1-p_{H_0})}{n}}}\\] är approximativt \\(N(0,1)\\) om \\(H_0\\) är sann. För att exemplifiera, anta att vi vill undersöka om 40% i populationen har hög utbildning. Vi sätter upp hypoteserna \\(H_0: p = 0.4\\) vs \\(H_1: p \\neq 0.4\\). Utifrån från formeln ovan beräknas det observerat \\(z\\)-värde. Vi ser sedan se hur extremt det är i en standardnormalfördelning för att få fram \\(p\\)-värdet. Om vi önskar fatta ett beslut jämför vi sedan \\(p\\)-värdet mot en förvald signifikansnivå. # p givet nollhypotesen pH0 &lt;- 0.4 # Teststatistika zobs &lt;- (phat - pH0)/sqrt(pH0*(1-pH0)/n) zobs Hög utbildning 0.48795 # Vi erhåller ett observerat z-värde. p-värdet är anger hur extremt detta z-värde. # pnorm() för sannolikheten VÄNSTER om z-värdet. Se Tabell 6.2.A i Formelsamling. För att beräkna # # p-värdet vid två mothypotes används absolutbesloppet (abs()) och vi tar 1 minus och multiplicear med 2. p_value &lt;- 2*(1 - pnorm(abs(zobs)) ) p_value Hög utbildning 0.6255852 Vi erhåller att \\(p=\\) 0.626. Tolkningen är att givet att andelen högutbildade i populationen skulle vara 40% är sannolikheten 0.63 att observera andelen som observeras eller mer extrem. Data stämmer alltså ganska väl överens med nollhypotesen! Ett beslut på 5% signifikansnivå skulle innebär att vi inte kan förkasta nollhypotesen. Huruvida vi vill fatta ett beslut eller inte beror på målet för analysen. Det finns dock en inbyggd funktion i R för att göra ovanstående analyser, nämligen prop.test(). I funktionen prop.test() anges först antalet lyckade försök (1or) samt det totala antalet försök (1or och 0r). Med argumentet p anges nollhypotesen och med argumentet alternative specificeras mothypotesen. Argumentet conf.level anger konfidensgrad för konfidensintervallet. Slutligen bestämmer argumentet correct kontinuitetsskorrektion ska användas. Vi använder inte kontinuitetskorrektion på denna kurs och sätter denna till FALSE. # Använd funktionen prop.test() för att skapa konfidensintervall utan korrigering edu_analysis &lt;- prop.test(x = k, n = n, p = 0.4, alternative = &quot;two.sided&quot;, conf.level = 0.95, correct = FALSE) edu_analysis 1-sample proportions test without continuity correction data: k out of n, null probability 0.4 X-squared = 0.2381, df = 1, p-value = 0.6256 alternative hypothesis: true p is not equal to 0.4 95 percent confidence interval: 0.3581276 0.4727639 sample estimates: p 0.4142857 Vi börjar med att se på resultatet från hypotesprövningen och upptäcker exakt samma \\(p\\)-värde som förut! Vårt tidigare observerade \\(z\\)-värde, 0.488 erhålls genom att ta roten ur 0.2380952. Vidare är konfidensintervallet mycket likt det tidigare framräknade intervallet. De överensstämmer dock inte exakt, vilket beror på att R använder något en annan formel för konfidensintervallet som har något bättre egenskaper om andelen är nära 0 eller 1 och stickprovet är litet. Låt säg att vi vill hämta värden från analysen som finns i det sparade objektet edu_analysis. Genom att använda str() ser vi vad som finns sparat. Koden nedan illustrerar hur vi kan hämta \\(p\\)-värdet om vi enbart är intresserad av detta. ## List of 9 ## $ statistic : Named num 0.238 ## ..- attr(*, &quot;names&quot;)= chr &quot;X-squared&quot; ## $ parameter : Named int 1 ## ..- attr(*, &quot;names&quot;)= chr &quot;df&quot; ## $ p.value : num 0.626 ## $ estimate : Named num 0.414 ## ..- attr(*, &quot;names&quot;)= chr &quot;p&quot; ## $ null.value : Named num 0.4 ## ..- attr(*, &quot;names&quot;)= chr &quot;p&quot; ## $ conf.int : num [1:2] 0.358 0.473 ## ..- attr(*, &quot;conf.level&quot;)= num 0.95 ## $ alternative: chr &quot;two.sided&quot; ## $ method : chr &quot;1-sample proportions test without continuity correction&quot; ## $ data.name : chr &quot;k out of n, null probability 0.4&quot; ## - attr(*, &quot;class&quot;)= chr &quot;htest&quot; ## [1] 0.6255852 div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Risk med inferens när \\(p\\) är nära 0 eller 1 Om andelen i populationen är nära 0 eller 1 krävs stort stickprov för att inferensen ska bli korrekt! Tumregeln \\(np(1-p)&gt;5\\) fungerar dåligt om andelen i populationen är mycket nära 0 eller 1. Konsekvensen blir för lägre konfidensgrad och ett högre Typ-I fel än i förväg angivet. Vi gör fel oftare! Beträffande konfidensintervall är Wilson score interval, som är det konfidensintervall R använder i prop.test, ett något bättre alternativ än den formeln som vi använder. I de absolut flesta fall har det inget betydelse om vi väljer prop.test() eller intervallet som baseras på normalapproximation. För hypotesprövning finns alternativet att använda ett så kallat exakt binomial-test. Detta test introduceras emellertid inte här utan vi hänvisar till funktionen binom.test() och tillhörande dokumentation. Var som sagt uppmärksam om andelen är nära 0 eller nära 1! Undersök på egen hand med följande app! https://jetty.im.uu.se/shiny/ConfidenceIntervals_prop/ div.yellow{ background-color:#FFFA94; border-radius: 5px; padding: 20px;} Test av andelar eller \\(\\chi^2\\)-test? Ett prop.test() med två-sidig mothypotes är likvärdigt med \\(\\chi^2\\)-test. \\(\\chi^2\\)-statistikan är samma som \\(z\\)-statistikan i kvadrat! Problemet med test av \\(p\\) kan nämligen formuleras som ett goodness-of-fit test med observerade frekvenser (\\(116\\) 1or och \\(164\\) 0or) och under nollhypotesen förväntade frekvenser (\\(np_{H_0}=112\\) 1or och \\(n(1-p_{H_0})=168\\) 0r). Vi illusterar i en tabell: 1or 0or 116 (112) 164 (168) Formeln för \\(\\chi^2\\)-testet går det sedan att tillämpa \\[\\chi^2 = \\sum \\dfrac{(O_i-E_i)^2}{E_i} = \\dfrac{(116-112)^2}{112} + \\dfrac{(164-168)^2}{168}=0.2381\\] vilket i detta fall jämförs med en \\(\\chi^2\\)-fördelning med 1 frihetsgrad. Notera att mothypotesen vid \\(\\chi^2\\)-testet alltid är två-sidig, vilket motiverar användningen av prop.test(). 5.5 Deskription av två binära variabler För två binära kan man välja att analysera dem var för sig eller så är målet att undersöka hur variablerna är relaterade till varandra. Det primära analys verktyget för två binär variabler är table(). 5.6 Tabeller och två binära variabler Även om funktionen table() kan användas vid analys av en enda variabel, så är den framför allt användbar för att skapa korstabeller, dvs analys av två kategorivariabler samtidigt. I table() anges variabeln som ska finnas på raden först, sedan variabeln redovisas. Tabellen som erhålls kallas i fallet med två variabler för tvåvägs-korstabell. Om det går att översätta variablerna i termer av oberoende variabel och beroende variabel, sätts den oberoende variabeln i regel kolumnsvis (x-axel) och den beroende variabeln radvis (y-axel). Vi ska nu beskriva sambandet mellan utbildningsnivå och rökning. Först skapas en korstabell med frekvenser. Baserat på denna skapas sedan en korstabell med andelar. Notera att det kräver en del pusslande, men i gengäld erhålls stor flexibilitet vad gäller den slutliga utformningen av tabellen. # Skapa en variabel smoker som är 1 om rökare och 0 om icke-rökare smoker &lt;- c(0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1, 1,1,1,1,0,0,0,1,0,1,0,1,1,0,0,0,1,1,1,1,0,0,1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,1,0,0,1,1,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1, 1,1,1,1,0,0,0,1,0,1,0,1,1,0,0,0,1,1,1,1,0,0,1) # Korstabulering av edu_bin och smoker (rökning radvis och utbildning kolumnvis) freq_table_edu_smoke &lt;- table(smoker, edu_bin) freq_table_edu_smoke &gt; edu_bin &gt; smoker 0 1 &gt; 0 76 80 &gt; 1 88 36 Vi har en tabell med frekvenser, men för att använda tabellen måste den i regel modifieras. Dels måste rader och kolumner tydligare namnges, dels måste sambandet åskådliggöras bättre om sambandsanalys är syftet. Det är nämligen svårt avläsa samband med enbart frekvenser, därför måste andelar (procent) anges. Precis som tidigare används därför funktionen prop.table() på ett objekt från table(). En två-vägs kortstabell ger nu prop.table() tre möjligheter att beräkna andelar: Andelar baserade på totala antalet (default) Andelar beräknade utifrån radvisa totaler i nämnarna, genom att sätta argumentet margin = 1 Andelar baserade på kolumnvisa totaler i nämnarna, genom sätta argumentet margin = 2. Notera att det är mycket viktigt att välja rätt andelar att beräkna eftersom dessa styr tolkningen av resultaten. Vi illustrerar nu hur andelarna beräknas i R och tolkar dem sen. # Andelar baserat alla table_all &lt;- prop.table(freq_table_edu_smoke) table_all &gt; edu_bin &gt; smoker 0 1 &gt; 0 0.2714286 0.2857143 &gt; 1 0.3142857 0.1285714 # Andelar baserat rader table_row_prop &lt;- prop.table(freq_table_edu_smoke, margin = 1) table_row_prop &gt; edu_bin &gt; smoker 0 1 &gt; 0 0.4871795 0.5128205 &gt; 1 0.7096774 0.2903226 # Andelar baserat kolumner table_column_prop &lt;- prop.table(freq_table_edu_smoke, margin = 2) table_column_prop &gt; edu_bin &gt; smoker 0 1 &gt; 0 0.4634146 0.6896552 &gt; 1 0.5365854 0.3103448 Spendera tid med att tolka de olika tabellerna! För att förenkla tolkningen beskriver vi sambanden i termer av sannolikheter. Den första tabellen visar att av alla i undersökningen är 27.1% icke-rökare och har låg utbildning. Om urvalet är slumpmässigt är detta således en skattning av sannolikheten \\(\\Pr(\\text{Icke-rökare}\\,\\, \\&amp; \\,\\, \\text{Låg utbildning})\\). På motsvarande sätt är 28.6%, 31.4% och 12.9% skattningar av \\(\\Pr(\\text{Icke-rökare}\\,\\, \\&amp; \\,\\, \\text{Hög utbildning})\\), \\(\\Pr(\\text{Rökare}\\,\\, \\&amp; \\,\\, \\text{Låg utbildning})\\) och \\(\\Pr(\\text{Rökare}\\,\\, \\&amp; \\,\\, \\text{Hög utbildning})\\). Huruvida dessa skattningar är relevanta beror på syftet med undersökningen. Den andra tabellen visar, genom att beräkna radprocent, att bland icke-rökarna har 48.7% låg utbildning. Det innebär naturligtvis att bland icke-rökarna har 51.3% hög utbildning. Om urvalet är slumpmässigt är dessa skattningar av \\(\\Pr(\\text{Låg utbildning}|\\text{Icke-rökare})\\) och \\(\\Pr(\\text{Hög utbildning}|\\text{Icke-rökare})\\). På motsvarande sätt har 71% låg utbildning respektive 29% hög utbildning bland rökarna. \\(\\Pr(\\text{Låg utbildning}|\\text{Rökare})\\) och \\(\\Pr(\\text{Hög utbildning}|\\text{Rökare})\\). Vi kan alltså med denna analys jämföra utbildningsnivån bland icke-rökare och rökare. Den tredje tabellen visar, genom att beräkna kolumnprocent, att bland de lågutbildade röker 53.7% medan bland de högutbildade röker 31%. Detta är således skattningar av \\(\\Pr(\\text{Rökare} | \\text{Låg utbildning})\\) respektive \\(\\Pr(\\text{Rökare} | \\text{Hög utbildning})\\). På motsvarande sätt är 46.3% och 69% skattningar av \\(\\Pr(\\text{Icke-rökare}|\\text{Låg utbildning})\\) och \\(\\Pr(\\text{Icke-rökare}|\\text{Hög utbildning})\\). Vi kan konstatera att i stickprovet är andelen rökare större bland lågutbildade än högutbildade. Vilken tabell som redovisas beror således på frågeställningen. Om syftet är att studera om utbildning påverkar benägenheten att röka är det den tredje tabellen den som ska redovisas. Det är då enkelt att jämföra andelarna som röker i respektive utbildningskategori. Vi konstruerar nu en korstabell innehåller både frekvenser och andelar baserade på kolumner och som tydligt beskriver sambandet. Tabellen konstrueras på motsvarande sätt som tidigare med **cbind()*. # Skapa tabell för presentation av analys table_edu_smoke &lt;- cbind(freq_table_edu_smoke[,1], round(100*table_column_prop[,1], 1), freq_table_edu_smoke[,2], round(100*table_column_prop[,2], 1)) colnames( table_edu_smoke ) &lt;- c(&quot;Låg (n)&quot;, &quot;Låg (%)&quot;, &quot;Hög (n)&quot;, &quot;Hög (%)&quot;) rownames( table_edu_smoke ) &lt;- c(&quot;Icke-rökare&quot;, &quot;Rökare&quot;) table_edu_smoke &gt; Låg (n) Låg (%) Hög (n) Hög (%) &gt; Icke-rökare 76 46.3 80 69 &gt; Rökare 88 53.7 36 31 Avslutningsvis, för fullständighetens skull, används funktionen addmargins() på tabellobjektet för att addera marginalsummor till tabellen. Genom att ange 1 adderas en ny rad som innehålla kolumnsummansummor, genom att ange två adderas en ny kolumn till tabellen med radsumman. Anges inget argument adderas både en rad och en kolumn med summor. Nu är vi klara med tabellen! Det som återstår är att exportera den till ett ordbehandlingsprogram eller ett bildspel, men detta beskrivs i ett senare avsnitt. table_edu_smoke_final &lt;- addmargins(table_edu_smoke, 1) rownames( table_edu_smoke_final ) &lt;- c(&quot;Icke-rökare&quot;, &quot;Rökare&quot;, &quot;Summa&quot;) table_edu_smoke_final &gt; Låg (n) Låg (%) Hög (n) Hög (%) &gt; Icke-rökare 76 46.3 80 69 &gt; Rökare 88 53.7 36 31 &gt; Summa 164 100.0 116 100 5.7 Kvantifiering av samband mellan två binära variabler Samband eller beroende mellan två binära variabler kan kvantifieras med olika mått. Ett vanligt sätt är användning av \\(\\chi^2\\)-måttet för att testa om två variabler är oberoende och kan sägas undersöka hur starkt ett samband är. Förutom \\(\\chi^2\\)-måttet finns en rad andra mått för graden av beroende, såsom Lambda-koefficienten, Cramérs V och tetrakorisk korrelation. Dessa mått introduceras inte här, men det kan vara bra att känna till att det finns alternativ till ^2$-måttet. Ofta vill undersökaren dock relatera sambandet till en konkret frågeställning som inte bara handlar om beroende, det vill säga man önskar få en uppfattning av storleken på sambandet. De tre vanligaste måtten på storleken på samband (så kallade effektstorlekar) mellan två binära variabler är: Skillnaden i andelar (absolut jämförelse av andelar): \\[p_{diff} = \\Pr(Y=1|X=1) - \\Pr(Y=0|X=1) = p_1 - p_0\\]. Skillnaden i andelar kan anta värdena \\(-1 \\leq p_{diff} \\leq1\\). Ofta kallat riskdifferens. Skillnaden i andelar är även en skillnad i procentenheter. \\(0\\) indikerar ingen skillnad. Positiva värden indikerar en högre sannolikhet i grupp 1 jämfört med grupp 0. Negativa värden indikerar en lägre sannolikhet i grupp 1 jämfört med grupp 0. Kvoten av andelar (relativ jämförelse av andelar): \\[p_{kvot} = \\dfrac{\\Pr(Y=1|X=1)}{\\Pr(Y=0|X=1)}= p_1/p_0\\]. Kvoten av andelar kan anta värdena \\(0 \\leq p_{kvot} &lt; \\infty\\). Ofta kallat relativ risk. \\(p_{kvot}=1\\) indikerar ingen skillnad mellan grupperna. \\(p_{kvot} &gt;1\\) indikerar en högre sannolikhet i grupp 1 jämfört med grupp 0. \\(p_{kvot} &lt; 1\\) indikerar en lägre sannolikhet i grupp 1 jämfört med grupp 0. Oddskvoten (relativ jämförelse av odds): \\[OR = \\dfrac{Odds(X=1)}{Odds(X=0)}=\\dfrac{\\dfrac{\\Pr(Y=1|X=1)}{1 - \\Pr(Y=1|X=1)}}{\\dfrac{\\Pr(Y=1|X=0)}{1 - \\Pr(Y=1|X=0)}} = \\dfrac{p_1/(1-p_1)}{p_0/(1-p_0)},\\], där oddset för en händelse givet \\(x\\) är definierat som \\[Odds(X=x)=\\dfrac{\\Pr(Y=1|X=x)}{1-(\\Pr(Y=1|X=x)}=\\dfrac{\\Pr(Y=1|X=x)}{\\Pr(Y=0|X=x)}.\\] Oddskvoten kan anta värdena \\(0 \\leq OR &lt; \\infty\\). Ofta kallat oddsratio. \\(OR=1\\) indikerar ingen skillnad mellan grupperna. \\(OR &gt;1\\) indikerar en högre sannolikhet i grupp 1 jämfört med grupp 0. \\(OR &lt; 1\\) indikerar en lägre sannolikhet i grupp 1 jämfört med grupp 0. Notera att ovanstående mått är definierade utifrån populationen. I praktiken använder vi därför motsvarigheterna i stickprovet \\(\\hat{p_1}=k_1/n_1\\) och \\(\\hat{p_0}=k_0/n_0\\), där \\(k_1\\) och \\(k_0\\) är antalet lyckade försök (1or) i respektive \\(x\\)-kategori och \\(n_1\\) och \\(n_0\\) är antalet försök i respektive \\(x\\)-kategori. Vilket av dessa tre mått som är mest relevant att presentera beror på syftet med undersökningen och ofta bör åtminstone både ett absolut mått och ett relativt mått presenteras. Måste man göra en indelning kan absoluta jämförelser av andelar ofta (men inte alltid!) vara mest policy-relevant eftersom måttet kan tolkas som en skillnad i procenheter mellan två stycken grupper. Däremot kan en relativ jämförelse av andelar uppfattas som mer relevant för en enskild individ. Detta beror dock på andra faktorer som populationsstorleken! Eftersom oddskvoten inte är lika enkel att förstå som relativa andelar är det ett mått som i regel främst väljs på grund av studiedesign eller val av statistiska analysmetod. # Beräkna andelen rökare bland högutbildade. Det går även att använda mean( smoker[edu_bin == 1] ) eller table_row_prop[2,2] k1 &lt;- freq_table_edu_smoke[2,2] n1 &lt;- sum(freq_table_edu_smoke[,2]) # Summera antal i kolumn 2, dvs de i kategori 1 phat1 &lt;- k1/n1 # Beräkna andelen rökare bland lågutbildade. Det går även att använda mean( smoker[edu_bin == 0] ) eller table_row_prop[2,1] k0 &lt;- freq_table_edu_smoke[2,1] n0 &lt;- sum(freq_table_edu_smoke[,1]) # Summera antal i kolumn 1, dvs de i kategori 0 phat0 &lt;- k0/n0 # Skillnad i andelar phat_diff &lt;- phat1 - phat0 phat_diff [1] -0.2262405 # kvot av andelar phat_kvot &lt;- phat1/phat0 phat_kvot [1] 0.5783699 # oddskvot orhat &lt;- (phat1/(1-phat1))/((phat0/(1-phat0))) orhat [1] 0.3886364 Tolkningen av dessa tre resultat är: Bland högutbildade röker 22 procentenheter mindre jämfört med lågutbildade. Högutbildade har 100(1 - 0.578)% = 42.2% reducerad sannolikhet (risk) att röka jämfört med lågutbildade. Högutbildade har 100(1 - 0.389)% = 62.1% reducerat odds för att röka jämfört lågutbildade. En pedagogisk poäng skulle vara att vända på analysen, dvs att sätta den kategori som ökar sannolikheten (lågutbildade) som 1 och jämförelsekategorin (högutbildade) som 0. Detta skulle ge följande resultat och tolkning: Bland lågutbildade röker 22 procentenheter fler jämfört med lågutbildade. Lågutbildade har 72.9% ökad sannolikhet att röka jämfört med högutbildade. Lågutbildade har 2.57 gånger större odds för att röka jämfört med lågutbildade. div.yellow{ background-color:#FFFA94; border-radius: 5px; padding: 20px;} Absoluta eller relativa jämförelser av andelar? Anta att 0.2% (2 av 1000) av alla som får Covid-19 dör. Ett studie visar att ett nytt antiviralt läkemedel leder till att endast 0.1% (1 av 1000) dör. Det är en skillnad i dödlighet på endast 0.1 procentenheter, men för individen innebär detta en halverad risk för att dö! Huruvida det är policyrelevant beror dock på hur många man räknar med att drabbas. Låt säg att bara 10 000 drabbas av Covid-19, då skulle läkemedlet rädda 10 liv. Skulle däremot 1 miljon få Covid-19 då skulle läkemedlet potentiellt rädda 10 000 liv. Anta att arbetsförmedlingen introducerar ett nytt åtgärdsprogram riktat mot gymnasieungdomar som riskerar att inte slutföra gymnasieskolan. Bland eleverna som deltar i programmet kommer 90% få slutbetyg, medan i kontrollgrupp får 70% slutbetyg Det är alltså en skillnad på hela 20 procentenheter. För en individ ökar dock sannolikheten till behörighet med endast 29%. 5.8 Figurer och två binära variabler Relationen mellan tabeller och figurer blir tydlig när man skapar diagram. Återigen tillämpas barplot() på tabellobjekten. Med freq_table_edu_smoke skapas ett stapeldiagram som redovisar antalet i respektive kategori. Vad denna figur visar är att det finns fler lågutbildade än högutbildade. Dessutom relaterar diagrammet direkt till frekvenserna i varje cell i tabellen. Denna figur är kan vara användbar i en del fall, men ofta blir det svårt att utläsa samband. Med table_row_prop blir figuren meninglös eftersom andelen lågutbildade är mer än 1! Med table_col_prop ges en tydlig bild av om andelen rökare inom respektive utbildning. Om vi däremot önskar få någon uppfattning om hur många som finns i respektive utbildningskategori ger denna figur ingen information. Vi illusterar nedan. För fullständighetens finns även argumentet legend med i koden. En legend i R är en förklaring av komponenterna i figuren Prova kör de olika figurerna nedan och relatera till koden. barplot(freq_table_edu_smoke) barplot( freq_table_edu_smoke, # Tabellen names.arg = c(&quot;Låg utbildning&quot;, &quot;Hög utbildning&quot;), # Ge namn till staplarna ylab = &quot;Andel&quot;, # Namn till y-axeln legend = c(&quot;Icke-rökare&quot;, &quot;Rökare&quot;), # Namn till färgerna args.legend = c(y = 190, horiz = TRUE, bty =&#39;n&#39;)) # Ställa in position, horisontell, samt ta bort # kantlinje i legend. barplot( table_row_prop, names.arg = c(&quot;Låg utbildning&quot;, &quot;Hög utbildning&quot;), ylab = &quot;Andel&quot;, legend = c(&quot;Icke-rökare&quot;, &quot;Rökare&quot;), args.legend = c(y = 1.4, horiz = TRUE, bty =&#39;n&#39;)) barplot( table_column_prop, names.arg = c(&quot;Låg utbildning&quot;, &quot;Hög utbildning&quot;), ylab = &quot;Andel&quot;, legend = c(&quot;Icke-rökare&quot;, &quot;Rökare&quot;), args.legend = c(y = 1.2, horiz = TRUE, bty =&#39;n&#39;)) Anta att syftet är att studera andelen rökare inom respektive utbildningskategori och vi väljer därför figuren som baseras på table_column_prop. Med argumentet beside och placering av staplarna bredvid varandra kan sambandet eventuellt tydligare åskådliggöras. Alternativt skapas ett stapeldiagram baserad på enbart rad 2 från tabellen, dvs andelen rökare i respektive kategori. barplot( table_column_prop, beside=TRUE, names.arg = c(&quot;Låg utbildning&quot;, &quot;Hög utbildning&quot;), ylab = &quot;Andel&quot;, legend = c(&quot;Icke-rökare&quot;, &quot;Rökare&quot;), args.legend = c(y = 0.8, horiz = TRUE, bty =&#39;n&#39;)) barplot( table_row_prop[2,], names.arg = c(&quot;Låg utbildning&quot;, &quot;Hög utbildning&quot;), ylab = &quot;Andel rökare&quot;) div.burly{ background-color:#EAF2F8; border-radius: 5px; padding: 20px;} Tips för ytterligare modifering av stapeldiagram Varför inte unyttja den funktionalitet som R erbjuder? Den sista figuren är korrekt, men det kan behövas ytterligare modifierng för att få figuren tillräckligt bra vilket enkelt görs i R. Nedan är en illustration för den intresserade. Enklast är att ta färdig kod och modifiera efter eget behov. Om du inte förstår färdig kod, testa att ändra i koden och se vad som händer! Figuren nedan skapas genom att: Vi lägger till procent ovanför staplarna med hjälp av funktionen text(). I denna funktion anges koordinater (x,y) för var texten ska in, där x-koordinaten är staplarnas placering i objektet my_bar och ofta får man testa sig fram. Med argumentet labels bestäms vad som ska stå över staplarna. Funktionen paste används för att sammanfoga numeriska värden och text, i detta fall procenttecknet. Vi ändrar färg på figuren samt gränserna för y-axeln med argumentet ylim. Annars får inte procentsiffrorna plats. Vi använder argument som börjar med cex för att bestämma storlekarna på axlar osv. # Gör om andelar till procent percentages_smoker &lt;- round(100*table_row_prop[2,], 1) # Skapa objekt så vi kan hämta information från figurobjekt my_bar &lt;- barplot( percentages_smoker, names.arg = c(&quot;Låg utbildning&quot;, &quot;Hög utbildning&quot;), ylim=c(0,80), col = &quot;lightblue&quot;, border = &quot;lightblue&quot;, ylab = &quot;Röker (%)&quot;, cex.axis = 1.1, cex.lab = 1.1, cex.names=1.1) # Lägg till text i figuren text(x = my_bar, # x-koordinat för placering av text y = percentages_smoker + 6, # y-koordinat för placering av test labels = paste(percentages_smoker, &quot;%&quot;, sep=&quot;&quot;), # Text cex = 1.1) # Storlek på text 5.9 Inferens för två binära variabler Anta nu att målet är generalisera analyserna av stickprovet till en population. Vi vill nu göra inferens för skillnaden i populationsandelar \\(p_1\\) och \\(p_0\\) i två population. Vi drar två oberoende OSU. Givet att förutsättningarna för normalapproximation håller ges ett konfidensintervall av: \\[\\hat{p_1} - \\hat{p_0}\\pm z_{\\alpha/2}\\sqrt{\\dfrac{\\hat{p_1}(1-\\hat{p_1})}{n_1} + \\dfrac{\\hat{p_0}(1-\\hat{p_0})}{n_0}}\\] Konfidensintervallet kan beräknas antingen med prop.test() eller genom att implementera formeln ovan. # Version 1 x0 &lt;- freq_table_edu_smoke[2,1] x1 &lt;- freq_table_edu_smoke[2,2] n0 &lt;- sum(freq_table_edu_smoke[,1]) n1 &lt;- sum(freq_table_edu_smoke[,2]) resultat &lt;- prop.test(c(x1, x0), c(n1, n0), correct = FALSE) p_differens &lt;- resultat$estimate[1] - resultat$estimate[2] p_diff_KI_resultat &lt;- resultat$conf.int p_differens prop 1 -0.2262405 p_diff_KI_resultat [1] -0.3398732 -0.1126079 attr(,&quot;conf.level&quot;) [1] 0.95 # Version 2 phat1 &lt;- mean(smoker[edu_bin == 1]) phat0 &lt;- mean(smoker[edu_bin == 0]) n1 &lt;- sum(edu_bin == 1) n0 &lt;- sum(edu_bin == 0) phatdiff &lt;- phat1 - phat0 vhat_pdiff &lt;- phat1*(1-phat1)/n1 + phat0*(1-phat0)/n0 alpha &lt;- 0.05 z_alpha &lt;- qnorm(1 - alpha/2) ll &lt;- phat_diff - z_alpha*sqrt(vhat_pdiff) ul &lt;- phat_diff + z_alpha*sqrt(vhat_pdiff) p_diff_KI &lt;- c(ll, ul) phatdiff [1] -0.2262405 p_diff_KI [1] -0.3398732 -0.1126079 # Kolla förutsättningarna! phat1*(1-phat1)*n1 [1] 24.82759 phat0*(1-phat0)*n0 [1] 40.78049 Tolkningen av resultaten kan skrivas på olika sätt. Nedan är två alternativ: Bland högutbildade röker 22 procentenheter mindre jämfört med lågutbildade. Med 95% säkerhet finns mellan 34 och 11 procenheter mindre rökare bland högutbildade jämfört med lågutbildade. Skillnaden i andelen som röker bland högutbildade jämfört med lågutbildade är -0.22 (95% KI: -0.33; -11%). Litar vi på resultaten? Detta bygger på två förutsättningar, OSU (som vi vet från designen) samt att normalapproximationen (vilket vi undersöker i stickprovet) fungerar. Bägge försättningarna är uppfyllda! Anta att syftet inte är att skatta skillnaden i andelen som röker, utan att frågan snarare är huruvida man röker i samma utsträckning oavsett utbildningsnivå. Då kan vi istället genomföra hypotesprövning och testa \\(H_0: p_1 = p_0\\) mot en två-sidig mothypotes, \\(H_0: p_1 \\neq p_0\\) andvänds test-funktionen \\[ z = \\dfrac{\\hat{p}_1 - \\hat{p}_0}{\\hat{p}_{pool}(1- \\hat{p}_{pool})\\left(\\dfrac{1}{n_1} + \\dfrac{1}{n_0}\\right)}\\] där \\[\\hat{p}_{pool} = \\dfrac{n_1\\hat{p}_1 + n_0 \\hat{p}_0}{n_1 + n_0}\\]. Testfunktionen är \\(N(0,1)\\) om nollhypotesen är sann om vi har OSU och om normalapproximation gäller (\\(n_1p_1(1-p_1) &gt; 5\\) och \\(n_0p_0(1-p_0) &gt; 5\\)). Nedan jämförs två likvärdiga alternativ att i R genomföra ovanstående test av andelar. Det första alternativet är att använda prop.test(). Funktionen används på samma sätt som för konfidensintervall och vi använder därför resultatet från förut. Det andra alternativet är att implementera formeln ovan och beräkna \\(p\\)-värdet. # Version 1 (hämta resultat från prop.test()) resultat 2-sample test for equality of proportions without continuity correction data: c(x1, x0) out of c(n1, n0) X-squared = 14.095, df = 1, p-value = 0.0001738 alternative hypothesis: two.sided 95 percent confidence interval: -0.3398732 -0.1126079 sample estimates: prop 1 prop 2 0.3103448 0.5365854 resultat$p.value [1] 0.0001738371 # Version 2 pooled_phat &lt;- (n1*phat1 + n0*phat0)/(n1 + n0) z &lt;- (phat1 - phat0)/sqrt(pooled_phat*(1-pooled_phat)*(1/n1 + 1/n0)) p_value &lt;- 2*(1 - pnorm(abs(z))) p_value [1] 0.0001738371 De två \\(p\\)-värden är samma och tolkas som att givet att andelen rökare är lika stor i bägge utbildningskategorier i populationen så är det 0.0002 sannolikhet att hitta en så stor skillnad i andelar eller större som vi erhållit. Data stämmer alltså inte alls väl överens med nollhypotesen om ingen skillnad! Det går även att genomföra en ensidig hypotesprövning. Anta att vi vill testa \\(H_0: p_0 = p_1\\) vs \\(H_1: p_1 &lt; p_0\\), dvs om andelen rökare mindre bland högutbildade än bland lågutbildade. Vi måste nu prop.test() ange att mothypotesen är mindre än. För testet baserat på formeln ändras inte \\(z\\)-värdet, däremot hur \\(p\\)-värdet beräknas. # Version 1 resultat_less &lt;- prop.test(c(x1, x0), c(n1, n0), alternativ = &quot;less&quot;, correct = FALSE) resultat_less 2-sample test for equality of proportions without continuity correction data: c(x1, x0) out of c(n1, n0) X-squared = 14.095, df = 1, p-value = 8.692e-05 alternative hypothesis: less 95 percent confidence interval: -1.000000 -0.130877 sample estimates: prop 1 prop 2 0.3103448 0.5365854 # Version 2 pnorm(z) [1] 8.691855e-05 Vi får ett mycket lågt \\(p\\)-värde (\\(p&lt;0.001\\)) som säger oss att givet att andelen rökare är lika stor i bägge utbildningskategorier i populationen så är det 0.00008 sannolikhet att finna att högutbildade röker i så mycket mindre utsträckning eller ännu mindre jämfört med lågutbildade. Data stämmer alltså inte alls väl överens med nollhypotesen om ingen skillnad! Ett annat sätt att generellt testa samband mellan binära variabler är att genomföra test för oberoende. En vanlig meted för att testa detta är \\(\\chi^2\\)-metoden, som testar hypoteserna: \\(H_0\\): Det finns inget samband mellan variablerna (oberoende) \\(H_1\\): Det finns ett samband mellan variablerna (beroende) Notera att mothypotesens riktning är ospecificerad! För att genomföra ett \\(\\chi^2\\)-test används test-statistikan \\[\\chi^2 = \\dfrac{\\sum_{i=1}^r\\sum_{j=1}^k\\left(O_{ij} - E_{ij}\\right)^2}{E_{ij}},\\] vilken är \\(\\chi^2\\)-fördelad med \\((r-1)(k-1)\\) frihetsgrader, där \\(r\\) är antal rader och \\(k\\) är antal kolumner i tabellen. För att implementera testet i R används i regel chisq.test() på ett tabell-objekt. Nedan illustreras också hur man genom att tillämpa formeln ovan kan genomföra ett \\(\\chi^2\\)-test. Det framräknade \\(\\chi^2\\)-värdet används sedan i pchisq() för ett erhålla \\(p\\)-värdet. # Version 1. Använder ej kontinuitetskorrekation eftersom resultat_chisq &lt;- chisq.test( freq_table_edu_smoke, correct = FALSE ) resultat_chisq Pearson&#39;s Chi-squared test data: freq_table_edu_smoke X-squared = 14.095, df = 1, p-value = 0.0001738 # Version 2 # Observerade frekvenser Oij &lt;- freq_table_edu_smoke full_table &lt;- addmargins(Oij) # Beräkna förväntade frekvenser och skapa en matris Eij med sådana totalsumma &lt;- full_table[3,3] radsummor &lt;- full_table[3, c(1,2)] kolsummor &lt;- full_table[c(1,2), 3] Eij &lt;- matrix(NA, 2, 2) Eij[1,1] &lt;- kolsummor[1]*radsummor[1]/totalsumma Eij[2,1] &lt;- kolsummor[2]*radsummor[1]/totalsumma Eij[1,2] &lt;- kolsummor[1]*radsummor[2]/totalsumma Eij[2,2] &lt;- kolsummor[2]*radsummor[2]/totalsumma # Beräkna teststatistikan X2obs &lt;- sum( (Oij - Eij)^2/Eij ) fg &lt;- (dim(Eij)[1] - 1)*(dim(Eij)[2] - 1) #(r-1)*(k-1) frihetsgrader ## pchisq ger vänstersvanssannolikhet i en chitvå-fördelning med df- frihetsgrader p_value &lt;- 1 - pchisq(X2obs, df = fg) p_value [1] 0.0001738371 # Undersök förutsättningarna. Med any() kan vi kolla om något element i matrisen är mindre än 5 check_assumptions &lt;- any(Eij &lt; 5) check_assumptions [1] FALSE Vi erhåller samma \\(p\\)-värde som när vi testade för skillnad av andelar i fallet med två-sidig mothypotes. \\(\\chi^2\\)-metoden kan alltså användas för att testa andelar, men testet är också ett mer generellt test för oberoende. Om två binära varaiabler är beroende, så är de beroende oavsett val av effektstorlek, eärför kan vi använda \\(\\chi^2\\)-metoden även för \\(p_{kvot}\\) och \\(OR\\). 5.10 Övningar Övning 5.1 En undersökning ville testa jämföra andelen vänsterhänta bland män och kvinnor. I studien drogs ett OSU av med 30 kvinnor varav 6 var vänsterhänta samt ett OSU med 29 män varav 4 är vänsterhänta. Är andelen vänsterhänta mellan kvinnor och män samma? Redovisa p-värdet som du erhåller från ett test av nollhypotesen. Tolka resultatet. Visa svar rm(list=ls()) x_f &lt;- 6 n_f &lt;- 30 x_m &lt;- 4 n_m&lt;- 29 prop.test(c(x_f,x_m), c(n_f, n_m), correct = FALSE) &gt; Warning in prop.test(c(x_f, x_m), c(n_f, n_m), correct = FALSE): Chi- &gt; squared approximation may be incorrect &gt; &gt; 2-sample test for equality of proportions without continuity &gt; correction &gt; &gt; data: c(x_f, x_m) out of c(n_f, n_m) &gt; X-squared = 0.40357, df = 1, p-value = 0.5252 &gt; alternative hypothesis: two.sided &gt; 95 percent confidence interval: &gt; -0.1282953 0.2524333 &gt; sample estimates: &gt; prop 1 prop 2 &gt; 0.200000 0.137931 # Undersök om de förväntade frekvenserna är större än 5 i alla celler freq_table &lt;- as.table( matrix( c(6, 24, 4, 25), 2, 2) ) test &lt;- chisq.test(freq_table, correct = FALSE) &gt; Warning in chisq.test(freq_table, correct = FALSE): Chi-squared &gt; approximation may be incorrect test &gt; &gt; Pearson&#39;s Chi-squared test &gt; &gt; data: freq_table &gt; X-squared = 0.40357, df = 1, p-value = 0.5252 test$expected &gt; A B &gt; A 5.084746 4.915254 &gt; B 24.915254 24.084746 \\(\\chi^2\\)-testet går alltså inte att använda! Förutsättningen om förväntade frekvenser större än 5 i alla celler är inte uppfylld. Det finns alternativa test som Fishers exakta test, men dessa ingår inte på kursen. Övning 5.2 Raghubir &amp; Srivastava (2009) undersökte effekten av storleken på sedlar och mynt på i vilken utsträckning pengarna används. Ett experiment genomfördes där 46 studenter fick en endollarssedel och 43 stycken studenter fick 4 stycken amerikanska 25 cents mynt, så kallade quarters. Studenterna fick sedan välja mellan att spara pengarna eller spendera dem på tuggummi och mintpastiller. Nedan redovisas en sammanfattning av studien. 1 dollar sedel 4 quarters Spenderade pengarna 12 27 Sparade pengarna 34 16 Skapa en tabell som deskriptivt redovisar sambandet Skapa en figur som deskriptivt redovisar sambandet Skatta skillnaden i andelar som spenderar pengar tillsammans med tillhörande 90% konfidensintervall. Beräkna \\(p\\)-värdet om givet att det inte finns någon skillnad mellan grupperna vad gäller andelen som spenderar pengarna. Ge en utförlig tolkning av resultaten. Litar du på resultaten? Är förutsättningarna uppfyllda? Visa svar rm(list=ls()) # a) freq_table &lt;- as.table( matrix( c(12, 34, 27, 16), 2, 2)) colnames(freq_table) &lt;- c(&quot;1 endollarsedel&quot;, &quot;4 quarters&quot;) rownames(freq_table) &lt;- c(&quot;Spenderade pengarna&quot;, &quot;Sparade pengarna&quot;) prop_table &lt;- prop.table(freq_table, 2) table_bill_spending &lt;- cbind(freq_table[,1], round(100*prop_table[,1], 1), freq_table[,2], round(100*prop_table[,2], 1)) colnames(table_bill_spending) &lt;- c(&quot;1 endollarsedel (n)&quot;, &quot;1 dollarsedel (%)&quot;, &quot;4 quarters (n)&quot;, &quot;4 quarters (%)&quot;) rownames(table_bill_spending) &lt;- c(&quot;Spenderade pengarna&quot;, &quot;Sparade pengarna&quot;) table_bill_spending 1 endollarsedel (n) 1 dollarsedel (%) 4 quarters (n) Spenderade pengarna 12 26.1 27 Sparade pengarna 34 73.9 16 4 quarters (%) Spenderade pengarna 62.8 Sparade pengarna 37.2 # b) percentages_spending&lt;- round(100*prop_table[1,], 1) my_bar &lt;- barplot( percentages_spending, names.arg = c(&quot;1 dollarsedel&quot;, &quot;4 quarters&quot;), ylim=c(0,80), col = &quot;lightblue&quot;, border = &quot;lightblue&quot;, ylab = &quot;Spenderade pengarna (%)&quot;) text(x = my_bar, y = percentages_spending + 6, labels = paste(percentages_spending, &quot;%&quot;, sep=&quot;&quot;)) # c) # Version 1 x1 &lt;- freq_table[1,1] x0 &lt;- freq_table[1,2] n1 &lt;- sum(freq_table[,1]) n0 &lt;- sum(freq_table[,2]) resultat &lt;- prop.test(c(x1, x0), c(n1, n0), conf.level = 0.9, correct = FALSE) p_differens &lt;- resultat$estimate[1] - resultat$estimate[2] p_differens_KI &lt;- resultat$conf.int p_differens prop 1 -0.3670374 p_differens_KI [1] -0.5284105 -0.2056644 attr(,&quot;conf.level&quot;) [1] 0.9 # Version 2 p1hat &lt;- x1/n1 p0hat &lt;- x0/n0 p_diff &lt;- p1hat - p0hat vp_diff &lt;- p1hat*(1-p1hat)/n1 + p0hat*(1-p0hat)/n0 alpha &lt;- 0.1 z_alpha &lt;- qnorm(1 - alpha/2) ll &lt;- p_diff - z_alpha*sqrt(vp_diff) ul &lt;- p_diff + z_alpha*sqrt(vp_diff) p_diff_KI &lt;- c(ll, ul) p_diff [1] -0.3670374 p_diff_KI [1] -0.5284105 -0.2056644 # d) # Version 1 p_value_p_differens &lt;- resultat$p.value p_value_p_differens [1] 0.0004877499 # Version 2 pooled_phat &lt;- (n1*p1hat + n0*p0hat)/(n1 + n0) zobs &lt;- (p1hat - p0hat)/sqrt(pooled_phat*(1-pooled_phat)*(1/n1 + 1/n0)) p_value_p_diff &lt;- 2*(1 - pnorm(abs(zobs))) p_value_p_diff [1] 0.0004877499 Se formuleringar ovan om andelar, differens av andelar, KI och p-värde. OSU (experiment) och normalapproximation gäller. Jag litar på resultaten. Övning 5.3 Rosa et al. (1998) undersökte om en typ av ‘’healers’’ hade förmåga att känna mänskliga kroppars så kallade energifält. Forskarna besökte en mässa för alternativmedicin och gjorde där ett experiment som gick ut på att healers skulle identifiera om undersökarens vänstra eller högre hand var närmst healern. Händerna var dolda under ett tygstycke. Totalt genomfördes 130 försök och av dessa lyckades healers identifera rätt hand 53 gånger. Undersök det finns belägg för denna förmåga bland healers. Tolka resultatet! Visa svar rm(list=ls()) # Version 1 x &lt;- 53 n &lt;- 130 resultat &lt;- prop.test(53, 130, p = 0.5, correct = FALSE) p_value &lt;- resultat$p.value p_value [1] 0.0352966 # Version 2 phat &lt;- x/n pH0 &lt;- 0.5 z &lt;- (phat - 0.5)/sqrt(pH0*(1-pH0)/n) p_value_v2 &lt;- 2*pnorm(z) p_value_v2 [1] 0.0352966 Givet att healers inte är bättre än slumpen, dvs \\(H_0: p = 0.5\\), så är sannolikheten \\(p=0.035\\) att observera ett så extremt värde som det studien ger. Hur tolkar vi detta rent praktiskt? För det första ser vi att om det vore så att det skulle finnas en förmåga så verkar det snarare vara i negativ riktning, dvs att healers presterar sämre än slumpen. För det andra är detta ett exempel på hur man inte ska förlita sig på enskilda studier och hypotesprövning allena. \\(p\\)-värdet är inte särskilt lågt och det är rimligt att tro att resultat helt enkelt är ett slumpfynd och att healers presterar varken bättre eller sämre än slumpen. Övning 5.4 Gerritsen et al. (1998) ville jämföra kiurgi med spjälning av handleden för att hantera det som kallas karpaltunnelsyndrom, dvs smärta till följd av att nerver kläms i handleden. Du erhåller följande datamaterial från studien. df &lt;- data.frame(treatment = c(rep(&quot;splint&quot;, 60), rep(&quot;splint&quot;, 23), rep(&quot;surgery&quot;, 67), rep(&quot;surgery&quot;, 6)), y = c(rep(&quot;succesful&quot;, 60), rep(&quot;unsucsessful&quot;,23), rep(&quot;succesful&quot;, 67), rep(&quot;unsucsessful&quot;,6))) Undersökarna vill beräkna kvoten av andelar lyckade behandlingar (relativ risk), där spjälning är referensgrupp. Eftersom forskarna vill fatta beslut vill man att en hypotesprövning genomförs på 5% signifikansnivå. Visa svar rm(list=ls()) df &lt;- data.frame(treatment = c(rep(&quot;splint&quot;, 60), rep(&quot;splint&quot;, 23), rep(&quot;surgery&quot;, 67), rep(&quot;surgery&quot;, 6)), y = c(rep(&quot;succesful&quot;, 60), rep(&quot;unsucsessful&quot;,23), rep(&quot;succesful&quot;, 67), rep(&quot;unsucsessful&quot;,6))) freq_table &lt;- table(df$y, df$treatment) prop_table &lt;- prop.table(freq_table, 2) phat_splint &lt;- prop_table[1,1] phat_surgery &lt;- prop_table[1,2] p_kvot &lt;- phat_surgery/phat_splint resultat &lt;- chisq.test(freq_table, correct = FALSE) p_kvot [1] 1.269635 resultat$p.value [1] 0.001792853 En patient har 27% (p = 0.002) större chans till lyckad behandling om patienten genomgår kirurgi istället för behandling. Eftersom \\(p&lt;0.05\\) förkastar vi på 5% signifikansnivå nollhypotesen om att kirurgi och spjälning är lika effektiva. Övning 5.5 En sjuksköterska är anklagad för att ha mördat ett antal patienter. Som bevis jämför man dödligheten på skift där den anklagade har arbetat med skift där den anklagade inte har arbetat. Anta nu att du är domare i det aktuella fallet. Ladda in nedanstående tabell. Ställ upp en nollhypotes och analysera data och bilda dig en uppfattning om den anklagade är oskyldig. accused &lt;- c(rep(&quot;accused was working&quot;, 40), rep(&quot;accused was working&quot;, 217), rep(&quot;accused was not working&quot;, 34), rep(&quot;accused was not working&quot;, 1350)) death &lt;- c(rep(&quot;shifts with a death&quot;, 40), rep(&quot;shifts without a death&quot;,217), rep(&quot;shifts with a death&quot;, 34), rep(&quot;shifts without a death&quot;, 1350)) table(accused, death) Visa svar rm(list=ls()) accused &lt;- c(rep(&quot;accused was working&quot;, 40), rep(&quot;accused was working&quot;, 217), rep(&quot;accused was not working&quot;, 34), rep(&quot;accused was not working&quot;, 1350)) death &lt;- c(rep(&quot;shifts with a death&quot;, 40), rep(&quot;shifts without a death&quot;,217), rep(&quot;shifts with a death&quot;, 34), rep(&quot;shifts without a death&quot;, 1350)) freq_table &lt;- table(accused, death) freq_table death accused shifts with a death shifts without a death accused was not working 34 1350 accused was working 40 217 resultat &lt;- chisq.test(freq_table) resultat$p.value [1] 6.489411e-20 Givet att det finns det inte skiljer sig åt mellan den anklagades skift och andras skift är det mycket liten sannolikhet att observera så många döda som vi observerar eller mer extremt ($p &lt; 0.001). Kristen Gilbert var en amerikansk sjuksköterska som fick smeknamnet “Angel Death” efter ett antal misstänkta dödsfall på psykiatriska avdelningar där hon arbetade. Hon blev så småningom dömd för mord och avtjänar numera livstids fängelsestraff utan möjlighet till benådning. Det är mycket viktigt att komma ihåg vad en jämförelse innebär. Ett litet \\(p\\)-värde tyder på något avvikande Ett litet \\(p\\)-värde talar inte om VARFÖR det avviken. För detta krävs antaganden. Till exempel randomiserades inte Gilbert till avdelningarna. Låt säg att ventilationen på hennes skift alltid var sämre, med högre partikelhalter. Då skulle detta vara orsaken. För att vara säker på att det är Gilbert som orsakat dödsfallen krävs att vissa förutsättningar är uppfyllda, t ex att skiften är slumpmässigt tilldelade. Domstolen beaktade därför inte statistiken som bevis. Vad som skedde var dock att statistiken avslöjade ett mönster som gjorde att man undersökte fallen ytterligare och därför kunde gripa Gilbert. Den intresserade kan läsa här om hur statistiken användes i just detta fall: http://www.stat.ucla.edu/~nchristo/statistics100B/article.pdf Övning 5.6 En studie 1980 undersökte homosexuellas situation Sverige. En del av denna studie utgjordes bland annat en enkätundersökning. Ladda ner Lilla Enkäten som är txt-fil som finns i zip-filen “Enkäterna i csv-format” på https://riksarkivet.se/psidata/livet-som-gay. Utgå från att data är insamlat med OSU och besvara sedan följande frågor: Har den svarande själv talat om för någon heterosexuell bekant (som inte bara är arbetskamrat) att den svarande är homo/bisexuell? Variabeln heter TALAT_OM. Finns ett samband mellan kön (KOEN) och fråga a)? Undersök samband mellan att känna skam eller ångest (SKAM) och TALAT_OM? Redovisa bortfall. Redovisa en figur. Visa svar rm(list=ls()) df &lt;- read.csv2(&quot;data/Lilla_enkaeten.txt&quot;) # Undersök variabeln och variabelkategorierna summary(df$TALAT_OM) &gt; Ja, för en bekant Ja, för flera bakanta &gt; 92 466 &gt; Jag har inga heterosexuella vänner Nej &gt; 8 181 table(df$TALAT_OM, useNA = &quot;ifany&quot;) &gt; &gt; Ja, för en bekant Ja, för flera bakanta &gt; 92 466 &gt; Jag har inga heterosexuella vänner Nej &gt; 8 181 # Skapar en tom variabel och koda sedan alla nej till 1 och övriga till 0 df$EJ_TALAT_OM_bin &lt;- NA df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Ja, för en bekant&quot;] &lt;- 0 df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Ja, för flera bakanta&quot;] &lt;- 0 df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Jag har inga heterosexuella vänner&quot;] &lt;- 0 df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Nej&quot;] &lt;- 1 # a) freq_table_EJ_TALAT_OM &lt;- table(df$EJ_TALAT_OM_bin) x &lt;- freq_table_EJ_TALAT_OM[2] n &lt;- sum(freq_table_EJ_TALAT_OM) resultat_1 &lt;- prop.test(x, n, correct = FALSE) resultat_1 &gt; &gt; 1-sample proportions test without continuity correction &gt; &gt; data: x out of n, null probability 0.5 &gt; X-squared = 198.43, df = 1, p-value &lt; 2.2e-16 &gt; alternative hypothesis: true p is not equal to 0.5 &gt; 95 percent confidence interval: &gt; 0.2129447 0.2742972 &gt; sample estimates: &gt; p &gt; 0.2423025 # b) # Undersök variabeln kön summary(df$KOEN) &gt; Kvinna Man &gt; 34 713 table(df$KOEN, useNA = &quot;ifany&quot;) &gt; &gt; Kvinna Man &gt; 34 713 # Skapa en korstabell av kön och ej talat om freq_table_KOEN_EJ_TALAT_OM &lt;- table(df$EJ_TALAT_OM_bin, df$KOEN) x1 &lt;- freq_table_KOEN_EJ_TALAT_OM[2,1] x0 &lt;- freq_table_KOEN_EJ_TALAT_OM[2,2] n1 &lt;-sum(freq_table_KOEN_EJ_TALAT_OM[,1]) n0 &lt;-sum(freq_table_KOEN_EJ_TALAT_OM[,2]) p1hat &lt;- x1/n1 p0hat &lt;- x0/n0 resultat_KOEN_EJ_TALAT_OM &lt;- prop.test(c(x1,x0), c(n1, n0), correct = FALSE) resultat_KOEN_EJ_TALAT_OM &gt; &gt; 2-sample test for equality of proportions without continuity &gt; correction &gt; &gt; data: c(x1, x0) out of c(n1, n0) &gt; X-squared = 3.0149, df = 1, p-value = 0.0825 &gt; alternative hypothesis: two.sided &gt; 95 percent confidence interval: &gt; -0.24344443 -0.01775514 &gt; sample estimates: &gt; prop 1 prop 2 &gt; 0.1176471 0.2482468 # Kolla förutsättningarna n1*p1hat*(1-p1hat) &gt; [1] 3.529412 n0*p0hat*(1-p0hat) &gt; [1] 133.0603 # c) # Undersök variabeln summary(df$SKAM) &gt; 9 Ja Nej &gt; 10 344 393 table(df$SKAM, useNA = &quot;ifany&quot;) &gt; &gt; 9 Ja Nej &gt; 10 344 393 # Skapa en korstabell df$skam_bin &lt;- NA df$skam_bin[df$SKAM == &quot;Ja&quot;] &lt;- 1 df$skam_bin[df$SKAM == &quot;Nej&quot;] &lt;- 0 df$skam_bin[df$SKAM == 9] &lt;- NA freq_table_ej_talat_om_skam &lt;- table( df$EJ_TALAT_OM_bin, df$skam_bin) colnames(freq_table_ej_talat_om_skam) &lt;- c(&quot;Ej skam&quot;, &quot;Skam&quot;) rownames(freq_table_ej_talat_om_skam) &lt;- c(&quot;Ej talat om&quot;, &quot;Talat om&quot;) prop_table_ej_talat_om_skam &lt;- prop.table(freq_table_ej_talat_om_skam, 2) barplot( prop_table_ej_talat_om_skam[2,], names.arg = c(&quot;Ej skam&quot;, &quot;Skam&quot;), ylab = &quot;Andel som tala om&quot;) x1_2 &lt;- freq_table_ej_talat_om_skam[2,2] x0_2 &lt;- freq_table_ej_talat_om_skam[2,1] n1_2 &lt;- sum(freq_table_ej_talat_om_skam[,2]) n0_2 &lt;- sum(freq_table_ej_talat_om_skam[,1]) p1hat_2 &lt;- x1_2/n1_2 p0hat_2 &lt;- x0_2/n0_2 p_kvot &lt;- p1hat_2/p0hat_2 p_kvot &gt; [1] 0.9877362 resultat_2 &lt;- prop.test(c(x1_2, x0_2), c(n1_2, n0_2), correct = FALSE) Notera att förutsättningen är ej uppfylld för sambandsanalysen. Vi kan inte lita på testet. 10 värden är kodade som 9, som förmodligen vet ej eller bortfall. Vi sätter dem som NA. Dessa exkuderas ur analysen. 5.11 Referenser Gerritsen, A. A., De Vet, H. C., Scholten, R. J., Bertelsmann, F. W., De Krom, M. C., &amp; Bouter, L. M. (2002). Splinting vs surgery in the treatment of carpal tunnel syndrome: a randomized controlled trial. Jama, 288(10), 1245-1251. Raghubir, P., &amp; Srivastava, J. (2009). The denomination effect. Journal of Consumer Research, 36(4), 701-713 Rosa, L., Rosa, E., Sarner, L., &amp; Barrett, S. (1998). A close look at therapeutic touch. Jama, 279(13), 1005-1010. p.comment { background-color: #DBDBDB; padding: 10px; border: 1px solid black; margin-left: 25px; border-radius: 5px; font-style: italic; } "],
["kategorivariabler-uppdateras.html", "Kapitel 6 Kategorivariabler (uppdateras) 6.1 Deskription av en variabel med fler än två kategorier 6.2 Figurer och en kategorivariabel med fler än 2 kategorier 6.3 Inferens och en kategorivariabel med fler än 2 kategorier 6.4 Övningar 6.5 Referenser", " Kapitel 6 Kategorivariabler (uppdateras) Ofta har vi inte bara binära variabler, utan det finns kategoriervariabler av olika slag som har fler kategorier än två. Kategorivariablerna kan vara antingen på nominal eller ordinalskala. Dessutom kan även heltal och diskreta kvantitativa variabler analyseras som som kategorivariabler. 6.1 Deskription av en variabel med fler än två kategorier Detta avsnitt lämpar sig i regel för variabler med relativt få kategorier, låt säg färre än 10. För analys av variabler med fler kategorier kan alternativa metoder för analys och presentation vara bättre. Notera ordvalet kan eftersom val av presentation och analys måste bedömas från fall till fall. Detta avsnitt utgår från data som används i kapitlet om binära variabler. Nu introduceras variabeln age som består av ålderskategorierna 0 - 65-79 år 1 - 50-64 år 2 - 18-49 år Variabel är på ordinal datanivå, även om den anges som numerisk med kategorierna. Dessusom är kodningen lite märkligt kodad, eftersom det lägsta numeriska värdet korresponderar till den högsta datakategorin. Därför inleder vi med att göra om variabeln till en faktor, med nivåerna i rätt ordning. Därefter ändrar vi namn på kategorierna. Analogt med fallet för binära variabler, skapar vi binära variabler för varje kategori. Det är användbart senare på kursen. # Variabel. Kodad numerisk. # 0 - 65-79 år # 1 - 50-64 år # 2 - 18-49 år age &lt;- c(1, 0, 1, 2, 2, 0, 2, 0, 1, 1, 2, 2, 1, 2, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 2, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 2, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 2, 0, 1, 2, 2, 0, 1, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 2, 1, 0, 2, 1, 2, 2, 0, 1, 1, 2, 0, 1, 2, 1, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 2, 2, 1, 1, 1, 1) # Gör variabel till faktor och ändra ordningen age_cat &lt;- factor(age, levels = c(2, 1, 0)) levels(age_cat)[levels(age_cat) == 0] &lt;- &quot;65-79 år&quot; levels(age_cat)[levels(age_cat) == 1] &lt;- &quot;50-64 år&quot; levels(age_cat)[levels(age_cat) == 2] &lt;- &quot;18-49 år&quot; # Skapa binära variabler för respektive ålderskategori age_1849 &lt;- rep(NA, length(age)) age_1849[age == 0] &lt;- 0 age_1849[age == 1] &lt;- 0 age_1849[age == 2] &lt;- 1 age_5064 &lt;- rep(NA, length(age)) age_5064[age == 0] &lt;- 0 age_5064[age == 1] &lt;- 1 age_5064[age == 2] &lt;- 0 age_6579 &lt;- rep(NA, length(age)) age_6579[age == 0] &lt;- 1 age_6579[age == 1] &lt;- 0 age_6579[age == 2] &lt;- 0 # Vi jämför de tre kodningarna och skapar tabeller på motsvarande sätt som förut. table(age) &gt; age &gt; 0 1 2 &gt; 66 148 66 freq_table_age &lt;- table(age_cat) freq_table_age &gt; age_cat &gt; 18-49 år 50-64 år 65-79 år &gt; 66 148 66 sum(age_1849) &gt; [1] 66 sum(age_5064) &gt; [1] 148 sum(age_6579) &gt; [1] 66 prop.table(table(age)) &gt; age &gt; 0 1 2 &gt; 0.2357143 0.5285714 0.2357143 prop_table_age &lt;- prop.table(freq_table_age ) mean(age_1849) &gt; [1] 0.2357143 mean(age_5064) &gt; [1] 0.5285714 mean(age_6579) &gt; [1] 0.2357143 6.2 Figurer och en kategorivariabel med fler än 2 kategorier Vi använder ett stapeldiagram för att redovisa antal (frekvenser) eller andelar för en kategorivariabel. Om vi har många kategorier är dotchart ett alternativ. Vad man bör har i åtanke när man skapar ett stolpdiagram eller stapeldiagram är att huruvida kategorierna avstånd bör vara korrekt representerade i figuren. Bestå kategorierna av nominal eller ordinalskala är avståndet oviktigt. Är däremot variabeln heltal, år, datum så måste avståndet mellan staplarna stämma överens med kategoriernas avstånd. Dessutom gäller det vara uppmärksam på kategorier som inte har frekvenser. par(mfrow = c(1,2)) # stapeldiagram baserat på tabellen med frekvenser barplot(freq_table_age, ylab = &quot;Antal&quot;, col = &quot;lightblue&quot;, border = &quot;lightblue&quot;) # stapeldiagram baserat på tabellen med andelar percentages_age &lt;- round(100*prop_table_age, 1) my_bar2 &lt;- barplot(percentages_age, ylab = &quot;Procent (%)&quot;, col = &quot;lightblue&quot;, border = &quot;lightblue&quot;, ylim = c(0, 65)) text(x = my_bar2, y = percentages_age + 6, labels = paste(percentages_age, &quot;%&quot;, sep=&quot;&quot;)) # Gör en numerisk variabel med två värden till en faktor. Notera att nivåerna i detta fall inte bestäms # av ordningen i vektorn utan av de numeriska värdens storlek. df &lt;- read.csv2(&quot;data/conscriptiondata.csv&quot;) freq_table_year &lt;- table(df$year) chisq.test(freq_table_year) &gt; &gt; Chi-squared test for given probabilities &gt; &gt; data: freq_table_year &gt; X-squared = 11203, df = 14, p-value &lt; 2.2e-16 6.3 Inferens och en kategorivariabel med fler än 2 kategorier Ett goodness of fit-test (GOF) undersöker om det rimligt att det observerad data stämmer överens med en definierad population. Anta att vi i ett OSU har en kategorivariabeln med \\(k\\) kategorier. Då kan ett sådant test genomföras med teststatistikan \\[\\chi^2 = \\sum_{i=1}^k\\dfrac{ (O_i - E_i)^2}{E_i}= \\dfrac{ (O_1 - E_1)^2}{E_1}+ \\dfrac{ (O_2 - E_2)^2}{E_2}+\\ldots+ \\dfrac{ (O_k - E_k)^2}{E_k}\\] där \\(O_i\\) är antalet observerade frekvenser i kategori \\(i\\) och \\(E_i\\) är antalet förväntade frekvenser, enligt på nollhypotesen, i kategori \\(i\\). Hypoteserna formuleras i detta fall som \\(H_0: p_1 = p_{1,H_0}, p_2 = p_{2,H_0}, \\ldots, p_k = p_{k,H_0}\\) mot \\(H_1:\\) Minst en av andelarna inte överstämmer med värdet under nollhypotesen. Teststatistikan är \\(\\chi^2\\)-fördelad med \\(k-1\\) frihetsgrader givet att nollhypotesen är sann och vi har ett OSU. Dessutom krävs att alla förväntade frekvenser är större än 5. Vi exemplifierar med vår analys av utbildning och rökning. Vi tänker oss att denna studie äger rum i en befolkning där det i det aktuella ålderspannet finns 65% i ålderskategorin 18-49 år, 20% i ålderskategorin 50-64 år och 15% ålderskategorin 65-79 år. Målet är att jämföra stickprovets åldersfördelning med populationen. För att genomföra detta används \\(\\chi^2\\)-metoder i R med funktionen chisq.test(). Eftersom det finns flera kategorier formuleras hypoteserna som \\(H_0: p_1 = 0.95\\) och \\(p_2 = 0.20\\) och \\(p_3 = 0.15\\) mot \\(H_1:\\) Minst en av andelarna inte överstämmer med värdet under nollhypotesen. # Gör en numerisk variabel med två värden till en faktor. Notera att nivåerna i detta fall inte bestäms # Version 1 resultat &lt;- chisq.test(freq_table_age, p = c(0.65, 0.2, 0.15)) resultat$p.value &gt; [1] 1.403291e-52 freq_table_age &gt; age_cat &gt; 18-49 år 50-64 år 65-79 år &gt; 66 148 66 resultat$expected &gt; 18-49 år 50-64 år 65-79 år &gt; 182 56 42 # Version 2 Oi &lt;- freq_table_age pH0 &lt;- c(0.65, 0.20, 0.15) totalsum &lt;- sum(freq_table_age) Ei &lt;- totalsum*pH0 X2obs &lt;- sum( (Oi - Ei)^2/Ei ) fg &lt;- length(pH0) - 1 p_value &lt;- 1 - pchisq(X2obs, 2) Resultatet ger ett mycket lågt \\(p\\)-värde (\\(p&lt;0.001\\)). Tolkningen är att om observerad data är slumpmässigt draget från befolkningen är det mycket låg sannolikhet att observera en så stor skillnad eller större mellan de oberseverade värdena och de förväntade. Data stämmer således inte överens med nollhypotesen. Vad \\(p\\)-värdet inte besvarar är varför överstämmelsen är låg. Det kan till exempel beror på att urvalet inte kommer är OSU. 6.4 Övningar Övning 6.1 En studie av Helsing, K. J., &amp; Comstock, G. W. (1977) undersökte faktorer som kan tänkas ha samband med bilbältesanvändning. Du erhåller följande data från studien. antal_cigaretter &lt;- c(rep(0, 175), rep(0, 149), rep(1, 20), rep(1, 17), rep(2, 42), rep(2, 41), rep(3, 6), rep(3, 9)) bilbalte &lt;- c(rep(0, 175), rep(1, 149), rep(0, 20), rep(1, 17), rep(0, 42), rep(1, 41), rep(0, 6), rep(1, 9)) Beskriv sambandet mellan rökning och bilbältesanvändning med en tabell. Beskriv sambandet mellan rökning och bilbältesanvändning med en figur. Genom ett statistiskt test för att undersöka sambandet mellan rökning och bilbältesanvändning. Genomför ett statistisk test utan att använda någon inbyggd test-funktion i R. Visa svar rm(list=ls()) antal_cigaretter &lt;- c(rep(0, 175), rep(0, 149), rep(1, 20), rep(1, 17), rep(2, 42), rep(2, 41), rep(3, 6), rep(3, 9)) antal_cigaretter_cat &lt;- factor(antal_cigaretter, ordered = TRUE) levels(antal_cigaretter_cat)[levels(antal_cigaretter_cat) == 0] &lt;- &quot;0&quot; levels(antal_cigaretter_cat)[levels(antal_cigaretter_cat) == 1] &lt;- &quot;1-14&quot; levels(antal_cigaretter_cat)[levels(antal_cigaretter_cat) == 2] &lt;- &quot;15-34&quot; levels(antal_cigaretter_cat)[levels(antal_cigaretter_cat) == 3] &lt;- &quot;35-&quot; bilbalte &lt;- c(rep(0, 175), rep(1, 149), rep(0, 20), rep(1, 17), rep(0, 42), rep(1, 41), rep(0, 6), rep(1, 9)) bilbalte_cat &lt;- factor(bilbalte) levels(bilbalte_cat)[levels(bilbalte_cat) == 0] &lt;- &quot;Ja&quot; levels(bilbalte_cat)[levels(bilbalte_cat) == 1] &lt;- &quot;Nej&quot; # a) freq_table &lt;- table(bilbalte_cat, antal_cigaretter_cat) prop.table_cig_belt &lt;- prop.table(freq_table, 2) prop.table_cig_belt &gt; antal_cigaretter_cat &gt; bilbalte_cat 0 1-14 15-34 35- &gt; Ja 0.5401235 0.5405405 0.5060241 0.4000000 &gt; Nej 0.4598765 0.4594595 0.4939759 0.6000000 # b) barplot(prop.table_cig_belt, ylab = &quot;Andel&quot;, legend = c(&quot;Bälte&quot;, &quot;Ej bilbälte&quot;), args.legend = c(y = 1.1, horiz = TRUE, bty =&#39;n&#39;)) # c) chisq.test(freq_table) &gt; &gt; Pearson&#39;s Chi-squared test &gt; &gt; data: freq_table &gt; X-squared = 1.3582, df = 3, p-value = 0.7154 # d) Oij &lt;- freq_table radsummor &lt;- rowSums(freq_table) kolumnsummor &lt;- colSums(freq_table) totalsumma &lt;- sum(freq_table) r &lt;- dim(freq_table)[1] k &lt;- dim(freq_table)[2] Eij &lt;- matrix(NA, r, k) Eij[1,1] &lt;- kolumnsummor[1]*radsummor[1]/totalsumma Eij[1,2] &lt;- kolumnsummor[2]*radsummor[1]/totalsumma Eij[1,3] &lt;- kolumnsummor[3]*radsummor[1]/totalsumma Eij[1,4] &lt;- kolumnsummor[4]*radsummor[1]/totalsumma Eij[2,1] &lt;- kolumnsummor[1]*radsummor[2]/totalsumma Eij[2,2] &lt;- kolumnsummor[2]*radsummor[2]/totalsumma Eij[2,3] &lt;- kolumnsummor[3]*radsummor[2]/totalsumma Eij[2,4] &lt;- kolumnsummor[4]*radsummor[2]/totalsumma X2obs &lt;- sum( (Oij - Eij)^2/Eij ) fg &lt;- (r-1)*(k-1) p_value &lt;- 1 - pchisq(X2obs, fg) X2obs &gt; [1] 1.358175 p_value &gt; [1] 0.7153672 Övning 6.2 En studie 1980 undersökte homosexuellas situation Sverige. En del av denna studie utgjordes bland annat en enkätundersökning. Ladda ner Lilla Enkäten som är txt-fil som finns i zip-filen “Enkäterna i csv-format” på https://riksarkivet.se/psidata/livet-som-gay. Utgå från att data är insamlat med OSU och besvara sedan följande frågor: Har den svarande själv haft en önskan om att inte vara homosexuell? Redovisa med en tabell. Undersök samband mellan önskan om att inte vara homosexuell och att känna skam eller ångest (SKAM)? Redovisa bortfall. Redovisa en figur. Undersök samband mellan önskan om att inte vara homosexuell och att känna skam eller ångest (SKAM)? Redovisa bortfall. Redovisa en figur. Visa svar rm(list=ls()) # a) df &lt;- read.csv2(&quot;data/Lilla_enkaeten.txt&quot;) df$skam_bin &lt;- NA df$skam_bin[df$SKAM == &quot;Ja&quot;] &lt;- 1 df$skam_bin[df$SKAM == &quot;Nej&quot;] &lt;- 0 df$onskan_bin &lt;- NA df$onskan_bin[df$OENSKAN == &quot;Ja, det har jag gjort men jag önskar det inte nu&quot;] &lt;- 1 df$onskan_bin[df$OENSKAN == &quot;Ja, jag önskar nu att jag vore (helt) heterosexuell&quot;] &lt;- 1 df$onskan_bin[df$OENSKAN == &quot;Nej&quot;] &lt;- 0 freq_table &lt;- table(df$onskan_bin, df$skam_bin) chisq.test(freq_table) Se formuleringar ovan om andelar, differens av andelar, KI och p-värde. OSU (experiment) och normalapproximation gäller. Jag litar på resultaten. Övning 6.3 År 2019 omkom 221 i trafiken. Uppdelat på månad Antal omkomna 2019 Antal omkomna 2018 Antal omkomna 2018 Januari 27 13 12 Februari 17 16 14 Mars 10 22 18 April 16 17 17 Maj 19 31 24 Juni 19 32 27 Juli 20 44 31 Augusti 25 29 34 September 15 21 27 Okober 23 25 20 November 13 36 10 December 17 38 19 Källa: Transportstyrelsen Besvara om antalet omkomna är oberoende av månad. Visa svar rm(list=ls()) # Version 1 omkomna2019 &lt;- c(27, 17, 10, 16, 19, 19, 20, 25, 15, 23, 13, 17) omkomna2018 &lt;- c(13, 16, 22, 17, 31, 32, 44, 29, 21, 25, 36, 38) omkomna2017 &lt;- c(12, 14, 18, 17, 24, 27, 31, 34, 27, 20, 10, 19) manad &lt;- c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;Maj&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Okt&quot;, &quot;Nov&quot;, &quot;Dec&quot;) barplot(omkomna2019, names.arg = manad) chisq.test(omkomna2019) Chi-squared test for given probabilities data: omkomna2019 X-squared = 14.276, df = 11, p-value = 0.2181 O &lt;- omkomna2019 E &lt;- rep(sum(omkomna2019)/12, 12) X2 &lt;- sum( (O - E)^2/E) Övning 6.4 BMI Nutritional status Below 18.5 Underweight 18.5–24.9 Normal weight 25.0–29.9 Pre-obesity 30.0–34.9 Obesity class I 35.0–39.9 Obesity class II Above 40 Obesity class III df &lt;- read.csv2(&quot;data/conscriptiondata.csv&quot;) df$bmi &lt;- df$weight/(df$height/100)^2 summary(df$bmi) df$bmi_cat &lt;- NA df$bmi_cat[df$bmi &lt; 18.5] &lt;- &quot;Undervikt&quot; df$bmi_cat[(df$bmi &gt;= 18.5) &amp; (df$bmi &lt; 25)] &lt;- &quot;Normalvikt&quot; df$bmi_cat[(df$bmi &gt;= 25) &amp; (df$bmi &lt; 30) ] &lt;- &quot;Övervikt&quot; df$bmi_cat[(df$bmi &gt;= 30) &amp; (df$bmi &lt; 35) ] &lt;- &quot;Fetma klass I&quot; df$bmi_cat[(df$bmi &gt;= 35) &amp; (df$bmi &lt; 40) ] &lt;- &quot;Fetma klass II&quot; df$bmi_cat[(df$bmi &gt;= 40)] &lt;- &quot;Fetma klass III&quot; df$bmi_cat &lt;- factor(df$bmi_cat, levels = c(&quot;Undervikt&quot;, &quot;Normalvikt&quot;, &quot;Övervikt&quot;, &quot;Fetma klass I&quot;, &quot;Fetma klass II&quot;, &quot;Fetma klass III&quot;), ordered = TRUE) freq_table_bmi_cat &lt;- table(df$bmi_cat) prop_table_bmi_cat &lt;- prop.table(freq_table) barplot(freq_table_bmi_cat) barplot(prop_table_bmi_cat) prop_bmi_year &lt;- prop.table( table(df$bmi_cat, df$year), 2 ) barplot(prop_bmi_year, las = 2, horiz = TRUE) chisq.test(freq_table_bmi_cat) Vi kan konstatera att andelen överviktiga har ökat. Samtidigt har andelen underviktiga minskat. Det finns ett beroende mellan år och bmi-kategori. Undersökarna vill beräkna kvoten av andelar lyckade behandlingar (relativ risk), där spjälning är referensgrupp. Eftersom forskarna vill fatta beslut vill man att en hypotesprövning genomförs på 5% signifikansnivå. Visa svar rm(list=ls()) df &lt;- data.frame(treatment = c(rep(&quot;splint&quot;, 60), rep(&quot;splint&quot;, 23), rep(&quot;surgery&quot;, 67), rep(&quot;surgery&quot;, 6)), y = c(rep(&quot;succesful&quot;, 60), rep(&quot;unsucsessful&quot;,23), rep(&quot;succesful&quot;, 67), rep(&quot;unsucsessful&quot;,6))) freq_table &lt;- table(df$y, df$treatment) prop_table &lt;- prop.table(freq_table, 2) phat_splint &lt;- prop_table[1,1] phat_surgery &lt;- prop_table[1,2] p_kvot &lt;- phat_surgery/phat_splint resultat &lt;- chisq.test(freq_table, correct = FALSE) p_kvot [1] 1.269635 resultat$p.value [1] 0.001792853 En patient har 27% (p = 0.002) större chans till lyckad behandling om patienten genomgår kirurgi istället för behandling. Eftersom \\(p&lt;0.05\\) förkastar vi på 5% signifikansnivå nollhypotesen om att kirurgi och spjälning är lika effektiva. Övning 6.5 I riksdagsvalet 2018 blev mandatfördelningen följande. Skapa ett stapeldiagram och ett cirkeldiagram som redovisar mandatfördelningen. Argumentera varför det enda diagrammet är att föredra i detta fall. Antal mandat i riksdagsvalet 2018 Centerpartiet 31 Kristdemokraterna 22 Liberalerna 20 Miljöpartiet 16 Moderaterna 70 Socialdemokraterna 100 Sverigedemokraterna 62 Vänsterpartiet 28 Visa svar rm(list=ls()) parti &lt;- c(&quot;Centerpartiet&quot;, &quot;Kristdemokraterna&quot;, &quot;Liberalerna&quot;, &quot;Miljöpartiet&quot;, &quot;Moderaterna&quot;, &quot;Socialdemokraterna&quot;, &quot;Sverigedemokraterna&quot;, &quot;Vänsterpartiet&quot;) partishort &lt;- factor(c(&quot;C&quot;, &quot;KD&quot;, &quot;L&quot;, &quot;Mp&quot;, &quot;M&quot;, &quot;S&quot;, &quot;SD&quot;, &quot;V&quot;)) particol &lt;- c(&quot;green&quot;, &quot;purple&quot;, &quot;lightblue&quot;, &quot;darkgreen&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;yellow&quot;, &quot;darkred&quot;) mandat &lt;- c(31, 22, 20, 16, 70, 100, 62, 28) df &lt;- data.frame(parti = parti, partishort = partishort, particol = particol, mandat = mandat) df$parti &lt;- factor(df$parti, levels = c(&quot;Vänsterpartiet&quot;, &quot;Socialdemokraterna&quot;, &quot;Miljöpartiet&quot;, &quot;Sverigedemokraterna&quot;, &quot;Centerpartiet&quot;, &quot;Liberalerna&quot;, &quot;Kristdemokraterna&quot;, &quot;Moderaterna&quot;)) df$particol &lt;- as.character(df$particol) df_sorted &lt;- df[order(df$parti),] # Stapeldiagram barplot(df_sorted$mandat, names.arg = df_sorted$partishort, col = df_sorted$particol) # Cirkeldiagram lbs &lt;- paste(df_sorted$partishort, &quot; &quot;, &quot;(&quot;, df_sorted$mandat, &quot;)&quot;, sep=&quot;&quot;) pie(df_sorted$mandat, labels = lbs, col = c(&quot;darkred&quot;, &quot;red&quot;, &quot;darkgreen&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;lightblue&quot;, &quot;purple&quot;, &quot;blue&quot;), clockwise = TRUE, radius = 1, main = &quot;Riksdagsvalet 2018: Mandatfördelning&quot;) # Hästskodiagram för att redovisa mandatfördelning. Överkurs. Installera # paketet ggplot2 och kör koden nedan. Till för att visa flexibiliten i R # och visualisering. install.packages(&quot;ggplot&quot;) library(&quot;ggparliament&quot;) swedish_election_2018 &lt;- parliament_data(election_data = df_sorted, party_seats = df_sorted$mandat, parl_rows = 5, type = &quot;horseshoe&quot;) swe &lt;- ggplot(swedish_election_2018, aes(x, y, colour = partishort)) + geom_parliament_seats() + theme_ggparliament() + labs(colour = NULL, title = &quot;Sveriges riksdag&quot;) + scale_colour_manual(values = particol, limits = partishort) + theme(legend.position = &#39;bottom&#39;) swe Övning 6.6 En studie 1980 undersökte homosexuellas situation Sverige. En del av denna studie utgjordes bland annat en enkätundersökning. Ladda ner Lilla Enkäten som är txt-fil som finns i zip-filen “Enkäterna i csv-format” på https://riksarkivet.se/psidata/livet-som-gay. Utgå från att data är insamlat med OSU och besvara sedan följande frågor: Har den svarande själv talat om för någon heterosexuell bekant (som inte bara är arbetskamrat) att den svarande är homo/bisexuell? Variabeln heter TALAT_OM. Finns ett samband mellan kön (KOEN) och fråga a)? Undersök samband mellan att känna skam eller ångest (SKAM) och TALAT_OM? Redovisa bortfall. Redovisa en figur. Visa svar rm(list=ls()) df &lt;- read.csv2(&quot;data/Lilla_enkaeten.txt&quot;) # Undersök variabeln och variabelkategorierna summary(df$TALAT_OM) table(df$TALAT_OM, useNA = &quot;ifany&quot;) # Skapar en tom variabel och koda sedan alla nej till 1 och övriga till 0 df$EJ_TALAT_OM_bin &lt;- NA df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Ja, för en bekant&quot;] &lt;- 0 df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Ja, för flera bakanta&quot;] &lt;- 0 df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Jag har inga heterosexuella vänner&quot;] &lt;- 0 df$EJ_TALAT_OM_bin[df$TALAT_OM == &quot;Nej&quot;] &lt;- 1 # a) freq_table_EJ_TALAT_OM &lt;- table(df$EJ_TALAT_OM_bin) x &lt;- freq_table_EJ_TALAT_OM[2] n &lt;- sum(freq_table_EJ_TALAT_OM) resultat_1 &lt;- prop.test(x, n, correct = FALSE) resultat_1 # b) # Undersök variabeln kön summary(df$KOEN) table(df$KOEN, useNA = &quot;ifany&quot;) # Skapa en korstabell av kön och ej talat om freq_table_KOEN_EJ_TALAT_OM &lt;- table(df$EJ_TALAT_OM_bin, df$KOEN) x1 &lt;- freq_table_KOEN_EJ_TALAT_OM[2,1] x0 &lt;- freq_table_KOEN_EJ_TALAT_OM[2,2] n1 &lt;-sum(freq_table_KOEN_EJ_TALAT_OM[,1]) n0 &lt;-sum(freq_table_KOEN_EJ_TALAT_OM[,2]) p1hat &lt;- x1/n1 p0hat &lt;- x0/n0 resultat_KOEN_EJ_TALAT_OM &lt;- prop.test(c(x1,x0), c(n1, n0), correct = FALSE) resultat_KOEN_EJ_TALAT_OM # Kolla förutsättningarna n1*p1hat*(1-p1hat) n0*p0hat*(1-p0hat) # c) # Undersök variabeln summary(df$SKAM) table(df$SKAM, useNA = &quot;ifany&quot;) # Skapa en korstabell df$skam_bin &lt;- NA df$skam_bin[df$SKAM == &quot;Ja&quot;] &lt;- 1 df$skam_bin[df$SKAM == &quot;Nej&quot;] &lt;- 0 df$skam_bin[df$SKAM == 9] &lt;- NA freq_table_ej_talat_om_skam &lt;- table( df$EJ_TALAT_OM_bin, df$skam_bin) colnames(freq_table_ej_talat_om_skam) &lt;- c(&quot;Ej skam&quot;, &quot;Skam&quot;) rownames(freq_table_ej_talat_om_skam) &lt;- c(&quot;Ej talat om&quot;, &quot;Talat om&quot;) prop_table_ej_talat_om_skam &lt;- prop.table(freq_table_ej_talat_om_skam, 2) barplot( prop_table_ej_talat_om_skam[2,], names.arg = c(&quot;Ej skam&quot;, &quot;Skam&quot;), ylab = &quot;Andel som tala om&quot;) x1_2 &lt;- freq_table_ej_talat_om_skam[2,2] x0_2 &lt;- freq_table_ej_talat_om_skam[2,1] n1_2 &lt;- sum(freq_table_ej_talat_om_skam[,2]) n0_2 &lt;- sum(freq_table_ej_talat_om_skam[,1]) p1hat_2 &lt;- x1_2/n1_2 p0hat_2 &lt;- x0_2/n0_2 p_kvot &lt;- p1hat_2/p0hat_2 p_kvot resultat_2 &lt;- prop.test(c(x1_2, x0_2), c(n1_2, n0_2), correct = FALSE) Notera att förutsättningen är ej uppfylld för sambandsanalysen. Vi kan inte lita på testet. 10 värden är kodade som 9, som förmodligen vet ej eller bortfall. Vi sätter dem som NA. Dessa exkuderas ur analysen. Övning 6.7 En marknadsundersökning genom ett slumpmässigt urval av konsumenter för undersöka om färg har betydelse vad gäller val av mobiltelefon. Nedan presenterar data som du fått från företaget gällande vilken färg konsumenterna föredrar av tre möjligt: Färg Cyberblå 150 Prestigeröd 150 Supergrå 200 Har färgen någon betydelse? Dessutom fanns data uppdelat på kön. Färg: Män Färg: Kvinnor Cyberblå 100 50 Prestigeröd 60 90 Supergrå 100 100 Finns det samband mellan kön och vilken färg konsumenterna föredrar? Visa svar rm(list=ls()) df &lt;- read.csv2(&quot;data/Lilla_enkaeten.txt&quot;) Notera att förutsättningen är ej uppfylld för sambandsanalysen. Vi kan inte lita på testet. 10 värden är kodade som 9, som förmodligen vet ej eller bortfall. Vi sätter dem som NA. Dessa exkuderas ur analysen. 6.5 Referenser Helsing, K. J., &amp; Comstock, G. W. (1977). What kinds of people do not use seat belts?. American Journal of Public Health, 67(11), 1043-1050. admitted &lt;- c(rep(1, 512), rep(1, 353), rep(1, 120), rep(1, 138), rep(1, 53), rep(1, 22), rep(1, 89), rep(1, 17), rep(1, 202), rep(1, 131), rep(1, 94), rep(1, 24), rep(0, 313), rep(0, 207), rep(0, 205), rep(0, 279), rep(0, 138), rep(0, 351), rep(0, 19), rep(0, 8), rep(0, 391), rep(0, 244), rep(0, 299), rep(0, 317)) male &lt;- c(rep(1, 512), rep(1, 353), rep(1, 120), rep(1, 138), rep(1, 53), rep(1, 22), rep(0, 89), rep(0, 17), rep(0, 202), rep(0, 131), rep(0, 94), rep(0, 24), rep(1, 313), rep(1, 207), rep(1, 205), rep(1, 279), rep(1, 138), rep(1, 351), rep(0, 19), rep(0, 8), rep(0, 391), rep(0, 244), rep(0, 299), rep(0, 317)) department &lt;- c(rep(“A”, 512), rep(“B”, 353), rep(“C”, 120), rep(“D”, 138), rep(“E”, 53), rep(“F”, 22), rep(“A”, 89), rep(“B”, 17), rep(“C”, 202), rep(“D”, 131), rep(“E”, 94), rep(“F”, 24), rep(“A”, 313), rep(“B”, 207), rep(“C”, 205), rep(“D”, 279), rep(“E”, 138), rep(“F”, 351), rep(“A”, 19), rep(“B”, 8), rep(“C”, 391), rep(“D”, 244), rep(“E”, 299), rep(“F”, 317)) table(admitted, male) prop.table(table(admitted, male, department),2) chisq.test(table(admitted, male)) chisq.test(table(admitted[department == “A”], male[department == “A”])) treatment &lt;- c(rep(“A”, 350), rep(“B”, 350)) success &lt;- c(rep(1, 81), rep(0,6), rep(1, 192), rep(0, 71), rep(1, 234), rep(0, 36), rep(1, 55), rep(0, 25)) size &lt;- c(rep(1, 81), rep(1,6), rep(0, 192), rep(0, 71), rep(1, 234), rep(1, 36), rep(0, 55), rep(0, 25)) prop.table(table(success, treatment), 2) prop.table( table(success[size == 1], treatment[size==1]), 2) prop.table( table(success[size == 0], treatment[size==0]), 2) "],
["urvalsmetoder.html", "Kapitel 7 Urvalsmetoder 7.1 Obundet slumpmässigt urval utan återläggning 7.2 Stratifierat urval 7.3 Gruppurval 7.4 Efterstratifiering 7.5 Övningar", " Kapitel 7 Urvalsmetoder Detta kapitel utgår från vi önskar beskriva en ändlig population vars värden betraktas som fixa och ej slumpmässiga. Om hela populationen är känd finns ingen osäkerhet, men av olika anledningar kan inte hela populationen undersökas. Vi är därför hänvisade till att genomföra ett slumpmässigt urval. Detta är en del i ett designbaserat ramverk där slumpmässigheten beror på själva urvalsdesignen. En alternativ sätt att betrakta slumpmässigheten är utgå från ett modellbaserat ramverk där populationen är en statistisk matematisk modell. Målet kan då vara att skatta parametrarna i denna modell för exempelvis kunna beskriva modellen eller använda modellen för prediktion. utgångspunkten här är emellertid det designbaserade ramverket och en ändlig population bestående av \\(N\\) element (objekt). Beteckna element \\(k\\) med sitt nummer \\(k\\). Elementen i den ändliga populationen \\(U\\) kan listas \\[U=\\left\\{1,2,\\ldots,k,\\ldots,N\\right\\}.\\] Låt \\(x\\) beteckna en variabel av intresse och låt \\(x_k\\) vara det värdet som element \\(k\\) har. En är en konstant som beskriver en variabel i populationen \\(U\\) och i en ändlig population kan en sådan formuleras utifrån populationens fixa värden. Parametern populationsmedelvärdet är exempelvis \\[\\mu = \\dfrac{x_1+x_2+\\cdots+x_N}{N} = \\dfrac{1}{N}\\sum_{i=1}^N x_i\\] Andra vanliga parametrar är andelen, \\(p\\), totalen, \\(\\tau\\), och variansen, \\(\\sigma^2\\): \\[p=\\frac{x}{n},\\,\\,\\,\\text{där}\\, x \\,\\text{är antal händelser},\\,\\,\\,\\,\\,\\,\\,\\,\\,\\tau = \\sum_{i=1}^N x_i = N\\mu, \\,\\,\\,\\,\\,\\,\\,\\,\\,\\sigma^2 = \\dfrac{1}{N}\\sum_{i=1}^N (x_i - \\mu)^2=\\sum_i^N x_i^2-\\mu^2.\\] Observera att parametrarna inte är slumpvariabler eftersom populationens värden är fixa. Slumpmässigheten beror på den slumpmässiga urvalsdesignen som används. Målet med detta kapitel är att beskriva några olika urvalsdesigner och dess betydelse för skattning av några parametrar i populationerna. För att exemplifiera de olika urvalsmetoderna i R kommer följande data att användas. Läs därför in följande dataframe om du ska replikera exempel. # Töm minnet rm(list=ls()) # Börja med att läsa in data till uppgiften df &lt;- data.frame(id = 500:919, inkomst = c(21612,26831,29068,41121,26601,10495,32891,23065,20098,27192,10864,33128,25951,13931,42063,20053,16979,18457,13727,12289,18474,29347,6172,62354,26727,40591,32350,15695,39887,36051,27667,32995,16711,29466,46706,15008,16223,12420,29185,21492,32746,36412,18635,9407,42185,18270,60093,43245,26905,47235,23508,29302,33199,16940,14905,18904,8200,10823,13540,32811,35465,19754,17484,19823,31397,26130,22034,20491,25759,84710,18300,29405,18801,14813,20879,24499,16288,40533,39616,25343,40417,11639,42591,29613,49918,24015,7917,48072,23721,40454,22857,24890,26873,25733,31870,22394,28161,40196,7263,9187,30253,6462,37143,31732,12895,41056,19258,24978,25309,19061,30371,22022,30063,44522,26037,29028,10030,24272,11394,18576,20376,31086,11700,17003,34196,19755,44144,23741,35294,41388,16435,18644,15322,51665,23378,50478,34808,20447,41233,17311,13941,39664,13168,28809,55952,12495,20185,38094,13822,32932,22205,36625,51575,21508,33509,26322,15392,21626,18837,24299,38921,38951,18360,32974,14131,28463,38232,20072,24300,40883,9090,30565,32935,32589,14408,33223,20177,32574,30640,16255,24056,18365,22039,32859,13595,10514,19490,30075,29849,14371,15076,18983,26641,14967,38646,27197,15314,9058,10275,19248,33629,16039,15302,8363,29178,29565,35454,25673,25116,21695,12594,31860,48489,37977,20106,45531,27277,15418,18315,20529,24322,9509,22487,14443,30287,33711,28788,38495,43640,21820,12945,29219,26099,53993,18370,13513,34515,39675,24622,10069,42460,21113,32073,40741,25925,48530,37672,16809,53412,28576,20974,53895,17485,9382,26977,37076,34885,24809,12793,18749,22223,27462,33319,25212,19846,36005,22765,25484,5710,22545,26475,50017,10044,28683,28379,36793,37007,43140,11389,28621,8074,18887,8729,34029,22957,25761,21928,23366,21629,29325,17545,34121,9780,34344,15565,35821,22192,24715,29730,36446,19315,18764,30303,44705,24113,24773,13433,21116,22444,17098,27646,29356,11167,39386,46786,20476,32806,8196,20299,11016,28822,34008,36611,40839,38823,27474,21803,23579,24328,26289,34776,42902,5958,20928,8996,14684,19391,14105,24321,31704,40910,14725,25166,33578,21071,37265,21827,17284,16401,38311,10416,16634,32329,18411,11388,22741,45799,24504,18190,9708,9590,10068,15552,34781,17205,12180,31054,19803,34321,28206,13392,25659,13679,10817,48137,16057,30680,28931,8746,51031,15530,21598,12816,39388,36873,10815,26335,8332,25860,12491,26264,17914,13240,51238,18080,28812,40576,33316,3978,32843,14942,33416,11274,14775,25466,15959,21031,12042,9518,38184,10007,8226,11975,29364,57382,11814,28760,19193,24117,35747), alder = c(3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1), postnr = c(85466,15111,1111,42520,7655,4434,113231,5520,112233,7854,4520,85466,4520,5520,15111,4343,9866,222,64267,55220,7655,222,42520,85466,4520,4434,42520,5554,1111,222,4520,7854,15111,3133,7854,1111,5554,77664,1131,42520,85466,112233,42520,1111,453,14520,453,453,4434,77664,85466,5520,15111,5554,7854,3467,3133,5520,15111,4434,112233,15111,112233,85466,1111,1111,7655,4343,85466,55220,113231,55220,15111,85466,85466,453,9866,85466,85466,9866,85466,1131,4434,77664,9866,3467,5520,14520,85466,113231,4520,4343,85466,4520,222,85466,1111,4520,4343,85466,14520,55220,3467,42520,64267,85466,7655,1111,113231,112233,3133,3133,453,3133,9866,4520,7854,222,453,112233,7854,64267,222,222,4520,1111,7854,3467,1111,7655,85466,9866,4520,453,5520,4343,3133,42520,4343,4520,1111,85466,55220,453,9866,55220,3467,112233,9866,4434,222,64267,7854,85466,3467,85466,15111,85466,4343,85466,77664,77664,113231,85466,3467,85466,4343,15111,4434,1131,85466,9866,7854,5520,453,15111,113231,9866,85466,113231,42520,85466,14520,55220,7655,85466,64267,9866,4434,4434,4520,3467,55220,15111,3467,85466,85466,4343,85466,222,85466,453,9866,4343,4434,4343,7854,5554,7854,7655,5554,1131,9866,9866,9866,64267,3467,4343,1131,4520,7854,113231,7655,55220,1131,85466,113231,9866,1111,7655,85466,9866,453,9866,9866,15111,9866,7854,85466,1131,7854,7854,5520,14520,77664,7854,1131,113231,9866,3467,77664,113231,4520,4343,112233,9866,4343,1111,453,453,112233,55220,4520,85466,222,4434,85466,85466,15111,3467,112233,1131,3133,4343,7854,4434,85466,77664,85466,9866,85466,5520,4434,85466,5520,5554,15111,9866,3467,112233,222,7854,85466,453,4343,7854,85466,9866,64267,4520,14520,453,3467,4343,453,1111,14520,222,15111,112233,7655,7854,85466,64267,85466,85466,9866,55220,15111,77664,77664,222,7854,3467,77664,64267,15111,85466,113231,77664,85466,85466,85466,112233,1131,7854,64267,7854,4343,222,85466,64267,85466,4520,1111,3467,5520,113231,3467,1111,4520,42520,85466,1131,1131,3467,3133,15111,85466,15111,9866,14520,3133,85466,112233,85466,3467,7854,453,1131,4343,85466,9866,42520,113231,1111,112233,5520,113231,9866,7655,453,5520,55220,5520,85466,55220,85466,5554,453,55220,7655,453,1131,222,42520,9866,1111,15111,4520,4520,85466,3467,5554,55220,4520,1131,85466,5520,4434,4434,64267,1111,1111,14520,5554,42520,85466,7854,4343)) 7.1 Obundet slumpmässigt urval utan återläggning Vid OSU med återläggning (OSU-MÅ) från en ändlig populationen med storleken \\(N\\) riskerar samma element väljas flera gånger. Alternativet är OSU utan återläggning (OSU-UÅ). Om urvalstorleken är \\(n\\) finns vid OSU-UÅ \\[\\binom{N}{n}=\\dfrac{N!}{n!(N-n)!}\\] möjliga urval. Alla urval har samma sannolikhet att väljas. Vid ett OSU-UÅ har således varje objekt samma inklusionssannolikhet, \\(n/N\\). OSU-MÅ respektive OSU-UÅ är de två urvalsmetoder som är grunden för mycket av den inferens som vi gör. OSU-MÅ kan illustreras med att lappar dras slumpmässigt från en hatt och varje gång en lapp dragits så läggs den tillbaka i hatten efter att värdet noterats, medan OSU-UÅ innebär att lappar dras slumpmässigt från en hatt, utan att lapparna läggs tillbaka. En mer formell analogi är att OSU-MÅ är som dragning från en binomialfördelning medan OSU-UÅ är som dragning från en hypergeometrisk fördelning. Om urvalsstorleken \\(n\\) är liten relativt populationsstorleken \\(N\\), låt säg \\(n/N &lt; 0.01\\) saknar det dock praktisk betydelse om vi väljer OSU-MÅ eller OSU-UÅ. Nedan illustreras de bägge urvalsmetoderna OSU-MÅ och OSU-UÅ i R. # Använd sample() för att dra urval från populationsvektorn x_pop med storleken N = 4 x_pop &lt;- c(6,4,7,9) # Dra ett osu med återläggning med n = 2 x_osu_ma &lt;- sample(x_pop, size = 2, replace = TRUE) x_osu_ma # Dra ett osu utan återläggning med n = 2 x_osu_ua &lt;- sample(x_pop, size = 2, replace = FALSE) x_osu_ua I praktiken måste vi inte bara dra ett OSU-UÅ från en vektor, utan i regel består en urvalsram av exempelvis kontaktuppgifter. Vi illusterar därför hur ett urval från en dataframe kan genomföras i R. Först dras unika identifieringsnummer. Därefter matchas identifieringsnummer till rader. Det logiska kommandot \\(==\\) går ej att tillämpa eftersom \\(id\\) och \\(idnr\\_ous\\_ua\\) har olika storlek. Istället används operatorn \\(\\%in\\%\\) för att finna de element som matchar mellan två vektorer. Sedan används funktionen which() för att hitta index (radnummer) för de rader vi har hittat matchande element. Avslutningsvis väljs sedan urvalet med hjälp av indexering. # Använd sample() för att dra urval från vektorn x_pop # Vi konstruerar en urvalsram nedan. id &lt;- c(5,7,44,41,99,101,6) namn &lt;- c(&quot;Alex&quot;, &quot;Robin&quot;, &quot;Kim&quot;, &quot;Charlie&quot;, &quot;Tintin&quot;, &quot;Lo&quot;, &quot;Kim&quot;) tfn &lt;- c(4443344,633223,3335664,322112,73344,42224,5435732) adress &lt;- c(&quot;Storgatan 1&quot;, &quot;Kungsgatan 4&quot;, &quot;Drottninggatan 6&quot;, &quot;Backvägen 33&quot;, &quot;Storgatan 7&quot;, &quot;Lillgränd 6&quot;, &quot;Skogsvägen 90&quot;) ram &lt;- data.frame(id = id, namn = namn, tfn = tfn, adress = adress) # Urvalsstorleken sätts till n=3. Välj 3 idnr med OSU-UÅ och spara i idnr_ous_ua n &lt;- 3 idnr_ous_ua &lt;- sample(df$id, n, replace = FALSE) # Välj rader i data frame (ramen) som korresponderar till slumpmässigt valda idnr. osu_ua &lt;- df[which(df$id %in% idnr_ous_ua), ] osu_ua Det är inte uppenbart för nybörjaren varför ovanstående kod ska användas. Det finns alternativa sätt att dra urval från en dataframe, exempelvis där användaren först skapar skapar en variabel med radnummer, 1:N, från vilken radnummer väljs slumpmässigt. Därefter rader väljas från en dataframe göras med indexinering. En sådan metod bygger dock på sorteringen i dataframet bibehålls. Oavsett metod förutsätter vi att alla element förekommer endast en gång i urvalsramen. Funktionen anyDuplicated() kan användas för att undersöka om värden på identifieringsvariabeln förekommer flera gånger. anyDuplicated(id) 7.1.1 Inferens för populationsmedelvärdet, \\(\\mu\\) Givet ett OSU-UÅ med storleken \\(n\\) gäller följande: Stickprovsmedelvärdet, \\[\\bar{x} = \\dfrac{1}{n}\\sum_{i=1}^n x_i\\] är en väntevärdesriktig skattning av \\(\\mu\\). Stickprovsmedelvärdets varians är \\[V(\\bar{x}) = \\left(\\dfrac{N-n}{N-1}\\right)\\dfrac{\\sigma^2}{n},\\] vilken skattas med \\[\\hat{V}(\\bar{x}) = \\left(1 - \\dfrac{n}{N}\\right)\\dfrac{s^2_x}{n},\\] där \\(s^2\\) är stickprovsvariansen. I praktiken skattas alltid \\(V(\\bar{x})\\). Om stickprovsstorleken är tillräckligt stor är stickprovsmedelvärdets samplingfördelning approximativt normalfördelad på grund av centrala gränsvärdessatsen (CGS). Om stickprovsstorleken är tillräckligt stor (ofta \\(n&gt;30\\)) ges ett konfidensintervall för \\(\\mu\\) av \\[ \\bar{x}\\pm z_{\\alpha/2}\\sqrt{\\hat{V}(\\bar{x})} \\] där \\(1-\\alpha\\) är konfidensgraden och \\(z_{\\alpha/2}\\) är det \\(z\\)-värde som erhålls om svanssannolikheten \\(\\alpha/2\\) läggs i högra svansen. För mindre stickprov används \\(t\\)-fördelningen med \\(n-1\\) frihetsgrader, under förutsättningen att \\(x\\) är normalfördelad. För statistiska test krävs en nollhypotes, en mothypotes, en testfunktion samt data. Om stickprovsstorleken är tillräckligt stor och om nollhypotesen \\(H_0:\\mu=\\mu_0\\) är sann är testfunktionen \\[z = \\dfrac{\\bar{x} - \\mu_0}{\\sqrt{\\hat{V}(\\bar{x})}}\\] approximativt \\(N(0,1)\\). Vi beräknar \\(z_{obs}\\) och undersöker, baserat på om mothypotesen är ensidig eller tvåsidig, hur extremt det observerade värdet är i denna fördelning. För mindre stickprov används \\(t\\)-fördelningen med \\(n-1\\) frihetsgrader, under förutsättningen att \\(x\\) är normalfördelad. Exempel 1: Inkomst Kommunen A önskar att med 95% konfidensgrad skatta medelinkomsten i kommunen. Målpopulationen är invånare i åldern 18-67 år och rampopulationen är en lista med 11200 individer från registret över totalbefolkningen. Vi utgår från att det inte finns någon övertäckning eller undertäckning och drar ett OSU-UÅ bestående av 420 individer från rampopulationen. Individerna kontaktas och data samlas in utan bortfall. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Utgå från det inlästa datasetet df. # Börja med att läsa in data till uppgiften och titta på data! hist(df$inkomst, breaks = 20, main = &quot;&quot;, xlab = &quot;Inkomst (SEK/månad)&quot;, ylab = &quot;Antal&quot;, col = &quot;lightblue&quot;) Data verkar inte komma från en normalfördelning, men fördelningen är inte heller väldigt skev. # Populationsstorlek N &lt;- 11200 # Stickprovsstorlek n &lt;- 420 # Medelvärde xbar &lt;- mean(df$inkomst) # Stickprovsvarians s2 &lt;- var(df$inkomst) # Skattningen av stickprovsmedelvärdets varians vid OSU-UÅ vhatxbar &lt;- (1 - n/N)*(s2/n) # Konfidensintervall med konfidensgraden 100(1-alpha)%. alpha &lt;- 0.05 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_mu &lt;- xbar - z_alpha*sqrt(vhatxbar) ul_mu &lt;- xbar + z_alpha*sqrt(vhatxbar) # Resultat resultat_mu &lt;- c(xbar, ll_mu, ul_mu) resultat_mu ## [1] 25593.58 24500.23 26686.93 Medelinkomsten i kommunen skattas till 25594 kr/mån. Med 95% säkerhet täcker intervallet 24500 kr/mån till 26687 kr/mån medelinkomsten i kommunen. Vi har ett OSU-UÅ vilket ger väntevärdesriktiga skattningar och eftersom urvalet är stort kan även skatta ett konfidensintervall eftersom vi på grund av CGS kan använda normalapproximationen. Exempel 2: Inkomst Kommunen A önskar testa om skatta medelinkomsten i kommunen är mer än 25000. Genom att påvisa att medelinkomsten är större än 25000, vilket innebär mer skatteintäkter, vågar kommunen göra en satsning på en ny idrottsanlägning. För mer information, se Exempel 1. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Använd uppgifter från tidigare exempel # z-test # Nollhypotesen mu0 &lt;- 25000 # Observera z-värde zobs &lt;- (xbar - mu0)/sqrt(vhatxbar) # Beräkna p-värde utifrån att H1: mu &gt; mu0 p_value &lt;- 1 - pnorm(zobs) p_value ## [1] 0.1436514 Medelinkomsten i kommunen skattas till 25594 kr/mån. Vi kan på 5% signifikansnivå inte påvisa att medelinkomsten i kommunen är större 25000 (\\(p=0.144\\)). Då data stämmer relativt väl överens med nollhypotesen väljer kommunen att inte att investera i en ny idrottsanläggning. Vi har ett OSU-UÅ vilket ger väntevärdesriktiga skattningar och eftersom urvalet är stort kan vi använda ett approximativt \\(z\\)-test eftersom vi på grund av CGS kan använda normalapproximationen. div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Normalfördelning eller \\(t\\)-fördelning? Det går att argumentera för att \\(t\\)-fördelningen bör användas i beräkning av konfidensintervall och test även vid användning av approximativ normalfördelning på grund av CGS. Anledningen är att variansen i den approximativa normalfördelningen är okänd och därmed skattas denna varians. Om vi förlitar oss på CGS har dock valet mellan normal- och \\(t\\)-fördelning liten betydelse eftersom dessa fördelningar är snarlika i stora stickprov. Använd följande Shiny-app och jämför standardnormalfördelningen med t-fördelningar med olika frihetsgrader, där antalet frihetgrader beror på stickprovsstorleken. https://jetty.im.uu.se/shiny/Dist/ div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Ensidig eller tvåsidig mothypotes? I många situationer är enbart ena svansen av intresse och då leder en tvåsidig mothypotes till att vi slösar bort signifikans i en för ändamålet ointressant svans. Nedan följer ett exempel på när ensidig mothypotes är rimlig: En miljöorganisation vill undersöka om miljöfarliga ämnen i en sjö överstiger ett gränsvärde. Om så är fallet kommer åtgärder vidtas. Inga förändringar kommer dock göras om det miljöfarliga ämnet inte överstiger gränsvärdet. Vanligast är dock en tvåsidig mothypotes och är man osäker och inte kan motivera en ensidig mothypotes ska en sådan användas. Nedan följer ett exempel på när en tvåsidig mothypotes är rimlig: Ett experiment genomförs för att jämföra en ny arbetsmarknadsåtgärd med ett ordinarie åtgärdsprogram och syftet är att jämföra återgång till arbete bland långtidsarbetslösa. Även om man kanske hoppas på att den nya arbetsmarknadsåtgärden leder till att fler återgår till arbete så vore det även värdefullt att konstatera att det motsatta råder, dvs att det nya programmet istället leder till en försämring vad gäller återgång till arbete. Valet av ensidig eller tvåsidig mothypotes får ALDRIG göras baserat på vad som observeras i stickprovet utan måste göras i förhand. div.red{ background-color:#F5B7B1; border-radius: 5px; padding: 20px;} Kommer du ihåg? \\(p\\)-värdet är sannolikheten att observera ett minst lika extremt värde som det observerade givet att nollhypotesen är sann. Beroende på hur hypoteserna är formulerade är \\(p\\)-värdet något av följande sannolikheter: För en händelse i höger svans, dvs \\(H_1: \\mu &gt; \\mu_0\\) är \\[p-value=\\Pr(Z \\geq z|H_0\\,\\,\\text{sann})\\] För en händelse i vänster svans, \\(H_1: \\mu &lt; \\mu_0\\) \\[p-value=\\Pr(Z \\leq z|H_0\\,\\,\\text{sann})\\] För en två-sidig \\(H_1:\\mu\\neq \\mu_0\\) \\[p-value=2 \\cdot \\min \\left\\{ \\Pr(Z \\leq z|H_0\\,\\,\\text{sann}), \\Pr(Z \\geq z|H_0\\,\\,\\text{sann}) \\right\\} \\] Om möjligt, beräkna alltid \\(p\\)-värdet istället för att enbart jämföra testfunktionens observerade värde med en kritisk punkt. Det går nämligen att tolka \\(p\\)-värdet som ett kontinuerligt mått på bevis mot nollhypotesen eller formulerat som i vilken utsträckning data stämmer överens med nollhypotesen. Ett lågt \\(p\\)-värde indikerar att data har låg överensstämmelse med nollhypoytesen. Om målet med studien trots allt innebär att ett beslut måste fattas kan \\(p\\)-värdet då enkelt relateras till vald signifikansnivå. Understiger \\(p\\)-värdet signifikansnivå så förkastas nollhypotesen, i annat fall kan nollhypotesen inte förkastas. Tänk på att signifikansnivån i dessa fall måste väljas i förväg. 7.1.2 Inferens för populationsandelen, \\(p\\) Anta nu att \\(x\\) är binär. Givet OSU-UÅ gäller med storleken \\(n\\) gäller att: Stickprovsandelen \\(\\hat{p}\\) är en väntevärdesriktig skattning av populationsandelen \\(p\\). Andelsestimatorns varians \\[V(\\hat{p}) = \\left(\\dfrac{N-n}{N-1}\\right)\\dfrac{p(1-p)}{n}\\] skattas med \\[\\hat{V}(\\hat{p}) = \\left(1 - \\dfrac{n}{N}\\right)\\dfrac{\\hat{p}(1-\\hat{p})}{n-1}\\]. Om \\(np(1-p)&gt;5\\) är \\(\\hat{p} \\underset{approx}{\\sim} N(p,V(p))\\). Givet normalapproximation ges ett konfidensintervall för \\(p\\) av \\[ \\hat{p}\\pm z_{\\alpha/2}\\sqrt{\\hat{V}(\\hat{p})} \\] där \\(1-\\alpha\\) är konfidensgraden och \\(z_{\\alpha/2}\\) är det \\(z\\)-värde som erhålls om svanssannolikheten \\(\\alpha/2\\) läggs i högra svansen. För mindre stickprov kan exakta konfidensintervall användas. Givet normalapproximation och nollhypotesen \\(H_0:p=p_0\\) är sann är testfunktionen \\[z = \\dfrac{\\hat{p} - p_0}{\\sqrt{V(\\hat{p})}}\\] approximativt \\(N(0,1)\\). Eftersom vi utgår från är \\(H_0\\) är sann används inte den skattade variansen i testfunktionen. Vi beräknar \\(z_{obs}\\) och undersöker hur extremt det observerade värdet är i denna fördelning. Detta görs utifrån om mothypotesen är ensidig eller tvåsidig. För mindre stickprov kan exakta test användas. Exempel 3: Inkomst mer än 30000 Kommunen A önskar att med 95% konfidensgrad skatta andelen i kommunen som har en inkomst över 30000. För mer information, se Exempel 1. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Använd uppgifter från tidigare exempel # Inkomst mer än 30000 df$inkomst_30000 &lt;- NA df$inkomst_30000[df$inkomst &gt; 30000] &lt;- 1 df$inkomst_30000[df$inkomst &lt;= 30000] &lt;- 0 x &lt;- sum(df$inkomst_30000) phat &lt;- x/n # Använd n givet att vi inte har bortfall! # Skattningen av andelsestimatorns varians vid OSU-UÅ vhatphat &lt;- (1 - n/N)*(phat*(1-phat)/(n-1)) # Konfidensintervall med konfidensgraden 100(1-alpha)%. alpha &lt;- 0.05 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_p &lt;- phat - z_alpha*sqrt(vhatphat) ul_p &lt;- phat + z_alpha*sqrt(vhatphat) # Resultat resultat_p &lt;- c(phat, ll_p, ul_p) resultat_p ## [1] 0.3214286 0.2775572 0.3653000 # Koll av CGS n*phat*(1-phat) ## [1] 91.60714 Andelen i kommunen med en inkomst över 30000 kr/mån skattas 0.32. Med 95% säkerhet täcker intervallet 0.28 till 0.37 andelen i kommunen som har en medelinkomsten som är över 30000 kr/mån. Vi har ett OSU-UÅ vilket ger väntevärdesriktiga skattningar och förutsättningarna för att på grund av CGS kan använda normalapproximationen är uppfylld. Exempel 4: Inkomst mer än 30000 Kommunen A önskar testa om 50% i kommunen har en inkomst över 30000. För mer information, se Exempel 1. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Använd uppgifter från tidigare exempel # z-test # Nollhypotes pH0 &lt;- 0.5 # Observerat z-värde zobs &lt;- (phat - pH0)/sqrt(pH0*(1-pH0)/n) # Beräkna p-värde utifrån att H1: p != pH0 p_value_pH0 &lt;- 2*(1 - pnorm(abs(zobs))) p_value_pH0 ## [1] 2.493561e-13 # Test av CGS n*pH0*(1-pH0) ## [1] 105 Andelen i kommunen med en inkomst över 30000 kr/mån skattas till 0.32. Vi kan på 5% signifikansnivå påvisa att andelen med inkomst över 30000 i kommunen inte är 0.50 (\\(p&lt;0.001\\)). Data stämmer inte överens med nollhypotesen. Vi har ett OSU-UÅ vilket ger väntevärdesriktiga skattningar och förutsättningarna för att, på grund av CGS, använda normalapproximationen är uppfylld. div.green{ background-color:#abd4b3; border-radius: 5px; padding: 20px;} Centrala gränsvärdessatsen och inferens om \\(p\\) Tumregeln \\(np(1-p)&gt;5\\) är dålig om andelen i populationen är nära 0 eller 1. Om andelen i populationen är nära 0 eller 1 krävs stort stickprov för att konfidensgraden ska vara rätt. Det finns dock så kallade exakta alternativ för att skapa konfidensintervall och genomföra test. 7.1.3 Inferens för populationstotalen, \\(\\tau\\) Givet OSU-UÅ med storleken \\(n\\) gäller att Totalestimatorn \\(\\hat{\\tau} = N\\bar{x}\\) är en väntevärdesriktig skattning av \\(\\tau\\). Om \\(x\\) är binär gäller att \\(\\hat{\\tau} = N\\hat{p}\\). Totalestimatorns varians är \\(V(\\hat{\\tau}) = N^2V(\\bar{x})\\), vilken skattas med \\(\\hat{V}(\\hat{\\tau}) = N^2\\hat{V}(\\bar{x})\\). Om \\(x\\) är binär gäller att andelsestimatorns varians är \\(V(\\hat{\\tau}) = N^2V(\\hat{p})\\), vilken skattas med och \\(\\hat{V}(\\hat{\\tau}) = N^2\\hat{V}(\\hat{p})\\). Samplingfördelningen följer samma regler som för \\(\\bar{x}\\) respektive \\(\\hat{p}\\). För konfidensintervall och test av \\(H_0:\\tau=\\tau_0\\) gäller samma förutsättningar som för \\(\\mu\\) och \\(p\\). Exempel 5: Inkomst mer än 30000 Kommunen A önskar att med 95% konfidensgrad skatta antalet i kommunen som har en inkomst över 30000. För mer information, se Exempel 1. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Använd uppgifter från tidigare exempel tauhat &lt;- N*phat # Skattningen av totalestimatorns varians vid OSU-UÅ vhattauhat &lt;- N^2*vhatphat # Konfidensintervall med konfidensgraden 100(1-alpha)%. alpha &lt;- 0.05 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_tau &lt;- tauhat - z_alpha*sqrt(vhattauhat) ul_tau &lt;- tauhat + z_alpha*sqrt(vhattauhat) # Resultat resultat_tau &lt;- c(tauhat, ll_tau, ul_tau) resultat_tau ## [1] 3600.00 3108.64 4091.36 # Koll av CGS n*phat*(1-phat) ## [1] 91.60714 Antalet i kommunen med en inkomst över 30000 skattas till 3600 stycken. Med 95% säkerhet täcker intervallet 3109 till 4091 antalet i kommunen med en inkomst över 30000. Vi har ett OSU-UÅ vilket ger väntevärdesriktiga skattningar och förutsättningarna för att, på grund av CGS, använda normalapproximationen är uppfylld. 7.1.4 Beräkningar av stickprovstorlek Låt \\(\\hat{\\theta}\\) vara en estimator. Tre vanliga precisionskrav är att \\(\\text{medelfel}=\\sqrt{V(\\hat{\\theta})},\\) \\(\\text{felmarginal}=tabellvärde\\cdot \\sqrt{V(\\hat{\\theta})}\\) eller \\(\\text{KIbredd}=2\\cdot tabellvärde \\cdot \\sqrt{V(\\hat{\\theta})}\\) får högst vara av en viss storlek. Storleken beror på vilken nogrannhet som krävs i en undersökning, vilket i sin tur beror på tillämpningen. En opinionsundersökning om partisympatier har kanske lägre krav på precision än urvalsundersökning som syftar till att undersöka halten av miljögifter i en sjö. Mer konkret kan formulera precisionskrav som följer: Kan vi i en partisympatiundersökning acceptera en felmarginal på 10 procentenheter när vi skattar andelen i väljarkåren som sympatiserar med Socialdemokraterna? Kan vi vid en skattning av andelen individer med antikroppar från Covid-19 acceptera ett konfidensintervall med längden 3 procentenheter? Precisionskravet beror sedan på variansen för vald estimator samt eventuellt ett tabellvärde som beror på samplingfördelningen. För att sedan beräkna urvalsstorleken \\(n\\) stoppar vi in kända parametervärden i precisionskravet, till exempel populationsvariansen, \\(\\sigma^2\\) och populationsstorleken \\(N\\). Slutligen löser vi ut urvalstorleken \\(n\\). Om en algebraisk lösning är svår att genomföra kan en iterativ lösning göras i R. Notera att det finns precisionkrav som utgår från Typ-I-fel (signifikansnivå) och Typ-II-fel (styrka), men detta ingår inte i detta kapitel om urvalsmetoder Exempel 6: Beräkning av stickprovsstorlek Grannkommunen B önskar genomföra en undersökning för att skatta medelinkomsten i kommun B. För att planera stickprovsstorleken utgår man från att standardavvikelsen i kommun A är \\(11652.95\\) kr/mån, och antar att denna är samma i kommun B. Vidare nöjer man sig med ett konfidensintervall som har längden 1000 kr/mån. Man avser sedan genomföra ett OSU-UÅ på motsvarande sätt som kommun A. I kommun B finns rampopulationen 21000 individer och det finns inget problem med övertäckning och undertäckning. # Bestäm spridningen i populationen, sätter 1 som default sigma2 &lt;- 11652.95^2 # Känd populationsstorlek N &lt;- 21000 # Bestäm konfidensgrad eller signifikansnivå, sätter 95%/5% som default alpha &lt;- 0.05 z_alpha &lt;- qnorm((1-alpha/2)) # Lista olika stickprovsstorlekar, sätter 1 till 1000 som default n &lt;- 1:4000 # Beräkna (teoretiska) variansen för stickprovsmedelvärdet för olika n vxbar &lt;- ((N-n)/(N-1))*sigma2/n # Beräkna konfidensintervallets bredd för olika stickprovsstorlekar xbar_KIbredd &lt;- 2*z_alpha*sqrt(vxbar) # Välj stickprovsstorlek utifrån valt precisionskra, sätter 0.2 som default precisionskrav &lt;- 1000 # Välj den minsta stickprovsstorlek som uppnår precisionskravet. min(n[xbar_KIbredd &lt;= precisionskrav]) # Studera precisionskrav som en funktion av stickprovstorleken plot(n, xbar_KIbredd, type = &quot;l&quot;, col = &quot;red&quot;) abline(h = precisionskrav) För att ett 95% konfidensintervall ska få vara högst 1000 kr/mån krävs en urvalsstorlek på 1899 individer. Detta är givet att urvalet är ett OSU-UÅ från populationen med 21000 individer samt att populationens standardavvikelse är 11652.95 kr/mån. 7.2 Stratifierat urval Populationen indelas nu i \\(K\\) stycken disjunkta strata. Populationsstorlekan i stratum \\(j\\) betecknas \\(N_j\\) och den totala populationsstorleken är därmed \\(N=N_1 + \\dots + N_K\\). Vidare betecknar \\(\\mu_j\\), \\(p_j\\) och \\(\\sigma^2_j\\) populationsmedelvärdet, populationsandelen respektive populationsvariansen i stratum \\(j\\). Parametrarna av intresse kan nu formuleras baserat på den stratifierade populationen: \\[\\mu = \\dfrac{N_1}{N}\\mu_1 + \\dfrac{N_2}{N}\\mu_2 + \\cdots + \\dfrac{N_K}{N}\\mu_K = \\sum_{j=1}^K\\dfrac{N_j}{N}\\mu_j,\\] \\[\\tau = N\\mu = N_1\\mu_1 + N_2\\mu_2 + \\cdots + N_K\\mu_K = \\sum_{j=1}^KN_j\\mu_j, \\] \\[p = \\dfrac{N_1}{N}p_1 + \\dfrac{N_2}{N}p_2 + \\cdots + \\dfrac{p_K}{N}\\mu_K = \\sum_{j=1}^K\\dfrac{N_j}{N}p_j.\\] Från respektive stratum dras ett urval. Den stratumspecifika urvalsstorleken betecknas \\(n_j\\) och den totala urvalsstorleken i undersökningen är därmed \\(n=n_1+\\cdots+n_K\\). 7.2.1 Inferens för \\(\\mu\\) Givet ett OSU-UÅ från respektive stratum är: Stickprovsmedelvärdet vid stratifierat urval, \\[\\bar{x}_{st} = \\dfrac{N_1}{N}\\bar{x}_1 + \\dfrac{N_2}{N}\\bar{x}_2 + \\cdots \\dfrac{N_K}{N}\\bar{x}_K =\\sum_{j=1}^K\\dfrac{N_j}{N}\\bar{x}_j\\] är en väntevärdesriktig skattning av \\(\\mu\\), där \\(\\bar{x}_{j}\\) betecknar stickprovsmedelvärdet i stratum \\(j\\). Stickprovsmedelvärdets varians är \\[V(\\bar{x}_{st}) = \\sum_{j=1}^K \\left(\\dfrac{N_j}{N}\\right)^2 V(\\bar{x}_j)\\] där stickprovsmedelvärdets varians betecknas \\[V(\\bar{x}_j) = \\left(\\dfrac{N_j-n_j}{N_j-1}\\right)\\dfrac{\\sigma^2_j}{n_j}\\]. Ovanstående skattas med \\[\\hat{V}(\\bar{x}_{st}) = \\left(\\dfrac{N_1}{N}\\right)^2\\hat{V}(\\bar{x}_1) + \\left(\\dfrac{N_2}{N}\\right)^2\\hat{V}(\\bar{x}_2) + \\cdots + \\left(\\dfrac{N_K}{N}\\right)^2\\hat{V}(\\bar{x}_K) = \\sum_{j=1}^K \\left(\\dfrac{N_j}{N}\\right)^2\\hat{V}(\\bar{x}_j)\\] där \\[\\hat{V}(\\bar{x}_j) = \\left(1 - \\dfrac{n_j}{N_j}\\right)\\dfrac{s^2_j}{n_j}\\] och \\(s^2_j\\) är stickprovsvariansen i stratum \\(j\\). Om stickprovsstorleken är tillräckligt stor i respektive stratum, (\\(n_j &gt; 20\\)), är \\(\\bar{x}_{st}\\) approximativt normalfördelad. För konfidensintervall för \\(\\mu\\) och test av \\(H_0:\\mu=\\mu_0\\) gäller samma formler som tidigare baserat på normalapproximationen. Exempel 7: Inkomst Kommunen A önskar att med 90% konfidensgrad skatta medelinkomsten i kommunen. Målpopulationen är invånare i åldern 18-67 år och rampopulationen är en lista med 11200 individer från registret över totalbefolkningen. Eftersom inkomst är relaterad till ålder genomförs en stratifiering utifrån ålderskategorierna 18-34 år (4000 individer), 35-49 år (4200 individer) och 50-67 år (3000 individer). Vi utgår från att det inte finns någon övertäckning eller undertäckning och drar från respektive stratum ett OSU-UÅ. Individerna kontaktas och data samlas in utan bortfall. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Vi inleder med att ordna data så att stratifieringsvariabeln är tydligare namngiven. # Dessutom anger vi relevanta parametrar från undersökningen samt delar upp datamaterial i stratumspecifika data. # Det är inte nödvändigt att göra den indelningen, utan det finns alternativa sätt att koda # NOTERA ATT 1 = 18-34 år, 2 = 35-49 år, 3 = 50-67 år df$age &lt;- factor(df$alder) levels(df$age)[levels(df$age) == &quot;1&quot;] &lt;- &quot;18-34 år&quot; levels(df$age)[levels(df$age) == &quot;2&quot;] &lt;- &quot;35-49 år&quot; levels(df$age)[levels(df$age) == &quot;3&quot;] &lt;- &quot;50-67 år&quot; # Populationsstorlekar från uppgiften N_1 &lt;- 3000 N_2 &lt;- 4200 N_3 &lt;- 4000 N &lt;- N_1 + N_2 + N_3 # Stickprovsstorlekar. Räkna hur många som inte är NA i respektive stratum n_1 &lt;- sum(!is.na(df$inkomst[df$age == &quot;18-34 år&quot;])) n_2 &lt;- sum(!is.na(df$inkomst[df$age == &quot;35-49 år&quot;])) n_3 &lt;- sum(!is.na(df$inkomst[df$age == &quot;50-67 år&quot;])) n &lt;- n_1 + n_2 + n_3 # Medelvärde xbar_1 &lt;- mean(df$inkomst[df$age == &quot;18-34 år&quot;]) xbar_2 &lt;- mean(df$inkomst[df$age == &quot;35-49 år&quot;]) xbar_3 &lt;- mean(df$inkomst[df$age == &quot;50-67 år&quot;]) xbar_st &lt;- (N_1/N)*xbar_1 + (N_2/N)*xbar_2 + (N_3/N)*xbar_3 # Stickprovsvarians s2_1 &lt;- var(df$inkomst[df$age == &quot;18-34 år&quot;]) s2_2 &lt;- var(df$inkomst[df$age == &quot;35-49 år&quot;]) s2_3 &lt;- var(df$inkomst[df$age == &quot;50-67 år&quot;]) # Skattningen av stickprovsmedelvärdets varians vid stratifierat urval vhatxbar_1 &lt;- (1 - n_1/N_1)*(s2_1/n_1) vhatxbar_2 &lt;- (1 - n_2/N_2)*(s2_2/n_2) vhatxbar_3 &lt;- (1 - n_3/N_3)*(s2_3/n_3) vhatxbar_st &lt;- (N_1/N)^2*vhatxbar_1 +(N_2/N)^2*vhatxbar_2 + (N_3/N)^2*vhatxbar_3 # Konfidensgraden 100(1-alpha)%. alpha &lt;- 0.1 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_mu_st &lt;- xbar_st - z_alpha*sqrt(vhatxbar_st) ul_mu_st &lt;- xbar_st + z_alpha*sqrt(vhatxbar_st) # Resultat resultat_mu_st &lt;- c(xbar_st, ll_mu_st, ul_mu_st) resultat_mu_st ## [1] 25853.41 24830.77 26876.04 Medelinkomsten i kommunen skattas till 27703 kr/mån. Med 90% säkerhet täcker intervallet 24759 kr/mån till 26647 kr/mån medelinkomsten i kommunen. Vi har ett STOSU vilket ger väntevärdesriktiga skattningar och eftersom alla stratumspecifika urval är stort kan vi även skatta ett konfidensintervall eftersom vi på grund av CGS kan använda normalapproximationen. Det är ofta illustrativt att även redovisa stratumspecifik beskrivande statistik i respektive stratum och även att undersöka variabelns fördelning i respektive stratum. En sådan tabell samt figurer bör konstrueras i praktiken, men ni förväntas inte genomföra detta på alla uppgifter som ni ska lösa. # Beskrivning av stratumspecifik statistik stratum_tabell &lt;- matrix(c(N_1,N_2,N_3, n_1,n_2,n_3, xbar_1,xbar_2,xbar_3, s2_1,s2_2,s2_3), 3, 4) colnames(stratum_tabell) &lt;- c(&quot;Nj&quot;, &quot;nj&quot;, &quot;xbarj&quot;, &quot;s2j&quot;) rownames(stratum_tabell) &lt;- levels(df$age) stratum_tabell # Stratumspecifika fördelningar par(mfrow = c(4,1)) hist(df$inkomst[df$age == &quot;18-34 år&quot;], breaks = 8, main = &quot;&quot;, xlab = &quot;Inkomst (SEK/månad) bland 18-34 år&quot;, ylab = &quot;Täthet&quot;, col = &quot;lightblue&quot;, xlim = c(0, 85000), freq = FALSE) hist(df$inkomst[df$age == &quot;35-49 år&quot;], breaks = 8, main = &quot;&quot;, xlab = &quot;Inkomst (SEK/månad) bland 35-49 år&quot;, ylab = &quot;Täthet&quot;, col = &quot;lightblue&quot;, xlim = c(0, 85000), freq = FALSE) hist(df$inkomst[df$age == &quot;50-67 år&quot;], breaks = 8, main = &quot;&quot;, xlab = &quot;Inkomst (SEK/månad) bland 50-67 år&quot;, ylab = &quot;Täthet&quot;, col = &quot;lightblue&quot;, xlim = c(0, 85000), freq = FALSE) boxplot(df$inkomst ~ df$age, col = &quot;lightblue&quot;, xlab = &quot;&quot;, ylab = &quot;Inkomst (kr/mån)&quot;) ## Nj nj xbarj s2j ## 18-34 år 3000 200 25002.49 131305562 ## 35-49 år 4200 120 25669.14 116515782 ## 50-67 år 4000 100 26685.07 168804297 7.2.2 Inferens för \\(p\\) Anta att \\(x\\) är binär. Givet ett OSU-UÅ från respektive stratum är: Stickprovsandelen \\(\\hat{p}_{st}=\\sum_{j=1}^K\\dfrac{N}{N_j}\\hat{p}_j\\) är en väntevärdesriktig skattning av \\(p\\), där den stratumspecifka stickprovsandelen är \\(\\hat{p}_j\\). Stickprovsandelens varians \\[V(\\hat{p}_{st}) = \\sum_{j=1}^K\\left(\\dfrac{N_j}{N}\\right)^2V(\\hat{p}_j)\\] skattas med \\[\\hat{V}(\\hat{p}_{st}) = \\sum_{j=1}^K\\left(\\dfrac{N_j}{N} \\right)^2\\hat{V}(\\hat{p}_j),\\] där \\[\\left(1 - \\dfrac{n_j}{N_j}\\right)\\dfrac{\\hat{p}_j(1-\\hat{p}_j)}{n_j-1}.\\] Om \\(n_jp_j(1-p_j)&gt;5\\) i alla stratum \\(j\\) är \\(\\hat{p}_{st}\\) approximativt normalfördelad. Hypotesprövning för andelen i populationen med stratifierat urval ingår inte på kursen! Exempel 8: Inkomst över 30000 kr/mån Kommunen A önskar att med 90% konfidensgrad skatta andelen i kommunen med en inkomst över 30000 kr/mån. För mer information, se Exempel 7. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Uppgifter från tidigare exempel # Andelar (givet att det inte finns bortfall!) x_1 &lt;- sum(df$inkomst_30000[df$age == &quot;18-34 år&quot;]) x_2 &lt;- sum(df$inkomst_30000[df$age == &quot;35-49 år&quot;]) x_3 &lt;- sum(df$inkomst_30000[df$age == &quot;50-67 år&quot;]) phat_1 &lt;- x_1/n_1 phat_2 &lt;- x_2/n_2 phat_3 &lt;- x_3/n_3 phat_st &lt;- (N_1/N)*phat_1 + (N_2/N)*phat_2 + (N_3/N)*phat_3 # Skattningen av stickprovsmedelvärdets varians vid stratifierat urval vhatphat_1 &lt;- (1 - n_1/N_1)*(phat_1*(1-phat_1)/(n_1-1)) vhatphat_2 &lt;- (1 - n_2/N_2)*(phat_2*(1-phat_2)/(n_2-1)) vhatphat_3 &lt;- (1 - n_3/N_3)*(phat_3*(1-phat_3)/(n_3-1)) vhatphat_st &lt;- (N_1/N)^2*vhatphat_1 +(N_2/N)^2*vhatphat_2 + (N_3/N)^2*vhatphat_3 # Konfidensgraden 100(1-alpha)%. alpha &lt;- 0.1 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_p_st &lt;- phat_st - z_alpha*sqrt(vhatphat_st) ul_p_st &lt;- phat_st + z_alpha*sqrt(vhatphat_st) # Resultat resultat_p_st &lt;- c(phat_st, ll_p_st, ul_p_st) resultat_p_st # Koll av förutsättningar n_1*phat_1*(1-phat_1) n_2*phat_2*(1-phat_2) n_3*phat_3*(1-phat_3) ## [1] 0.3267857 0.2863618 0.3672096 ## [1] 42.395 ## [1] 27.59167 ## [1] 21.39 Andelen i kommunen med en inkomst över 30000 kr/mån skattas 0.337. Med 90% säkerhet är andelen i kommunen med en inkomst över 30000 kr/mån mellan 0.286 och 0.367. Vi har ett OSU-UÅ vilket ger väntevärdesriktiga skattningar och förutsättningarna för att använda normalapproximationen är uppfylld. Vi presenterar också en sammanställning av stratumspecfika kvantiteter. ## Nj nj phatj ## 18-34 år 3000 200 0.3050000 ## 35-49 år 4200 120 0.3583333 ## 50-67 år 4000 100 0.3100000 7.2.3 Inferens för \\(\\tau\\) Givet ett OSU-UÅ från respektive stratum är: Totalestimatorn \\(\\hat{\\tau}_{st} = N\\bar{x}_{st}\\) är en väntevärdesriktig skattning av \\(\\tau\\). Om \\(x\\) är binär gäller att \\(\\hat{\\tau}_{st} = N\\hat{p}_{st}\\) Totalestimatorns varians är \\(V(\\hat{\\tau}_{st}) = N^2V(\\bar{x}_{st})\\), vilken skattas med \\(\\hat{V}(\\hat{\\tau}_{st}) = N^2\\hat{V}(\\bar{x}_{st})\\). Om \\(x\\) är binär är \\(V(\\hat{\\tau}_{st}) = N^2V(\\hat{p}_{st})\\), vilken skattas med \\(\\hat{V}(\\hat{\\tau}_{st}) = N^2\\hat{V}(\\hat{p}_{st})\\). Samplingfördelningen följer samma regler som för \\(\\bar{x}_{st}\\) respektive \\(\\hat{p}_{st}\\). Samma principer gäller för inferens om \\(\\mu\\) respektive \\(p\\). Exempel 9: Inkomst över 30000 kr/mån Kommunen A önskar att med 90% konfidensgrad skatta antalet i kommunen med en inkomst över 30000 kr/mån. För mer information, se Exempel 7. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. ## [1] 3660.000 3207.252 4112.748 ## [1] 42.395 ## [1] 27.59167 ## [1] 21.39 Antalet i kommunen med en inkomst över 30000 skattas till 3660 stycken. Med 95% säkerhet täcker intervallet 3207 till 4113 antalet i kommunen med en inkomst över 30000. Vi har ett OSU-UÅ från respektive stratum vilket ger väntevärdesriktiga skattningar och förutsättningarna för att, på grund av CGS, använda normalapproximationen är uppfylld. 7.2.4 Allokering av \\(n\\) Utgå från att vi har budget för en viss urvalsstorlek. Vid stratifierat urval ska denna urvalsstorlek allokeras till olika strata. Neyman-allokering innebär hänsyn tas till variation och populationsstorlek: \\[n_j=\\dfrac{\\sigma_jN_j}{\\sum_{j=1}^K \\sigma_j N_j}\\] Proportionell allokering tar enbart hänsyn till de stratumspecifika populationsstorlekarna. Därmed försvinner \\(\\sigma_j\\) från allokeringsformeln. Proportionell allokering är visserligen mindre effektiv än Neyman-allokering, men kan ändå väljas på grund av ett eller flera av följande skäl: (i) Varianserna antas vara lika varandra i olika stratum och Neyman-allokering skulle innebära en mycket låg precisionsvinst. Det saknas information om de stratumspecifika varianserna. Inferensen blir enklare med proportionell allokering eftersom det leder till ett så kallat självvägt urval (alla element i populationen har samma inklusionssannolikhet). Lika allokering innebär att \\(n_j=n/K\\). Exempel 10 Anta att du har en stickprovsstorlek på 980 observationer som du vill allokera till fyra strata. Du har fyra stratumspecifika populationsvarianser \\(\\sigma^2_1 = 9, \\sigma^2_2 = 4, \\sigma^2_3 = 1, \\sigma^2_4 = 25\\) och fyra stratumspecifika populationsstorlekar \\(N_1 = 7000, N_2 = 15000, N_3 = 40000, N_4 = 1300\\). Genom för allokering av stickprovsstorleken. sigma2_1 &lt;- 9 sigma2_2 &lt;- 4 sigma2_3 &lt;- 1 sigma2_4 &lt;- 25 N_1_allok &lt;- 7000 N_2_allok &lt;- 15000 N_3_allok &lt;- 40000 N_4_allok &lt;- 1300 n_size &lt;- 980 denominomator &lt;- sqrt(sigma2_1)*N_1_allok + sqrt(sigma2_2)*N_2_allok + sqrt(sigma2_3)*N_3_allok + sqrt(sigma2_4)*N_4_allok nj &lt;- n_size*c(sqrt(sigma2_1)*N_1_allok, sqrt(sigma2_2)*N_2_allok, sqrt(sigma2_3)*N_3_allok, sqrt(sigma2_4)*N_4_allok)/denominomator nj ## [1] 211.07692 301.53846 402.05128 65.33333 Du allokerar 211 observationer till stratum ett, 302 till stratum två, 402 till stratum tre och 65 till stratum fyra. 7.3 Gruppurval Utgå från en population bestående av \\(N\\) grupper (kluster). Varje grupp populationen består av \\(M_i\\) element och totalt finns i populationen \\(M\\) element, dvs \\(\\sum_{i=1}^NM_i\\). Låt \\(x_{ij}\\) beteckna värdet som element \\(j\\) har i grupp \\(i\\). Totalvärdet för grupp \\(i\\) är då \\(x_i\\), dvs \\(x_i=\\sum_{j=1}^{M_i} x_{ij}\\). Vi formulerar medelvärdet för alla grupptotaler som \\[\\bar{\\mu} = \\dfrac{1}{N}\\sum_{i=1}^Nx_i\\]. Det innebär att totalen för alla element i populationen kan skrivas: \\[\\tau = \\sum_{i=1}^N\\sum_{j=1}^{M_i}x_{ij}=\\sum_{i=1}^N x_i = N\\bar{\\mu}\\]. Därmed är medelvärdet för alla element i populationen \\[\\mu = \\dfrac{1}{M}\\sum_{i=1}^N\\sum_{j=1}^{M_i}x_{ij} = \\dfrac{1}{M} \\sum_{i=1}^N x_i = \\dfrac{N}{M}\\bar{\\mu}.\\] Om vi låter \\(x_{ij}\\) anta värdena 0 och 1 kan andelen i populationen, \\(p\\), definieras på motsvarande sätt som medelvärdet. Analogt med \\(\\bar{\\mu}\\) kan vi definiera populationsvariansen för grupptotalerna \\[\\sigma^2_u = \\dfrac{1}{N}\\sum_{i=1}^N (x_i - \\bar{\\mu})^2.\\] Från rampopulationen bestående av \\(N\\) grupper genomförs ett OSU-UÅ av storleken \\(n\\) grupper, där varje grupp består av \\(m_i\\) element. Totalt består urvalet av \\(m = \\sum_{i=1}^n m_i\\) element. Nedan exemplifieras de olika kvantiteterna i en population. 7.3.1 Inferens för \\(\\mu\\) Utgå från ett OSU-UÅ med \\(n\\) grupper. En väntevärdesriktig estimator för \\(\\mu\\) är \\[\\bar{x}_{vvr}=\\dfrac{N}{M} \\hat{\\bar{\\mu}},\\] där \\(\\hat{\\bar{\\mu}} = \\dfrac{1}{n}\\sum_{i=1}^n x_i\\) är medelvärdet för alla grupptotaler i stickprovet. Estimatorns varians \\(V(\\bar{x}_{vvr})\\) skattas med \\[\\hat{V}(\\bar{x}_{vvr}) = \\left(\\dfrac{N}{M}\\right)^2\\left(1 - \\dfrac{n}{N}\\right)\\dfrac{s^2_u}{n}\\] där \\[s^2_u = \\dfrac{1}{n}\\sum_{i=1}(x_i - \\hat{\\bar{\\mu}})^2\\] är stickprovsvariansen av alla \\(x_i\\). Estimatorn \\(\\bar{x}_{vvr}\\) är approx. \\(N(\\mu, V(\\bar{x}_{vvr}))\\) om \\(n&gt;20\\) För konfidensintervall för \\(\\mu\\) och test av \\(H_0:\\mu=\\mu_0\\) gäller samma formler som tidigare baserat på normalapproximationen. En alternativ estimator om \\(M\\) inte är tillgänglig är kvotestimatorn \\[\\bar{x}_{kvot}= \\dfrac{\\sum_{i=1}^n x_i}{\\sum_{i=1}^n m_i} = \\dfrac{n}{m}\\hat{\\bar{\\mu}}\\] där \\(m_i\\) är antalet element i i en grupp i urvalet och \\(m = \\sum_{i=1}^N m_i\\) antalet element i urvalet. Notera att \\(\\dfrac{n}{m}\\) skattar \\(\\dfrac{N}{M}\\). Denna estimator är dock inte väntevärdesriktig. Däremot har den en har lägre varians än \\(\\bar{x}_{vvr}\\) om \\(x_i\\) är korrelerad med \\(M_i\\). Biasen kan ignoerar om \\(n &gt; 20\\). Variansen för denna estimator ingår inte på kursen, då den är komplicerad. Exempel 11. Inkomst Kommunen A önskar att med 95% konfidensgrad skatta medelinkomsten i kommunen. Målpopulationen är invånare i åldern 18-67 år. Rampopulationen är en lista med 610 postnummer i kommunen. Vi utgår från att det inte finns någon övertäckning eller undertäckning vad gäller postnummer och drar ett OSU-UÅ bestående av 23 postnummer från rampopulationen. Individerna som bor i dessa postnummerområden kontaktas och data samlas in utan bortfall. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Antal grupp i populationen N &lt;- 610 # Antal element i populationen M &lt;- 11200 # Använd aggregate() för att summera inkomst för varje postnummer grupp_xi &lt;- aggregate(df$inkomst ~ df$postnr, FUN = sum) # Grupptotaler i urvalet xi &lt;- grupp_xi[,2] # Antal grupper i urvalet n &lt;- length(xi) # Medelvärdet av alla grupptotaler (xi) i urvalet mubarhat &lt;- mean(xi) # Stickprovsvarians alla grupptotaler (xi) i urvalet s2u &lt;- var(xi) # Medelvärdesskattning xbar_vvr &lt;- (N/M)*mubarhat # Skattningen av stickprovsmedelvärdets varians vid OSU-UÅ vhatxbar_vvr &lt;- (N/M)^2*(1 - n/N)*(s2u/n) # Konfidensintervall med konfidensgraden 100(1-alpha)%. alpha &lt;- 0.05 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_mu_grupp &lt;- xbar_vvr - z_alpha*sqrt(vhatxbar_vvr) ul_mu_grupp &lt;- xbar_vvr + z_alpha*sqrt(vhatxbar_vvr) # Resultat resultat_mu_grupp &lt;- c(xbar_vvr, ll_mu_grupp, ul_mu_grupp) resultat_mu_grupp [1] 25454.48 18976.56 31932.41 # Alternativ estimator för medelvärdet om M är okänt grupp_mi &lt;- aggregate(df$inkomst ~ df$postnr, FUN = length) # Antal element i respektive grupp mi &lt;- grupp_mi[,2] xbar_kvot &lt;- sum(xi)/sum(mi) xbar_kvot [1] 25593.58 Medelinkomsten i kommunen skattas till 25454 kr/mån. Med 95% säkerhet täcker intervallet 18977 kr/mån till 31932 kr/mån medelinkomsten i kommunen. Vi har ett OSU-UÅ av grupper vilket ger väntevärdesriktiga skattningar och eftersom urvalet är stort kan även skatta ett konfidensintervall eftersom vi på grund av CGS kan använda normalapproximationen. Notera hur mycket stor osäkerheten nu är jämfört med OSU-UÅ. Med kvotestimatorn skattas medelinkomsten i kommunen till 25593 kr/mån. 7.3.2 Inferens för \\(\\tau\\) Utgå från ett OSU-UÅ med \\(n\\) grupper. En väntevärdesriktig estimator för \\(\\tau\\) är \\[\\hat{\\tau}_{vvr}=N\\hat{\\bar{\\mu}}.\\] Estimatorns varians, \\(V(\\hat{\\tau}_{vvr})\\), skattas med \\[\\hat{V}(\\hat{\\tau}_{vvr}) = N^2\\left(1 - \\dfrac{n}{N}\\right)\\dfrac{s^2_u}{n}\\] I övrigt samma egenskaper som \\(\\bar{x}_{vvr}.\\) Exempel 12. Inkomst Kommunen A önskar att med 95% konfidensgrad skatta den totala inkomsten i kommunen. Se information i Exempel 11. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. # Totalskattning tauhau_vvr &lt;- N*mubarhat # Skattningen av stickprovsmedelvärdets varians vid OSU-UÅ vhattau_vvr &lt;- N^2*(1 - n/N)*(s2u/n) # Konfidensintervall med konfidensgraden 100(1-alpha)%. alpha &lt;- 0.05 z_alpha &lt;- qnorm(1 - alpha/2) # Konfidensintervallets gränser ll_tau_grupp &lt;- tauhau_vvr - z_alpha*sqrt(vhattau_vvr) ul_tau_grupp &lt;- tauhau_vvr + z_alpha*sqrt(vhattau_vvr) # Resultat resultat_tau_grupp &lt;- c(tauhau_vvr, ll_tau_grupp, ul_tau_grupp) resultat_tau_grupp [1] 285090183 212537429 357642938 Den totala inkomsten bland invånarna i kommunen skattas till 285090183 kr/mån. Med 95% säkerhet täcker intervallet 212537429 kr/mån till 357642938 kr/mån den totala inkomsten i kommunen. Vi har ett OSU-UÅ av grupper vilket ger väntevärdesriktiga skattningar och eftersom urvalet är stort kan även skatta ett konfidensintervall eftersom vi på grund av CGS kan använda normalapproximationen. Notera hur mycket stor osäkerheten nu är jämfört med OSU-UÅ. 7.3.3 Inferens för \\(p\\) Anta att element \\(x_{ij}\\) bara kan anta värdena 0 eller 1. Vi låter \\(a_i\\) beteckna antalet ettor i en grupp och låter medelantalet ettor i grupperna i stickprovet vara \\(\\bar{a}=\\dfrac{1}{n}\\sum_{i=1}^n a_i\\). Utgå från ett OSU-UÅ med \\(n\\) grupper. En väntevärdesriktig skattning av andelen i populationen ges av \\[\\hat{p}_{vvr} = \\dfrac{N}{M}\\bar{a}.\\] Om \\(M\\) är okänd kan vi, under förutsättning att antalet grupper är tillräckligt stort (\\(n&gt;20\\)), använda \\[\\hat{p}_{kvot} = \\dfrac{\\sum_{i=1}^n a_i}{\\sum_{i=1}^n m_i} = \\dfrac{n}{m}\\bar{a}.\\] Varianser för \\(\\hat{p}_{vvr}\\) och \\(\\hat{p}_{kvot}\\) ingår inte på kursen. Exempel 13. Inkomst över 30000 Kommunen A önskar skatta andelen som har en jnkomst över 30000 i kommunen. Se information i Exempel 11. Besvara kommunens önskemål samt reflektera över om du kan lita på resultatet. grupp_xi &lt;- aggregate(df$inkomst_30000 ~ df$postnr, FUN = sum) ai &lt;- grupp_xi[,2] abar &lt;- mean(ai) # Väntevärdesriktig medelvärdesskattning phat_vvr &lt;- (N/M)*abar phat_vvr [1] 0.3196817 Andelen invånare i åldersgruppen 18-67 år med en inkomst över 30 000 skattas till 0.32. 7.4 Efterstratifiering Efterstratifiering (poststratifiering) innebär att en stratifiering görs i efterhand. Anledningen är att hjälpvariabeln inte finns i urvalsramen och det är först efter datainsamlingen som elementens stratumtillhörigheter blir kända. En förutsättning för efterstratifiering är dock att information om hjälpvariabeln är känd på aggregerad nivå i populationen, dvs \\(N_j\\) för respektive stratum måste vara känd. Efterstratifiering leder till att de stratumspecifika stickprovsstorlekarna \\(n_j\\) är slumpvariabler eftersom de stratumspecifika stickprovsstorlekarna beror de element som valts ut i urvalet. På detta vis skiljer sig efterstratifering från sedvanligt stratifierat urval där \\(n_j\\) är konstanter som väljs i förväg. På grund av denna extra slumpmässighet är estimatorernas varianser vid efterstratifiering alltid större än vid stratifierat urval, dvs \\(V(\\bar{x}_{post}) &gt; V(\\bar{x}_{st})\\). Dock minskar skillnaden mellan varianserna när \\(n\\) är stort och all \\(n_j\\) är relativt stora. Därför gäller att om \\(n\\) är stort och alla \\(n_j\\) är relativt stora används samma variansskattningar som vid stratifierat urval. En praktisk konsekvens är att man inte kan välja allt för många strata vid en efterstratifiering. Istället för att stratifiera utifrån nio eller tio ålderskategorier så måste vi nöja oss med två eller tre strata. Undersökaren måste i förväg ha bestämt hur stratifiering ska göras, så att man inte letar efter en lämplig stratumindelning i efterhand. Efterstratifiering används ofta för korrigera för bortfall i en undersökning. 7.5 Övningar Nedan följer ett antal övningsuppgifter tillhörande detta kapitel. De senare lösningarna kan ha en annan utformning än de inledande, gällande exempelvis beteckningar i R-kod. Ni får använda den kod som ni är mest bekväm med. Övning 7.1 I ett nybyggt höghusområde önskade kommunen undersöka förskolebehovet. Kommunen gjorde därför ett obundet slumpmässigt urval utan återläggning av 100 hushåll. Frågan som ställdes var hur många platser som hushållen är i behov av. Totalt finns det 800 hushåll i området. Av de tillfrågade hushållen angav 56 inget behov, 34 hade behov av en plats, 7 hade behov av två platser och 3 hade behov av tre platser. Beräkna ett 95 % konfidensintervall för det totala antalet önskade förskoleplatser i området. Tolka intervallet! Reflektera över förutsättningarna. Beräkna ett 95 % KI för andelen hushåll i området som inte önskar någon förskoleplats. Tolka intervallet! Reflektera över förutsättningarna. Visa svar # Töm minnet rm(list=ls()) # Läs in data från uppgift platsbehov &lt;- c(rep(0, times = 56), rep(1, times = 34), rep(2, times = 7), rep(3, times = 3)) # Populationsstorlek N &lt;- 800 # Stickprovsstorlek n &lt;- 100 # Skattning av populationstotalen xbar &lt;- mean(platsbehov) tauhat &lt;- N*xbar # Stickprovsvariansen s2 &lt;- var(platsbehov) # Skattning av totalestimatorns varians vhattauhat &lt;- N^2*(1 - n / N)*s2/n # Konfidensintervall alpha &lt;- 0.05 z_alpha &lt;- qnorm((1 - alpha/2)) ll_tau &lt;- tauhat - z_alpha*sqrt(vhattauhat) ul_tau &lt;- tauhat + z_alpha*sqrt(vhattauhat) resultat_tau &lt;- c(tauhat, ll_tau, ul_tau) resultat_tau [1] 456.0000 345.1879 566.8121 Svar: Med 95% säkerhet täcker intervallet \\(345 &lt; \\tau &lt; 567\\) det totala antalet önskade förskoleplatser i området. Vi har OSU-UÅ, vilket gör att vi kan skatta populationstotal och estimatorns varians. Dessutom kan vi beräkna ett konfidensintervall eftersom \\(n&gt;30\\) tillåter normalapproximation pga CGS. # b) # Antal händelser x &lt;- sum(platsbehov == 0) # Beräkning av stickprovsandelen phat&lt;- x/n # Skattning av andelsestimatorns varians vhatphat &lt;- (1 - n/N)*(phat*(1-phat)/(n-1) ) # Konfidensintervall alpha &lt;- 0.05 z_alpha &lt;- qnorm((1 - alpha/2)) ll_p &lt;- phat - z_alpha*sqrt(vhatphat) ul_p &lt;- phat + z_alpha*sqrt(vhatphat) resultat_p &lt;- c(phat, ll_p, ul_p) resultat_p [1] 0.560000 0.468535 0.651465 # Kan vi lita på intervallet? Kolla CGS n*phat*(1-phat) [1] 24.64 Svar: Med 95% säkerhet täcker intervallet \\(0.469 &lt; p &lt; 0.651\\) andelen i området som inte önskar någon förskoleplats. Vi har OSU-UÅ, vilket gör att vi kan skatta populationstotal och estimatorns varians. Dessutom kan vi beräkna ett konfidensintervall eftersom \\(np(1-p)\\) förmodligen är större än 5, vilket tillåter normalapproximation pga CGS. Övning 7.2 Vid en marknadsundersökning i en kommun med \\(8000\\) hushåll valdes 200 hushåll med OSU-UÅ. Hushållen tillfrågades genom brevenkät om åsikterna beträffande ett antal produkter. Efter påminnelser hade kommunen fått svar från samtliga 200 hushåll. De i urvalet ingående hushållens procentuella fördelning efter åsikt beträffande en viss produkt A blev följande: Utmärkt (U) 30%, Tillfredsställande (T) 50%, Dålig (D) 20%. Beräkna ett 95% konfidensintervall för antalet hushåll i kommunen som anser att produkten är dålig. Tolka intervallet! Reflektera över förutsättningarna! Hur stort är medelfelet för andelen hushåll i kommunen som anser att produkten är utmärkt? Tolka intervallet! Reflektera över förutsättningarna! Visa svar # Töm minnet rm(list=ls()) # Skapa data enligt uppgift. kommunprodukt &lt;- c(rep(&quot;U&quot;, times = 60), rep(&quot;T&quot;, times = 100), rep(&quot;D&quot;, times = 40)) N &lt;- 8000 n &lt;- 200 # Skapa en binär variabel (går också att lösa uppgiften med prop.table()) kommunprodukt_bin_D &lt;- NA kommunprodukt_bin_D[kommunprodukt == &quot;U&quot;] &lt;- 0 kommunprodukt_bin_D[kommunprodukt == &quot;T&quot;] &lt;- 0 kommunprodukt_bin_D[kommunprodukt == &quot;D&quot;] &lt;- 1 # Skatta populationstotalen x &lt;- sum(kommunprodukt_bin_D) phat &lt;- x/n tauhat &lt;- N*phat # Skatta variansen för totalestimatorn vhatphat &lt;- (1 - n/N)*phat*(1 - phat)/( n - 1) vhattuahat &lt;- N^2*vhatphat # Konfidensintervall alpha &lt;- 0.05 z_alpha &lt;- qnorm((1 - alpha/2)) ll_tau &lt;- tauhat - z_alpha*sqrt(vhattuahat) ul_tau &lt;- tauhat + z_alpha*sqrt(vhattuahat) resultat &lt;- c(tauhat, ll_tau, ul_tau) resultat [1] 1600.000 1160.991 2039.009 Svar: Med 95% säkerhet täcker intervallet \\(1161 &lt; \\tau &lt; 2039\\) det totala antalet hushåll i kommunen som anser att produkten är dålig. Vi har OSU-UÅ, vilket gör att vi kan skatta populationstotal och estimatorns varians. Dessutom kan vi beräkna ett konfidensintervall eftersom \\(n&gt;30\\) tillåter normalapproximation pga CGS. # Skapa en binär variabel kommunprodukt_bin_U &lt;- NA kommunprodukt_bin_U[kommunprodukt == &quot;U&quot;] &lt;- 1 kommunprodukt_bin_U[kommunprodukt == &quot;T&quot;] &lt;- 0 kommunprodukt_bin_U[kommunprodukt == &quot;D&quot;] &lt;- 0 # Beräkna medelfelet x_U &lt;- sum(kommunprodukt_bin_U) phat_U &lt;- x_U/n vhatphat_U &lt;- (1 - n/N)*phat_U*(1 - phat_U)/( n - 1) se_phat_U &lt;- sqrt(vhatphat_U) Svar: Medelfelet (standardfelet, standard error) är 0.032 vilket är den skattade standardavvikelsen i stickprovsandelens samplingfördelning. OSU-UÅ gör att vi kan skatta medelfelet. Övning 7.3 Ett oljebolag är intresserat av att för ett äldre bostadsområde med \\(2\\,000\\) hus skatta andelen hus utan oljeeldning. Sakkunskapen säger att det sanna antalet hus utan oljeeldning är mellan 300 och 800 stycken. Precisionskravet är formulerat så att ett 95% konfidensintervall för andelen hus utan oljeeldning inte får bli längre än 0.05 procentenheter. Beräkna urvalsstorleken vid OSU om dragningen sker med återläggning. Beräkna urvalsstorleken vid OSU om dragningen sker utan återläggning. Visa svar Precisionskravet är \\(2z_\\alpha/2\\sqrt{V(\\hat{p})}\\) där $ V()=$. Vi antar att \\(p=\\frac{800}{2000}=0,4\\) eftersom detta ger störst varians givet den information vi har. Vi utgår från att \\(np(1-p)&gt;5\\) kommer att vara uppfyllt. Vi måste sedan kontrollera att antagandet faktiskt är uppfyllt! Annars gäller inte CGS och approximativ normalfördelning. Det går att ändra värdena på \\(n\\) i R för att se vilket n som ger vår önskade minsta stickprovsstorlek. Vi vill att uttrycket nedan ska vara lika med eller mindre än 0.05. # Töm minnet rm(list=ls()) # Hypotetisk andel p &lt;- 0.4 # Konfidensintervall som testas för olika värden för n z_alpha &lt;- qnorm(0.975) # Test olika värden för n n &lt;- 10:2000 KIbredd &lt;- 2*z_alpha*sqrt((p*(1 - p))/n) n[KIbredd &lt; 0.05] ## [1] 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 ## [15] 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 ## [29] 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 ## [43] 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 ## [57] 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 ## [71] 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 ## [85] 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 ## [99] 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 ## [113] 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 ## [127] 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 ## [141] 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 ## [155] 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 ## [169] 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 ## [183] 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 ## [197] 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 ## [211] 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 ## [225] 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 ## [239] 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 ## [253] 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 ## [267] 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 ## [281] 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 ## [295] 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 ## [309] 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 ## [323] 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 ## [337] 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 ## [351] 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 ## [365] 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 ## [379] 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 ## [393] 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 ## [407] 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 ## [421] 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 ## [435] 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 ## [449] 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 ## [463] 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 ## [477] 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 ## [491] 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 ## [505] 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 ## [519] 1994 1995 1996 1997 1998 1999 2000 Vi kan även lösa uppgiften algebraiskt genom att sätta in värden \\[ 0.05\\geq 2\\cdot 1.96\\sqrt{\\frac{0.4(1-0.4)}{n}}. \\] Kvadrera båda leden för att bli av med kvadratroten \\[0.05^2\\geq 2^2\\cdot 1.96^2 \\cdot \\frac{0.4(1-0.4)}{n}.\\] Löser vi sedan ut \\(n\\) landar vi på uttrycket \\[n\\geq \\frac{4\\cdot 1.96^2\\cdot 0.24}{0.0025}=1475.174.\\] Svar: För att uppnå precisionskravet behövs ett stickprov med minst 1476 hus. Glöm inte att kontrollera CGS: \\(np(1-p)=1476\\cdot 0.4(1-0,4)=354.24 &gt; 5\\) så antagandet är uppfyllt. Som a) men OSU-UÅ, dvs \\(V(\\hat{p})\\) vid OSU-UÅ ges av \\(\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}\\) och vi har \\(N=2000\\). Vi vill att uttrycket nedan ska vara lika med eller mindre än 0.05. N &lt;- 2000 KIbredd_2 &lt;- 2*z_alpha*sqrt(((N - n)/(N-1))*(p*(1 - p))/n) n[KIbredd_2 &lt; 0.05] ## [1] 850 851 852 853 854 855 856 857 858 859 860 861 862 ## [14] 863 864 865 866 867 868 869 870 871 872 873 874 875 ## [27] 876 877 878 879 880 881 882 883 884 885 886 887 888 ## [40] 889 890 891 892 893 894 895 896 897 898 899 900 901 ## [53] 902 903 904 905 906 907 908 909 910 911 912 913 914 ## [66] 915 916 917 918 919 920 921 922 923 924 925 926 927 ## [79] 928 929 930 931 932 933 934 935 936 937 938 939 940 ## [92] 941 942 943 944 945 946 947 948 949 950 951 952 953 ## [105] 954 955 956 957 958 959 960 961 962 963 964 965 966 ## [118] 967 968 969 970 971 972 973 974 975 976 977 978 979 ## [131] 980 981 982 983 984 985 986 987 988 989 990 991 992 ## [144] 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 ## [157] 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 ## [170] 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 ## [183] 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 ## [196] 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 ## [209] 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 ## [222] 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 ## [235] 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 ## [248] 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 ## [261] 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 ## [274] 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 ## [287] 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 ## [300] 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 ## [313] 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 ## [326] 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 ## [339] 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 ## [352] 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 ## [365] 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 ## [378] 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 ## [391] 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 ## [404] 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 ## [417] 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 ## [430] 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 ## [443] 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 ## [456] 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 ## [469] 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 ## [482] 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 ## [495] 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 ## [508] 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 ## [521] 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 ## [534] 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 ## [547] 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 ## [560] 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 ## [573] 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 ## [586] 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 ## [599] 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 ## [612] 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 ## [625] 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 ## [638] 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 ## [651] 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 ## [664] 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 ## [677] 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 ## [690] 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 ## [703] 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 ## [716] 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 ## [729] 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 ## [742] 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 ## [755] 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 ## [768] 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 ## [781] 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 ## [794] 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 ## [807] 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 ## [820] 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 ## [833] 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 ## [846] 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 ## [859] 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 ## [872] 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 ## [885] 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 ## [898] 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 ## [911] 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 ## [924] 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 ## [937] 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 ## [950] 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 ## [963] 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 ## [976] 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 ## [989] 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 ## [1002] 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 ## [1015] 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 ## [1028] 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 ## [1041] 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 ## [1054] 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 ## [1067] 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 ## [1080] 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 ## [1093] 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 ## [1106] 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 ## [1119] 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 ## [1132] 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 ## [1145] 1994 1995 1996 1997 1998 1999 2000 Algebraisk lösning är att vi sätter in värden och löser ut \\(n\\). \\[\\begin{equation}\\label{eq:intbredd2} 0.05\\geq 2\\cdot 1.96\\sqrt{\\left(\\frac{2000-n}{1999}\\right)\\frac{0.24}{n}} \\end{equation}\\] \\[\\left(\\frac{0.05}{2\\cdot 1.96}\\right)^2 \\geq \\left(\\frac{2000-n}{1999}\\right)\\frac{0.24}{n}\\] \\[\\left(\\frac{0.05}{2\\cdot 1.96}\\right)^2 1999 \\geq \\left(\\frac{2000}{n}-1\\right)0.24\\] \\[\\left(\\frac{0.05}{2\\cdot 1.96}\\right)^2 1999+0.24 \\geq \\frac{2000}{n}0.24.\\] Vi landar slutligen på uttrycket \\[n \\geq \\frac{2000\\cdot 0.24}{\\left(\\frac{0.05}{2\\cdot 1.96}\\right)^2 1999+0.24}\\] vilket ger \\[n \\geq 849.22.\\] Svar: Vi behöver ett urval bestående av minst 850 hushåll för att nå precisionskravet. Kontroll för CGS: \\(np(1-)=204 &gt; 5\\). OK! Övning 7.4 Utgå från en population med \\(N=5\\) element med värdena \\(x_1=4, x_2=8, x_3=2, x_4=6, x_5=9\\). Anta sedan att man inte kan undersöka hela populationen utan måste dra ett OSU-UÅ med stickprovsstorleken \\(n=3\\). Beräkna medelvärde i populationen \\(\\mu_x\\), populationsmedianen \\(md\\), och populationsvariansen \\(\\sigma^2_x\\). Totalt finns det \\(K\\) möjliga stickprov. Beräkna \\(K\\). Beräkna medelvärdet, \\(\\bar{x}\\), och medianen, \\(\\widehat{md}\\) i varje stickprov. Hint: Använd funktionen apply(). Rita två stolpdiagram. Ett som beskriver fördelningen av medelvärdet, ett som beskriver fördelningen av medianen. Vad kallas dessa fördelningar? Beräkna \\(E(\\bar{x})\\) och \\(E(\\widehat{md})\\). Beräkna \\((1/K)(\\sum_{k=1}^K(\\bar{x}_k-E(\\bar{x}))^2)\\) och \\((1/K)\\sum_{k=1}^K(\\widehat{md}_k-E(\\widehat{md}))^2\\). Beräkna även \\(V(\\bar{x})=\\left(\\dfrac{N-n}{N-1}\\right)\\dfrac{\\sigma^2_x}{n}\\) och jämför med de två tidigare värdena. Beskriv med ord skillnaden mellan \\(\\sigma^2_x\\), \\(s^2_x\\), \\(V(\\bar{x})\\), \\(\\hat{V}(\\bar{x})\\), \\(SE(\\bar{x})\\), \\(V(\\widehat{md})\\), \\(\\hat{V}(\\widehat{md})\\) samt \\(SE(\\widehat{md})\\). (Notera att \\(\\sigma^2_x\\) och \\(s^2_x\\) ofta skrivs utan index, samt att \\(V(\\bar{x})\\) och \\(\\hat{V}(\\bar{x})\\) alternativt kan skrivas \\(\\sigma^2_{\\bar{x}}\\) och \\(\\hat{\\sigma}^2_{\\bar{x}}\\).) Om \\(n\\) är stort och vi kan använda tumregeln \\(n &gt; 30\\), vilken varians och approximativ fördelning har \\(\\bar{x}\\)? Vad kallas fördelningen för \\(\\bar{x}\\)? Förklara med ord hur denna fördelning uppkommer. Om \\(n\\) är stort och vi kan använda tumregeln \\(n &gt; 30\\), vilken varians och approximativ fördelning har \\(\\hat{\\tau}=N\\bar{x}\\)? Visa svar Vi beräknar populationsstorheterna på följande vis: # Töm minnet rm(list=ls()) x &lt;- c(4, 8, 2, 6, 9, 10, 50, 4) # vår population # Populationsstorlek N &lt;- length(x) # Populationsmedelvärde mu &lt;- mean(x) mu ## [1] 11.625 # Populationsmedian md &lt;- median(x) md ## [1] 7 # Populationsvarians variant 1 sigma2 &lt;- mean(x^2) - mean(x)^2 # Baseras på E(x^2) - E(x^2) sigma2 ## [1] 216.9844 # Populationsvarians variant 2 sigma2 &lt;- (1/N)*sum( (x - mean(x))^2 ) # Baseras på E[(x - E(x))^2] som är kan skrivas om variant 1 Med choose() beräknas \\(K={n \\choose k}\\). # Stickprovsstorlek n &lt;- 3 # Beräkna (5 över 3) K &lt;- choose(n = N, k = n) K ## [1] 56 Funkionen comb() ger alla möjliga kombinationer från de 5 x-värdena när vi väljer ut 3 av dem per gång. # Skapa alla möjligt stickprov aav storlek 3 från x och beräkna medelvärde och median i varje urval urval &lt;- combn(x, 3) xbars &lt;- apply(urval, 2, mean) xbars ## [1] 4.666667 6.000000 7.000000 7.333333 20.666667 5.333333 4.000000 ## [8] 5.000000 5.333333 18.666667 3.333333 6.333333 6.666667 20.000000 ## [15] 4.666667 7.666667 21.000000 5.666667 21.333333 6.000000 19.333333 ## [22] 5.333333 6.333333 6.666667 20.000000 4.666667 7.666667 8.000000 ## [29] 21.333333 6.000000 9.000000 22.333333 7.000000 22.666667 7.333333 ## [36] 20.666667 5.666667 6.000000 19.333333 4.000000 7.000000 20.333333 ## [43] 5.000000 20.666667 5.333333 18.666667 8.333333 21.666667 6.333333 ## [50] 22.000000 6.666667 20.000000 23.000000 7.666667 21.000000 21.333333 medians &lt;- apply(urval, 2, median) medians ## [1] 4 6 8 8 8 4 4 4 4 4 4 6 6 6 4 9 9 4 10 4 4 6 8 ## [24] 8 8 4 8 8 8 6 9 9 8 10 8 8 6 6 6 4 9 9 4 10 4 4 ## [47] 9 9 6 10 6 6 10 9 9 10 # Stolpdiagram för medelvärdena probs_xbars &lt;- prop.table(table(xbars)) plot(probs_xbars) # Stolpdiagram för medianerna probs_medians &lt;- prop.table(table(medians)) plot(probs_medians) # Jämför mu och E(xbar) mu ## [1] 11.625 mean(xbars) ## [1] 11.625 # Jämför md och E(medians) md ## [1] 7 mean(medians) ## [1] 6.821429 Vi ser att medelvärdet är väntevärdesriktig skattning av medelvärdet. Vi ser också att medianen är inte en väntevärdesriktig skattning av medianen i populationen. Konsekvensen av detta är dock inget som ni behöver bry er om i praktiken just nu, utan detta är en illustration över att det inte är uppenbart att en estimator alltid är väntevärdesriktig. Insättning av värden ger i de tre formlerna ger: # Beräkning enligt formel. (1/K)*sum((xbars - mean(xbars))^2 ) ## [1] 51.66295 (1/K)*sum((medians - mean(medians))^2 ) ## [1] 4.646684 ((N-n)/(N-1))*sigma2/n ## [1] 51.66295 \\(\\sigma_x^2\\) är variansen för \\(x\\) i populationen som vi är intresserade av. \\(s_x^2\\) är variansen för \\(x\\) i stickprovet. \\(V(\\bar{x})\\) är variansen för stickprovsmedelvärdets fördelning som beräknas med populationsvariansen. \\(\\hat{V}(\\bar{x})\\) är den skattade variansen för stickprovsmedelvädets fördelning som beräknas med stickprovsvariansen. \\(SE(\\bar{x})\\) är standardavvikelsen för stickprovsmedelvärdets fördelning. \\(V(\\widehat{md})\\) är variansen för stickprovsmedianens fördelning. \\(\\hat{V}(\\widehat{md})\\) är den skattade variansen för stickprovsmedianens fördelning. \\(SE(\\widehat{md})\\) är standardavvikelsen för stickprovsmedianens fördelning. Om \\(n\\) är stort följer \\(\\bar{x}\\) approximativt fördelningen \\(N(\\mu; V(\\bar{x}))\\). Samplingfördelningen för stickprovsmedelvärdet. Det är fördelningen för medelvärdena för alla olika stickprov vi kan dra från populationen. Om \\(n\\) är stort följer \\(\\hat{\\tau}\\) approximativt fördelningen \\(N(\\mu; V(\\hat{\\tau}))\\). Övning 7.5 Styrelsen i en mindre fackförening på 2000 medlemmar överväger att erbjuda medlemmarna en gruppförsäkring av typ ‘’liv och olycksfall’’. För att utröna slagkraften i ett inkommet erbjudande avser man att uppskatta genomsnittsvärdet av den årliga utgift medlemmarna för närvarande betalar för dylika försäkringar, genom ett urval. Precisionskravet formuleras så att längden av ett 95% konfidensintervall för medelutgiften bland de 2000 medlemmarna inte får överstiga 50 kronor. Försäkringsbolaget hävdar att standardavvikelsen i populationen med största säkerhet inte överstiger 250 kronor. Bestäm tillräcklig stickprovsstorlek under förutsättningarna att den av bolaget angivna standardavvikelsen överensstämmer med populationens och att urvalet är ett OSU-UÅ. Hur stort stickprov ska dras om precisionskravet istället är att felmarginalen får vara max 50 kronor? Hur stort stickprov ska dras om precisionskravet istället är att medelfelet får vara max 50 kronor? Visa svar Vi vill bestämma nödvändig stickprovsstorlek \\(n\\) om längden för ett 95% konfidensintervall för medelutgiften inte får överstiga 50 kronor. Vi utgår från att vi vet populationsstandardavvikelsen (250) samt att \\(V(\\bar{x})=\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}\\). Längden för ett 95% konfidensintervall kan skrivas som \\[2\\cdot z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Precisionskravet är \\(50\\geq 2\\cdot z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}\\). Vi sätter in värden och löser ut \\(n\\). \\[\\begin{equation}\\label{eq:intbredd3} 50\\geq 2\\cdot 1,96\\sqrt{\\left(\\frac{2000-n}{2000-1}\\right)\\frac{250^2}{n}} \\end{equation}\\] \\[\\left(\\frac{50}{2\\cdot 1.96}\\right)^2\\geq \\left(\\frac{2000-n}{1999}\\right)\\frac{250^2}{n}\\] \\[\\left(\\frac{50}{2\\cdot 1.96}\\right)^2 1999 \\geq \\left(\\frac{2000}{n}-1\\right)250^2\\] \\[\\left(\\frac{50}{2\\cdot 1.96}\\right)^2 1999+250^2 \\geq \\frac{2000}{n}250^2\\] \\[n\\geq \\frac{2000\\cdot 250^2}{\\left(\\frac{50}{2\\cdot 1.96}\\right)^2 1999+250^2}=322.40.\\] Man kan även testa sig fram i R: # Längden för att konfidensintevall får inte ska överskrida 50 kronor. N &lt;- 2000 sigma2 &lt;- 250^2 alpha &lt;- 0.05 z_alpha &lt;- qnorm((1-alpha/2)) n &lt;- 10:2000 KI_langd &lt;- 2*z_alpha*sqrt( ((N - n)/(N-1))*(sigma2/n)) n[KI_langd &lt; 50] ## [1] 323 324 325 326 327 328 329 330 331 332 333 334 335 ## [14] 336 337 338 339 340 341 342 343 344 345 346 347 348 ## [27] 349 350 351 352 353 354 355 356 357 358 359 360 361 ## [40] 362 363 364 365 366 367 368 369 370 371 372 373 374 ## [53] 375 376 377 378 379 380 381 382 383 384 385 386 387 ## [66] 388 389 390 391 392 393 394 395 396 397 398 399 400 ## [79] 401 402 403 404 405 406 407 408 409 410 411 412 413 ## [92] 414 415 416 417 418 419 420 421 422 423 424 425 426 ## [105] 427 428 429 430 431 432 433 434 435 436 437 438 439 ## [118] 440 441 442 443 444 445 446 447 448 449 450 451 452 ## [131] 453 454 455 456 457 458 459 460 461 462 463 464 465 ## [144] 466 467 468 469 470 471 472 473 474 475 476 477 478 ## [157] 479 480 481 482 483 484 485 486 487 488 489 490 491 ## [170] 492 493 494 495 496 497 498 499 500 501 502 503 504 ## [183] 505 506 507 508 509 510 511 512 513 514 515 516 517 ## [196] 518 519 520 521 522 523 524 525 526 527 528 529 530 ## [209] 531 532 533 534 535 536 537 538 539 540 541 542 543 ## [222] 544 545 546 547 548 549 550 551 552 553 554 555 556 ## [235] 557 558 559 560 561 562 563 564 565 566 567 568 569 ## [248] 570 571 572 573 574 575 576 577 578 579 580 581 582 ## [261] 583 584 585 586 587 588 589 590 591 592 593 594 595 ## [274] 596 597 598 599 600 601 602 603 604 605 606 607 608 ## [287] 609 610 611 612 613 614 615 616 617 618 619 620 621 ## [300] 622 623 624 625 626 627 628 629 630 631 632 633 634 ## [313] 635 636 637 638 639 640 641 642 643 644 645 646 647 ## [326] 648 649 650 651 652 653 654 655 656 657 658 659 660 ## [339] 661 662 663 664 665 666 667 668 669 670 671 672 673 ## [352] 674 675 676 677 678 679 680 681 682 683 684 685 686 ## [365] 687 688 689 690 691 692 693 694 695 696 697 698 699 ## [378] 700 701 702 703 704 705 706 707 708 709 710 711 712 ## [391] 713 714 715 716 717 718 719 720 721 722 723 724 725 ## [404] 726 727 728 729 730 731 732 733 734 735 736 737 738 ## [417] 739 740 741 742 743 744 745 746 747 748 749 750 751 ## [430] 752 753 754 755 756 757 758 759 760 761 762 763 764 ## [443] 765 766 767 768 769 770 771 772 773 774 775 776 777 ## [456] 778 779 780 781 782 783 784 785 786 787 788 789 790 ## [469] 791 792 793 794 795 796 797 798 799 800 801 802 803 ## [482] 804 805 806 807 808 809 810 811 812 813 814 815 816 ## [495] 817 818 819 820 821 822 823 824 825 826 827 828 829 ## [508] 830 831 832 833 834 835 836 837 838 839 840 841 842 ## [521] 843 844 845 846 847 848 849 850 851 852 853 854 855 ## [534] 856 857 858 859 860 861 862 863 864 865 866 867 868 ## [547] 869 870 871 872 873 874 875 876 877 878 879 880 881 ## [560] 882 883 884 885 886 887 888 889 890 891 892 893 894 ## [573] 895 896 897 898 899 900 901 902 903 904 905 906 907 ## [586] 908 909 910 911 912 913 914 915 916 917 918 919 920 ## [599] 921 922 923 924 925 926 927 928 929 930 931 932 933 ## [612] 934 935 936 937 938 939 940 941 942 943 944 945 946 ## [625] 947 948 949 950 951 952 953 954 955 956 957 958 959 ## [638] 960 961 962 963 964 965 966 967 968 969 970 971 972 ## [651] 973 974 975 976 977 978 979 980 981 982 983 984 985 ## [664] 986 987 988 989 990 991 992 993 994 995 996 997 998 ## [677] 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 ## [690] 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 ## [703] 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 ## [716] 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 ## [729] 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 ## [742] 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 ## [755] 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 ## [768] 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 ## [781] 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 ## [794] 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 ## [807] 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 ## [820] 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 ## [833] 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 ## [846] 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 ## [859] 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 ## [872] 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 ## [885] 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 ## [898] 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 ## [911] 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 ## [924] 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 ## [937] 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 ## [950] 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 ## [963] 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 ## [976] 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 ## [989] 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 ## [1002] 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 ## [1015] 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 ## [1028] 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 ## [1041] 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 ## [1054] 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 ## [1067] 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 ## [1080] 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 ## [1093] 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 ## [1106] 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 ## [1119] 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 ## [1132] 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 ## [1145] 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 ## [1158] 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 ## [1171] 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 ## [1184] 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 ## [1197] 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 ## [1210] 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 ## [1223] 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 ## [1236] 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 ## [1249] 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 ## [1262] 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 ## [1275] 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 ## [1288] 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 ## [1301] 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 ## [1314] 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 ## [1327] 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 ## [1340] 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 ## [1353] 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 ## [1366] 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 ## [1379] 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 ## [1392] 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 ## [1405] 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 ## [1418] 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 ## [1431] 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 ## [1444] 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 ## [1457] 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 ## [1470] 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 ## [1483] 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 ## [1496] 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 ## [1509] 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 ## [1522] 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 ## [1535] 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 ## [1548] 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 ## [1561] 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 ## [1574] 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 ## [1587] 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 ## [1600] 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 ## [1613] 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 ## [1626] 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 ## [1639] 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 ## [1652] 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 ## [1665] 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 ## [1678] 2000 Svar: Vi behöver ett urval bestående av minst 323 medlemmar för att nå precisionskravet. Kontroll för CGS: \\(323 &gt; 30\\). OK! Felmarginalen utgör halva konfidensintervallets längd varpå en felmarginal på 50 kronor innebär en intervallängd på 100 kr. Vi kan ställa upp precisionskravet som \\[50\\geq z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}.\\] Vi anpassar formeln för nödvändig stickprovsstorlek som härleddes i (a) vilket ger \\[n\\geq \\frac{2000\\cdot 250^2}{\\left(\\frac{20}{1,96}\\right)^2 1999+250^2}=91,68.\\] Vi kan även testa oss fram i R: felmarginal &lt;- z_alpha*sqrt( ((N - n)/(N-1))*(sigma2/n)) n[felmarginal &lt; 50] ## [1] 92 93 94 95 96 97 98 99 100 101 102 103 104 ## [14] 105 106 107 108 109 110 111 112 113 114 115 116 117 ## [27] 118 119 120 121 122 123 124 125 126 127 128 129 130 ## [40] 131 132 133 134 135 136 137 138 139 140 141 142 143 ## [53] 144 145 146 147 148 149 150 151 152 153 154 155 156 ## [66] 157 158 159 160 161 162 163 164 165 166 167 168 169 ## [79] 170 171 172 173 174 175 176 177 178 179 180 181 182 ## [92] 183 184 185 186 187 188 189 190 191 192 193 194 195 ## [105] 196 197 198 199 200 201 202 203 204 205 206 207 208 ## [118] 209 210 211 212 213 214 215 216 217 218 219 220 221 ## [131] 222 223 224 225 226 227 228 229 230 231 232 233 234 ## [144] 235 236 237 238 239 240 241 242 243 244 245 246 247 ## [157] 248 249 250 251 252 253 254 255 256 257 258 259 260 ## [170] 261 262 263 264 265 266 267 268 269 270 271 272 273 ## [183] 274 275 276 277 278 279 280 281 282 283 284 285 286 ## [196] 287 288 289 290 291 292 293 294 295 296 297 298 299 ## [209] 300 301 302 303 304 305 306 307 308 309 310 311 312 ## [222] 313 314 315 316 317 318 319 320 321 322 323 324 325 ## [235] 326 327 328 329 330 331 332 333 334 335 336 337 338 ## [248] 339 340 341 342 343 344 345 346 347 348 349 350 351 ## [261] 352 353 354 355 356 357 358 359 360 361 362 363 364 ## [274] 365 366 367 368 369 370 371 372 373 374 375 376 377 ## [287] 378 379 380 381 382 383 384 385 386 387 388 389 390 ## [300] 391 392 393 394 395 396 397 398 399 400 401 402 403 ## [313] 404 405 406 407 408 409 410 411 412 413 414 415 416 ## [326] 417 418 419 420 421 422 423 424 425 426 427 428 429 ## [339] 430 431 432 433 434 435 436 437 438 439 440 441 442 ## [352] 443 444 445 446 447 448 449 450 451 452 453 454 455 ## [365] 456 457 458 459 460 461 462 463 464 465 466 467 468 ## [378] 469 470 471 472 473 474 475 476 477 478 479 480 481 ## [391] 482 483 484 485 486 487 488 489 490 491 492 493 494 ## [404] 495 496 497 498 499 500 501 502 503 504 505 506 507 ## [417] 508 509 510 511 512 513 514 515 516 517 518 519 520 ## [430] 521 522 523 524 525 526 527 528 529 530 531 532 533 ## [443] 534 535 536 537 538 539 540 541 542 543 544 545 546 ## [456] 547 548 549 550 551 552 553 554 555 556 557 558 559 ## [469] 560 561 562 563 564 565 566 567 568 569 570 571 572 ## [482] 573 574 575 576 577 578 579 580 581 582 583 584 585 ## [495] 586 587 588 589 590 591 592 593 594 595 596 597 598 ## [508] 599 600 601 602 603 604 605 606 607 608 609 610 611 ## [521] 612 613 614 615 616 617 618 619 620 621 622 623 624 ## [534] 625 626 627 628 629 630 631 632 633 634 635 636 637 ## [547] 638 639 640 641 642 643 644 645 646 647 648 649 650 ## [560] 651 652 653 654 655 656 657 658 659 660 661 662 663 ## [573] 664 665 666 667 668 669 670 671 672 673 674 675 676 ## [586] 677 678 679 680 681 682 683 684 685 686 687 688 689 ## [599] 690 691 692 693 694 695 696 697 698 699 700 701 702 ## [612] 703 704 705 706 707 708 709 710 711 712 713 714 715 ## [625] 716 717 718 719 720 721 722 723 724 725 726 727 728 ## [638] 729 730 731 732 733 734 735 736 737 738 739 740 741 ## [651] 742 743 744 745 746 747 748 749 750 751 752 753 754 ## [664] 755 756 757 758 759 760 761 762 763 764 765 766 767 ## [677] 768 769 770 771 772 773 774 775 776 777 778 779 780 ## [690] 781 782 783 784 785 786 787 788 789 790 791 792 793 ## [703] 794 795 796 797 798 799 800 801 802 803 804 805 806 ## [716] 807 808 809 810 811 812 813 814 815 816 817 818 819 ## [729] 820 821 822 823 824 825 826 827 828 829 830 831 832 ## [742] 833 834 835 836 837 838 839 840 841 842 843 844 845 ## [755] 846 847 848 849 850 851 852 853 854 855 856 857 858 ## [768] 859 860 861 862 863 864 865 866 867 868 869 870 871 ## [781] 872 873 874 875 876 877 878 879 880 881 882 883 884 ## [794] 885 886 887 888 889 890 891 892 893 894 895 896 897 ## [807] 898 899 900 901 902 903 904 905 906 907 908 909 910 ## [820] 911 912 913 914 915 916 917 918 919 920 921 922 923 ## [833] 924 925 926 927 928 929 930 931 932 933 934 935 936 ## [846] 937 938 939 940 941 942 943 944 945 946 947 948 949 ## [859] 950 951 952 953 954 955 956 957 958 959 960 961 962 ## [872] 963 964 965 966 967 968 969 970 971 972 973 974 975 ## [885] 976 977 978 979 980 981 982 983 984 985 986 987 988 ## [898] 989 990 991 992 993 994 995 996 997 998 999 1000 1001 ## [911] 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 ## [924] 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 ## [937] 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 ## [950] 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 ## [963] 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 ## [976] 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 ## [989] 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 ## [1002] 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 ## [1015] 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 ## [1028] 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 ## [1041] 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 ## [1054] 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 ## [1067] 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 ## [1080] 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 ## [1093] 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 ## [1106] 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 ## [1119] 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 ## [1132] 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 ## [1145] 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 ## [1158] 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 ## [1171] 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 ## [1184] 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 ## [1197] 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 ## [1210] 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 ## [1223] 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 ## [1236] 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 ## [1249] 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 ## [1262] 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 ## [1275] 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 ## [1288] 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 ## [1301] 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 ## [1314] 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 ## [1327] 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 ## [1340] 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 ## [1353] 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 ## [1366] 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 ## [1379] 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 ## [1392] 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 ## [1405] 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 ## [1418] 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 ## [1431] 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 ## [1444] 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 ## [1457] 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 ## [1470] 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 ## [1483] 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 ## [1496] 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 ## [1509] 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 ## [1522] 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 ## [1535] 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 ## [1548] 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 ## [1561] 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 ## [1574] 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 ## [1587] 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 ## [1600] 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 ## [1613] 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 ## [1626] 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 ## [1639] 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 ## [1652] 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 ## [1665] 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 ## [1678] 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 ## [1691] 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 ## [1704] 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 ## [1717] 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 ## [1730] 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 ## [1743] 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 ## [1756] 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 ## [1769] 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 ## [1782] 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 ## [1795] 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 ## [1808] 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 ## [1821] 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 ## [1834] 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 ## [1847] 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 ## [1860] 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 ## [1873] 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 ## [1886] 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 ## [1899] 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 Svar: Vi behöver ett urval bestånde av minst 92 medlemmar för att nå precisionskravet om en felmarginal på 50 kronor. Kontroll för CGS: \\(92 &gt; 30\\). OK! Vi behöver inte normalfördelning för att beräkna medelfelet. Medelfelet ges av \\[SE(\\bar{x})=\\sqrt{V(\\bar{x})}=\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}.\\] Precisionskravet kan skrivas som \\[50\\geq \\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}\\] och insättning av värden ger \\[50\\geq \\sqrt{\\left(\\frac{2000-n}{2000-1}\\right)\\frac{250^2}{n}}.\\] Vi löser ut \\(n\\) på motsvarande sätt som i (a) och landar på uttrycket \\[n\\geq \\frac{2000\\cdot250^2}{50^2\\cdot1999+250^2}=24,70.\\] Vi kan även testa oss fram i R: medelfel &lt;- sqrt( ((N - n)/(N-1))*(sigma2/n)) n[medelfel &lt; 50] ## [1] 25 26 27 28 29 30 31 32 33 34 35 36 37 ## [14] 38 39 40 41 42 43 44 45 46 47 48 49 50 ## [27] 51 52 53 54 55 56 57 58 59 60 61 62 63 ## [40] 64 65 66 67 68 69 70 71 72 73 74 75 76 ## [53] 77 78 79 80 81 82 83 84 85 86 87 88 89 ## [66] 90 91 92 93 94 95 96 97 98 99 100 101 102 ## [79] 103 104 105 106 107 108 109 110 111 112 113 114 115 ## [92] 116 117 118 119 120 121 122 123 124 125 126 127 128 ## [105] 129 130 131 132 133 134 135 136 137 138 139 140 141 ## [118] 142 143 144 145 146 147 148 149 150 151 152 153 154 ## [131] 155 156 157 158 159 160 161 162 163 164 165 166 167 ## [144] 168 169 170 171 172 173 174 175 176 177 178 179 180 ## [157] 181 182 183 184 185 186 187 188 189 190 191 192 193 ## [170] 194 195 196 197 198 199 200 201 202 203 204 205 206 ## [183] 207 208 209 210 211 212 213 214 215 216 217 218 219 ## [196] 220 221 222 223 224 225 226 227 228 229 230 231 232 ## [209] 233 234 235 236 237 238 239 240 241 242 243 244 245 ## [222] 246 247 248 249 250 251 252 253 254 255 256 257 258 ## [235] 259 260 261 262 263 264 265 266 267 268 269 270 271 ## [248] 272 273 274 275 276 277 278 279 280 281 282 283 284 ## [261] 285 286 287 288 289 290 291 292 293 294 295 296 297 ## [274] 298 299 300 301 302 303 304 305 306 307 308 309 310 ## [287] 311 312 313 314 315 316 317 318 319 320 321 322 323 ## [300] 324 325 326 327 328 329 330 331 332 333 334 335 336 ## [313] 337 338 339 340 341 342 343 344 345 346 347 348 349 ## [326] 350 351 352 353 354 355 356 357 358 359 360 361 362 ## [339] 363 364 365 366 367 368 369 370 371 372 373 374 375 ## [352] 376 377 378 379 380 381 382 383 384 385 386 387 388 ## [365] 389 390 391 392 393 394 395 396 397 398 399 400 401 ## [378] 402 403 404 405 406 407 408 409 410 411 412 413 414 ## [391] 415 416 417 418 419 420 421 422 423 424 425 426 427 ## [404] 428 429 430 431 432 433 434 435 436 437 438 439 440 ## [417] 441 442 443 444 445 446 447 448 449 450 451 452 453 ## [430] 454 455 456 457 458 459 460 461 462 463 464 465 466 ## [443] 467 468 469 470 471 472 473 474 475 476 477 478 479 ## [456] 480 481 482 483 484 485 486 487 488 489 490 491 492 ## [469] 493 494 495 496 497 498 499 500 501 502 503 504 505 ## [482] 506 507 508 509 510 511 512 513 514 515 516 517 518 ## [495] 519 520 521 522 523 524 525 526 527 528 529 530 531 ## [508] 532 533 534 535 536 537 538 539 540 541 542 543 544 ## [521] 545 546 547 548 549 550 551 552 553 554 555 556 557 ## [534] 558 559 560 561 562 563 564 565 566 567 568 569 570 ## [547] 571 572 573 574 575 576 577 578 579 580 581 582 583 ## [560] 584 585 586 587 588 589 590 591 592 593 594 595 596 ## [573] 597 598 599 600 601 602 603 604 605 606 607 608 609 ## [586] 610 611 612 613 614 615 616 617 618 619 620 621 622 ## [599] 623 624 625 626 627 628 629 630 631 632 633 634 635 ## [612] 636 637 638 639 640 641 642 643 644 645 646 647 648 ## [625] 649 650 651 652 653 654 655 656 657 658 659 660 661 ## [638] 662 663 664 665 666 667 668 669 670 671 672 673 674 ## [651] 675 676 677 678 679 680 681 682 683 684 685 686 687 ## [664] 688 689 690 691 692 693 694 695 696 697 698 699 700 ## [677] 701 702 703 704 705 706 707 708 709 710 711 712 713 ## [690] 714 715 716 717 718 719 720 721 722 723 724 725 726 ## [703] 727 728 729 730 731 732 733 734 735 736 737 738 739 ## [716] 740 741 742 743 744 745 746 747 748 749 750 751 752 ## [729] 753 754 755 756 757 758 759 760 761 762 763 764 765 ## [742] 766 767 768 769 770 771 772 773 774 775 776 777 778 ## [755] 779 780 781 782 783 784 785 786 787 788 789 790 791 ## [768] 792 793 794 795 796 797 798 799 800 801 802 803 804 ## [781] 805 806 807 808 809 810 811 812 813 814 815 816 817 ## [794] 818 819 820 821 822 823 824 825 826 827 828 829 830 ## [807] 831 832 833 834 835 836 837 838 839 840 841 842 843 ## [820] 844 845 846 847 848 849 850 851 852 853 854 855 856 ## [833] 857 858 859 860 861 862 863 864 865 866 867 868 869 ## [846] 870 871 872 873 874 875 876 877 878 879 880 881 882 ## [859] 883 884 885 886 887 888 889 890 891 892 893 894 895 ## [872] 896 897 898 899 900 901 902 903 904 905 906 907 908 ## [885] 909 910 911 912 913 914 915 916 917 918 919 920 921 ## [898] 922 923 924 925 926 927 928 929 930 931 932 933 934 ## [911] 935 936 937 938 939 940 941 942 943 944 945 946 947 ## [924] 948 949 950 951 952 953 954 955 956 957 958 959 960 ## [937] 961 962 963 964 965 966 967 968 969 970 971 972 973 ## [950] 974 975 976 977 978 979 980 981 982 983 984 985 986 ## [963] 987 988 989 990 991 992 993 994 995 996 997 998 999 ## [976] 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 ## [989] 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 ## [1002] 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 ## [1015] 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 ## [1028] 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 ## [1041] 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 ## [1054] 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 ## [1067] 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 ## [1080] 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 ## [1093] 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 ## [1106] 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 ## [1119] 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 ## [1132] 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 ## [1145] 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 ## [1158] 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 ## [1171] 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 ## [1184] 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 ## [1197] 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 ## [1210] 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 ## [1223] 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 ## [1236] 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 ## [1249] 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 ## [1262] 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 ## [1275] 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 ## [1288] 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 ## [1301] 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 ## [1314] 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 ## [1327] 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 ## [1340] 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 ## [1353] 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 ## [1366] 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 ## [1379] 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 ## [1392] 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 ## [1405] 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 ## [1418] 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 ## [1431] 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 ## [1444] 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 ## [1457] 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 ## [1470] 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 ## [1483] 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 ## [1496] 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 ## [1509] 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 ## [1522] 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 ## [1535] 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 ## [1548] 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 ## [1561] 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 ## [1574] 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 ## [1587] 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 ## [1600] 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 ## [1613] 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 ## [1626] 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 ## [1639] 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 ## [1652] 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 ## [1665] 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 ## [1678] 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 ## [1691] 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 ## [1704] 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 ## [1717] 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 ## [1730] 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 ## [1743] 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 ## [1756] 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 ## [1769] 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 ## [1782] 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 ## [1795] 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 ## [1808] 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 ## [1821] 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 ## [1834] 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 ## [1847] 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 ## [1860] 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 ## [1873] 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 ## [1886] 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 ## [1899] 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 ## [1912] 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 ## [1925] 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 ## [1938] 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 ## [1951] 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 ## [1964] 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 Svar: Vi behöver ett urval på minst 25 medlemmar för att uppnå precisionskravet. Övning 7.6 För några år sedan annonserade Findus på följande sätt: ‘’Findus lagar fortfarande Sveriges populäraste köttbullar (näst efter hemlagade förstås)’’. Detta uttalande baserade Findus på en undersökning utförd av Skandinaviska Marknadsinstitutet. Där hade man låtit 200 konsumenter jämföra Findus köttbullar med Felix köttbullar. De 200 konsumenterna hade valts med OSU utan återläggning från en grupp bestående av \\(5000\\) personer som ansågs representera svenska konsumenter. På basis av undersökningen gjorde man ett konfidensintervall för andelen som tyckte att Findus smakade bäst. Detta konfidensintervall tyckte man dock blev alltför brett. I stället ville man ha ett 95% konfidensintervall som skulle vara högst 6 procentenheter brett. Hur stort urval ur konsumentpanelen på \\(5000\\) personer måste man göra för att uppfylla detta precisionskrav? Visa svar Beräkna nödvändig stickprovsstorlek \\(n\\) om längden för ett 95% konfidensintervall för andelen i populationen får vara max 6 procentenheter brett. Vi vet populationsstorleken och använder ändlighetskorrektion varpå \\(\\hat{V}(p)=\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}\\). Vi vet inget om populationsandelen och använder därför 0.5 som ger störst varians. Vi utgår från att \\(np(1-p)&gt;5\\) är uppfyllt för att CGS ska gälla men vi måste i efterhand kontrollera om så faktiskt är fallet. Vi kan lösa uppgiften algebraiskt. Längden för ett 95% konfidensintervall kan skrivas som \\[2\\cdot z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}}\\] där \\(z_{\\alpha/2}=z_{0.025}=1,96\\). Vi sätter in värden givet precisionskravet och löser ut \\(n\\). \\[0,06\\geq 2\\cdot 1.96\\sqrt{\\left(\\frac{5000-n}{5000-1}\\right)\\frac{0.5(1-0.5)}{n}}\\] \\[\\left(\\frac{0.06}{2\\cdot 1.96}\\right)^2 \\geq \\left(\\frac{5000-n}{4999}\\right)\\frac{0.25}{n}\\] \\[\\left(\\frac{0.06}{2\\cdot 1.96}\\right)^2 4999 \\geq \\left(\\frac{5000}{n}-1\\right)0.25\\] \\[\\left(\\frac{0.06}{2\\cdot 1.96}\\right)^2 4999+0.25 \\geq \\frac{5000}{n}0.25.\\] Vi landar slutligen på \\[n \\geq \\frac{5000\\cdot 0.25}{\\left(\\frac{0.06}{2\\cdot1.96}\\right)^2 4999+0.25}=879.57.\\] Vi kan även testa oss fram i R: # Töm minnet rm(list=ls()) N &lt;- 5000 p &lt;- 0.5 alpha &lt;- 0.05 z_alpha &lt;- qnorm((1-alpha/2)) n &lt;- 10:2000 KI_langd &lt;- 2*z_alpha*sqrt(( (N - n)/(N-1))*(p*(1 - p))/n) n[KI_langd &lt; 0.06] ## [1] 880 881 882 883 884 885 886 887 888 889 890 891 892 ## [14] 893 894 895 896 897 898 899 900 901 902 903 904 905 ## [27] 906 907 908 909 910 911 912 913 914 915 916 917 918 ## [40] 919 920 921 922 923 924 925 926 927 928 929 930 931 ## [53] 932 933 934 935 936 937 938 939 940 941 942 943 944 ## [66] 945 946 947 948 949 950 951 952 953 954 955 956 957 ## [79] 958 959 960 961 962 963 964 965 966 967 968 969 970 ## [92] 971 972 973 974 975 976 977 978 979 980 981 982 983 ## [105] 984 985 986 987 988 989 990 991 992 993 994 995 996 ## [118] 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 ## [131] 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 ## [144] 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 ## [157] 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 ## [170] 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 ## [183] 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 ## [196] 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 ## [209] 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 ## [222] 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 ## [235] 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 ## [248] 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 ## [261] 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 ## [274] 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 ## [287] 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 ## [300] 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 ## [313] 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 ## [326] 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 ## [339] 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 ## [352] 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 ## [365] 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 ## [378] 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 ## [391] 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 ## [404] 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 ## [417] 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 ## [430] 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 ## [443] 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 ## [456] 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 ## [469] 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 ## [482] 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 ## [495] 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 ## [508] 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 ## [521] 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 ## [534] 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 ## [547] 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 ## [560] 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 ## [573] 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 ## [586] 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 ## [599] 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 ## [612] 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 ## [625] 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 ## [638] 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 ## [651] 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 ## [664] 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 ## [677] 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 ## [690] 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 ## [703] 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 ## [716] 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 ## [729] 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 ## [742] 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 ## [755] 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 ## [768] 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 ## [781] 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 ## [794] 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 ## [807] 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 ## [820] 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 ## [833] 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 ## [846] 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 ## [859] 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 ## [872] 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 ## [885] 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 ## [898] 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 ## [911] 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 ## [924] 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 ## [937] 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 ## [950] 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 ## [963] 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 ## [976] 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 ## [989] 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 ## [1002] 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 ## [1015] 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 ## [1028] 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 ## [1041] 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 ## [1054] 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 ## [1067] 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 ## [1080] 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 ## [1093] 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 ## [1106] 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 ## [1119] 1998 1999 2000 Svar: För att uppnå precisionskravet behövs ett stickprov på minst 880 personer. Kontroll av CGS: \\(np(1-p)=880\\cdot 0.5\\cdot(1-0.5)=220&gt;5\\). OK! Övning 7.7 Låt \\(\\hat{\\tau}\\) vara en estimator för totalen i en ändlig population där urvalet är ett OSU-UÅ. Utgå från att du känner till \\(V(\\bar{x})\\). Visa att \\[V(\\hat{\\tau})=N^2\\left(\\dfrac{N-n}{N-1}\\right)\\dfrac{\\sigma^2}{n}.\\] Visa svar Vi vill skatta populationstotalen \\(\\tau=N\\mu\\) där \\(N\\) är populationsstorleken och \\(\\mu\\) är populationsmedelvärdet. Vi använder estimatorn \\(\\hat{\\tau}=N\\bar{x}\\). Vi vet att \\(V(\\bar{x})=\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}\\) där \\(\\sigma^2\\) är populationsvariansen och \\(n\\) är stickprovsstorleken. Vi kan nu skriva \\[\\begin{equation}\\nonumber V(\\hat{\\tau})=V(N\\bar{x})=N^2V(\\bar{x})=N^2\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}. \\end{equation}\\] Likheten gäller eftersom \\(N\\) är en konstant som kvadreras enligt regeln \\(V(aX)=a^2V(X)\\) om \\(X\\) är en slumpvariabel och \\(a\\) är en konstant. Övning 7.8 En grisuppfödare äger 150 svin som är utspridda i ett stall. Av praktiska skäl är en totalundersökning inte möjlig. Hon gör därför ett urval på 20 djur på ett sådant sätt att det kan betraktas som ett OSU-UÅ. Grisarnas vikt kan betraktas som normalfördelad. Medelvikten för de 65 utvalda svinen visade sig vara 120 kg och standardavvikelsen 15 kg. Bilda ett 95% konfidensintervall för svinens medelvikt. Tolka intervallet i ord! Reflektera över förutsättningarna. Hur ser ändlighetskorrektionen i variansformeln ut? Vilket syfte har denna korrektion? Hur stort stickprov hade behövts för att halvera konfidensintervallets längd i (a)? Vi kan lösa uppgiften algebraiskt. Visa svar Mål: Intervallskatta medelvikten för svinen i stallet. Parameter: \\(\\mu\\) = medelvikten för samtliga svin i stallet. Estimator: \\(\\bar{x}\\) = medelvikten för svinen i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Populationsstorlek: \\(N=150\\). Urvalsstorlek: \\(n=20\\). Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\bar{x})\\) med \\(\\hat{V}(\\bar{x})=\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}\\). \\(x\\) är normalfördelad så vi behöver inte förlita oss på CGS. Eftersom stickprovet är litet använder vi \\(t\\)-fördelningen med \\(n-1\\) frihetsgrader. Beräkningar: först sammanställer vi våra värden från uppgiften. # Töm minnet rm(list=ls()) xbar &lt;- 120 s = 15 N &lt;- 120 n &lt;- 20 vhatxbar &lt;- (1 - n/N)*s^2/n alpha &lt;- 0.05 # t-fördelningen eftersom litet stickprov t_alpha &lt;- qt((1-alpha/2), df = n - 1) ll_mu &lt;- xbar - t_alpha*sqrt(vhatxbar) ul_mu &lt;- xbar + t_alpha*sqrt(vhatxbar) resultat &lt;- c(xbar, ll_mu, ul_mu) resultat ## [1] 120.0000 113.5914 126.4086 Ett 95% konfidensintervall för \\(\\mu\\) ges av \\[\\bar{x}\\pm t_{n-1; \\alpha/2}\\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}}.\\] Konfidensintervallet skapas här nedanför. qt() fungerar som qnorm() fast för t-fördelningen. Vi måste specificera vilken kvantil vi söker samt hur många frihetsgrader vi har (dvs vilken hur t-fördelningen ser ut). Svar: Med 95% säkerhet täcker intervallet 113.5 till 126.5 den genomsnittliga vikten för svinen i stallet. \\(\\left(1-\\frac{n}{N}\\right)\\). Ändlighetskorrektionen tar hänsyn till den ökade precisionen om urvalet utgör en allt större andel av populationen. Konfidensintervallets längd är \\[2\\cdot t_{n-1;\\alpha/2}\\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}}=13.07.\\] Om längden halveras ska intervallet vara \\(13.07/2=6.535\\) enheter brett, d.v.s. \\(2\\cdot t_{n-1;\\alpha/2}\\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}}=6.535\\). Insättning av värden ger \\[2\\cdot 2.093 \\sqrt{\\left(1-\\frac{n}{150}\\right)\\frac{15^2}{n}}=6.535\\] \\[2^2\\cdot 2.093^2\\left(1-\\frac{n}{150}\\right)\\frac{15^2}{n}=6.535^2\\] \\[\\left(1-\\frac{n}{150}\\right)\\frac{15^2}{n}=\\frac{6.535^2}{2^2\\cdot 2.093^2}\\] \\[\\frac{15^2}{n}-\\frac{15^2}{150}=\\frac{6.535^2}{2^2\\cdot 2.093^2}\\] \\[\\frac{15^2}{n}=\\frac{6.535^2}{2^2\\cdot 2.093^2}+\\frac{15^2}{150}\\] vilket ger uttrycket \\[n=\\frac{15^2}{\\frac{6.535^2}{2^2\\cdot 2.093^2}+\\frac{15^2}{150}}=57.147.\\] Vi avrundar uppåt eftersom vi vill som minst halvera intervallets längd varpå =58. Vi kan även testa oss fram i R, med qt(). Prova själv. Svar: Vi behöver ett stickprov på minst 58 svin för att halvera intervallets längd. Övning 7.9 Ett fackförbundsdistrikt vill veta med hjälp av ett OSU-UÅ veta hur många av medlemmarna som ställer sig positiva till ett förslag. Distriktet har 3800 medlemmar. Beräkna urvalsstorlek om felmarginalen får max vara 2 procentenheter. Beräkna urvalsstorlek om konfidensintervallet får max vara 3 procentenheter. Visa svar Beräkna nödvändig stickprovsstorlek \\(n\\) om felmarginalen för andelen i populationen, \\(p\\), får vara max 2 procentenheter bred. Vi vet populationsstorleken och använder ändlighetskorrektion. \\(V(p)=\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}\\). Vi vet inte populationsandelen men utgår från att den är \\(p=0,5\\) vilket ger störst varians. Vi antar att \\(np(1-p)&gt;5\\) för att CGS ska gälla men måste kontrollera om det stämmer i slutet av uppgiften. Felmarginalen ges av \\[z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}}\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Vi sätter in precisionskrav och värden och löser ut \\(n\\): \\[0.02\\geq 1.96\\sqrt{\\left(\\frac{3800-n}{3800-1}\\right)\\frac{0.5(1-0.5)}{n}}\\] \\[\\left(\\frac{0.02}{1.96}\\right)^2\\geq \\left(\\frac{3800-n}{3799}\\right)\\frac{0.25}{n}\\] \\[\\left(\\frac{0.02}{1.96}\\right)^2 3799 \\geq \\left(\\frac{3800}{n}-1\\right)0.25\\] \\[\\left(\\frac{0.02}{1.96}\\right)^2 3799+0.25 \\geq \\left(\\frac{3800}{n}\\right)0.25\\] vilket ger att \\[n\\geq \\frac{3800\\cdot 0.25}{\\left(\\frac{0.02}{1.96}\\right)^2 3799+0.25}=1471.58.\\] Du kan även testa dig fram i R, enligt tidigare uppgifter. Svar: För att uppnå precisionskravet behövs ett stickprov med minst 1472 medlemmar. Kontroll av CGS: \\(np(1-p)=386 &gt; 5\\) så antagandet är uppfyllt. Beräkna nödvändig stickprovsstorlek \\(n\\) om ett 95 % konfidensintervall för andelen i populationen får vara max 3 procentenheter brett. Vi vet populationsstorleken och använder ändlighetskorrektion. \\(V(p)=\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}\\). Vi vet inte populationsandelen men utgår från att den är \\(p=0,5\\) vilket ger störst varians. Vi antar att \\(np(1-p)&gt;5\\) för att CGS ska gälla men måste kontrollera om det stämmer i slutet av uppgiften. Längden för ett 95% konfidensintervall för \\(p\\) ges av \\[2\\cdot z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}}\\] där \\(z_{\\alpha/2}=z_{0.025}=1.96\\). Vi sätter in värden givet precisionskravet \\[0,03 \\geq 2\\cdot 1.96\\sqrt{\\left(\\frac{3800-n}{3799}\\right)\\frac{0.25}{n}}.\\] På motsvarande sätt som i a) löser vi ut och landar på \\[n \\geq \\frac{3800 \\cdot 0.25}{\\left(\\frac{0.03}{2\\cdot 1.96}\\right)^23799+0.25}=2010.56.\\] Vi kan även testa oss fram i R motsvarande som i tidigare uppgifter. Svar: För att uppnå precisionskravet behövs ett stickprov på minst 2011 medlemmar. Övning 7.10 En forskare ville undersöka genomsnittlig IQ bland studenterna som går en kurs i statistik. På kursen går 70 studenter och forskaren drog ett OSU-UÅ bestående av 11 studenter fick genomföra ett IQ-test. Resultatet av testet blev: 98 121 124 105 104 102 102 128 96 92 94. Skatta medelfelet. Tolka medelfelet! Reflekta över förutsättningarna. Visa svar Mål: Skatta medelfelet för genomsnittlig IQ bland studenterna. Parameter: \\(\\mu\\) = genomsnittlig IQ för de 70 studenterna på kursen. Estimator: \\(\\bar{x}\\) = genomsnittlig IQ för de 11 studenterna i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Populationsstorlek: \\(N = 70\\). Urvalsstorlek: \\(n = 11\\). Vi använder ändlighetskorrektion varpå \\(V(\\bar{x})\\) skattas med \\(\\hat{V}(\\bar{x})=\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}\\). Beräkning: Medelfelet ges av \\[SE(\\bar{x})=\\sqrt{\\hat{V}(\\bar{x})}=\\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}}.\\] Vi gör beräkningar i R: # Töm minne rm(list = ls()) # Läs in data och nödvändiga parametrar iq &lt;- c(98, 121, 124, 105, 104, 102, 102, 128, 96, 92, 94) N &lt;- 70 n &lt;- 11 # Beräkna medelfel s2 &lt;- var(iq) vhatxbar &lt;- (1 - n/N)*s2/n medelfel &lt;- sqrt(vhatxbar) medelfel ## [1] 3.472826 Svar: Medelfelet är 3.47 vilket är den skattade standardavvikelsen i stickprovsmedelvärdets samplingfördelning. Övning 7.11 En forskare ville undersöka genomsnittlig IQ bland studenterna som går en kurs i statistik. På kursen går 70 studenter och forskaren drog ett OSU-UÅ bestående av 11 studenter som fick genomföra ett IQ-test. IQ anses följa normalfördelning och är konstruerat så att standardavvikelsen är 15 (dvs den anses känd). Resultatet av testet blev: 98 121 124 105 104 102 102 128 96 92 94. Beräkna ett 90% konfidensintervall för genomsnittlig IQ i bland studenterna på kursen. Var noga med förutsättningar! Tolka intervallet! Visa svar Mål: Med ett 90% konfidensintervall skatta genomsnittlig IQ bland studenterna på kursen. Parameter: \\(\\mu\\) = genomsnittlig IQ för de 70 studenterna på kursen. Estimator: \\(\\bar{x}\\) = genomsnittlig IQ för de 11 studenterna i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Populationsstorlek: \\(N\\) = 70. Urvalsstorlek: \\(n\\) = 11. Vi använder ändlighetskorrektion och känner populationsstandardavvikelsen varpå \\(V(\\bar{x})=\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}\\). Vi är givna i uppgiften att IQ anses följa en normalfördelning. Beräkning: Ett 90% konfidensintervall för \\(\\mu\\) ges av \\[\\bar{x}\\pm z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,6449\\) och \\(\\bar{x}=106\\). Insättning av värden i R ger: # Samma data som i uppg 118. I detta fall känner vi till populationsstandardavvikelsen och # #behöver därför ingen variansskattning. # Töm minne rm(list = ls()) # Läs in data och nödvändiga konstanter iq &lt;- c(98, 121, 124, 105, 104, 102, 102, 128, 96, 92, 94) N &lt;- 70 n &lt;- 11 sigma2 &lt;- 15^2 # Skattningar xbar &lt;- mean(iq) s2 &lt;- var(iq) vxbar &lt;- ((N - n)/(N - 1))*sigma2/n alpha &lt;- 0.1 z_alpha &lt;- qnorm((1- alpha/2)) ll &lt;- xbar - z_alpha*sqrt(vxbar) ul &lt;- xbar + z_alpha*sqrt(vxbar) resultat &lt;- c(xbar, ll, ul) resultat ## [1] 106.00000 99.12103 112.87897 Svar: Med 90% säkerhet täcker intervallet 99 till 113 genomsnittlig IQ för studenterna på kursen. Övning 7.12 En barnmorska arbetar på en vårdcentral som har ett visst patientunderlag. Hon ville jämföra om nyfödda barns födelsevikt vid vårdcentralen är mindre än genomsnittsvikten i Sverige som är 3600 gram för pojkar. Hon valde med OSU-UÅ ut 20 pojkar av de totalt 190 spädbarn som var listade vid vårdcentralen. Hon frågade därefter föräldarna om godkännande och tittade sedan i barnens journaler. Födelsevikt kan betraktas som normalfördelad variabel. Följande födelsevikter erhölls: 3017 3523 2609 2518 2556 2659 3103 2657 3272 4153 3729 3711 3223 2668 3042 3545 3530 2209 2470 Genomför en hypotesprövning på 5-procentsnivån för att undersöka om barnmorskan har belägg för sin misstanke. Visa svar Mål: Testa om nyfödda barns födelsevikt vid kliniken i genomsnitt är mindre än medelvikten i Sverige som är 3600 gram. Parameter: \\(\\mu\\) = medelvikten bland nyfödda i Sverige. Estimator: \\(\\bar{x}\\) = medelvikten i stickprovet. Hypoteser: \\(H: \\mu_0=3600\\) versus \\(H_1: \\mu&lt;3600\\) Signifikansnivå: \\(\\alpha=0.05\\). Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Populationsstorlek: \\(N\\) = 190. Urvalsstorlek: \\(n\\) = 20. Eftersom \\(\\frac{n}{N}&gt;0,1\\) och vi inte vet populationsstandardavvikelsen skattas \\(V(\\bar{x})\\) med \\(\\hat{V}(\\bar{x})=\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}\\). Vi är givna i uppgiften att födelsevikten kan betraktas som normalförderdelad. Testfunktion: \\[Z=\\frac{\\bar{x}-\\mu_0}{\\sqrt{\\hat{V}(\\bar{x})}}\\] som är approximativt \\(N(0;1)\\) när nollhypotesen är sann. Beslutsregel: Vi har en ensidig mothypotes vilket ger \\(z_{\\alpha}=z_{0,05}=1,6449\\) så vi förkastar nollhypotesen om \\(Z_{obs}&lt;-z_{0,05}=-1,6449\\). Beräkning: Först sammanställer vi data. # Töm minnet rm(list =ls()) gram &lt;- c(3017, 3523, 2609, 2518, 2556, 2659, 3103, 2657, 3272, 4153, 3729, 3711, 3223, 2668, 3042, 3545, 3530, 2209, 2470, 3120) N = 190 n &lt;- 20 mu0 &lt;- 3600 # Skattningar xbar &lt;- mean(gram) s2 &lt;- var(gram) vhatxbar &lt;- (1 - (n/N))*(s2/n) # Test alpha &lt;- 0.05 tobs &lt;- (xbar - mu0)/sqrt(vhatxbar) p_value &lt;- pt(tobs, n-1) p_value ## [1] 5.336026e-05 Medelvikten bland vårdcentralen är 534.3 lägre än genomsnittvikten i Sverige (\\(p\\leq 0.001\\)). Svar: Vi kan på 5% signifikansnivå påvisa att födelsevikten på kliniken är mindre än genomsnittet i Sverige. Urvalet är ett OSU-UÅ, vilket gör att punktskattningen och variansskattningen är väntevärdesriktiga. Dock är urvalet litet. Därför måste vi förlita oss på att variabeln födelsevikt är normalfördelad i populationen för att kunna göra testet. Eftersom populationsvariansen är okänd används \\(t\\)-fördelningen. Övning 7.13 (Baserad på Mendelhall et al. (1996)) Vi vill undersöka situationen i tillverkningsindustrin genom att få en preliminär uppfattning om antalet anställda ett visst år. Anta att tillverkningsindustrin kan delas upp i 80 kategorier. Från en lista med olika typer av tillverkningsindustrier gör vi därför ett systematiskt urval, där var femte industri väljs. Genom att undersöka de valda industrierna erhålls följande resultat: # anställda 1987 (1000-tals) data1987 &lt;- c(72.4, 45.4, 57.9, 129.1, 110, 53.2, 31.7, 16.1, 384.7, 80.9, 64, 151.9, 112.3, 389.1, 166.7, 88.9) # anställda 1997 (1000-tals) data1991 &lt;- c(65.5, 49.3, 54.7, 130.3, 110.6, 46.3, 36.6, 16.4, 388.9, 77, 56.3, 126, 94.1, 369.9, 135.8, 78) # tot. antal kategorier N &lt;- 80 Skatta den genomsnittliga förändringen i antalet anställda mellan 1987 och 1991. Beräkna felmarginalen. Visa svar n &lt;- 16 diffs &lt;- data1991 - data1987 xbar_diff &lt;- mean(diffs) s2 &lt;- var(diffs) vhatxbar_diff &lt;- (1 - n/N)*s2/n alpha &lt;- 0.05 t_alpha &lt;- qt((1-alpha/2), df = (n-1)) t_alpha*sqrt(vhatxbar_diff) ## [1] 5.226613 Övning 7.14 En undersökning i USA vill undersöka andelen positiva till dödsstraff. Tidigare studier visar att ungefär 60% i USA är positiva. Vilken stickprovsstorlek behövs vid ett OSU för att vi med 90% konfidensgrad ska ha som mest 3 procents felmarginal för andelen positiva? Mål: Beräkna nödvändig stickprovsstorlek för ett 90% konfidensintervall för andelen positiva till dödsstraff i USA där felmarginalen får vara max tre procentenheter. Parameter: \\(p\\) = andelen positiva i USA. Estimator: \\(\\hat{p}\\) = andelen positiva i stickprovet. Förutsättningar: OSU ger att \\(E(\\hat{p})=p\\). Vi vet inte populationsstorleken men har en uppfattning om andelen i populationen. Därför skattas \\(V(p)\\) med \\(V(\\hat{p})=\\frac{p(1-p)}{n}\\). Vi utgår från att \\(np(1-p)&gt;5\\) för att CGS ska gälla men måste kontrollera om antagandet är uppfyllt på slutet. Beräkning: Felmarginalen ges av \\[z_{\\alpha/2}\\sqrt{\\frac{p(1-p)}{n}}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,6449\\). Vi sätter in värden. # vi har en stor population och kan approximera situationen som ett OSU-MÅ. Det går att ändra värdena på n för att se vilket n som ger vår önskade minsta stickprovsstorlek. Vi vill att uttrycket nedan ska vara lika med eller mindre än 0.03. n &lt;- 20 p &lt;- 0.6 z &lt;- qnorm(0.95) z * sqrt( ( p * (1-p) ) / n ) ## [1] 0.1801847 Svar: För att uppnå precisionskraven behövs ett stickprov på minst 722 individer. Kontroll av CGS: \\(np(1-p)=173&gt;5\\) så antagandet är uppfyllt. Anta nu att vill nu undersöka andelen positiva i den lilla staden Sigmaville med 3800 invånare där tidigare undersökningar också visat att andelen positiva är 60%. Vilken stickprovsstorlek behövs nu vid ett OSU för att vi med 90% konfidensgrad ska ha som mest 3 procents felmarginal för andelen positiva? Jämför med ovanstående undersökning med undersökningen för USA. Vad kan vi konstatera vad gäller betydelsen av populationens storlek för stickprovsstorleken? Mål: Beräkna nödvändig stickprovsstorlek för ett 90% konfidensintervall för andelen positiva till dödsstraff i USA där felmarginalen får vara max tre procentenheter. Parameter: \\(p\\) = andelen positiva i USA. Estimator: \\(\\hat{p}\\) = andelen positiva i stickprovet. Förutsättningar: OSU ger att \\(E(\\hat{p})=p\\). Vi vet populationsstorleken och har en uppfattning om andelen i populationen. Därför skattas \\(V(p)\\) mzed \\(V(\\hat{p})=\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}\\). Vi utgår från att \\(np(1-p)&gt;5\\) för att CGS ska gälla men måste kontrollera om antagandet är uppfyllt på slutet. Beräkning: Vi gör samma sak som i (a) men med ändlighetskorrektion. Felmarginalen för \\(p\\) ges av \\[ z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,6449\\). Vi sätter in värden: # vi har OSU-UÅ. Det går att ändra värdena på n för att se vilket n som ger vår önskade minsta stickprovsstorlek. Vi vill att uttrycket nedan ska vara lika med eller mindre än 0.03. N &lt;- 3800 n &lt;- 200 p &lt;- 0.6 z &lt;- qnorm(0.95) z * sqrt( ( (N - n)/(N-1) ) * ( p * (1-p) ) / n ) ## [1] 0.05546698 Svar: När vi vet och tar hänsyn till populationsstorleken behövs ett stickprov på minst 607 individer för att uppnå precisionskraven. Kontroll för CGS: \\(np(1-p)=146&gt;5\\) alltså är antagandet uppfyllt. Anta nu att en undersökare i en helt annan undersökning är intresserad av att skatta den totala vikten bland kalvar som fått en ny sorts foder. Totalt finns det \\(N = 1000\\) kalvar, men att väga varenda kalv skulle ta för mycket tid. Därför dras ett stickprov bestående av \\(n\\) kalvar, där felmarginalen med konfidensgraden 95% får vara som mest 20 kg. Från tidigare studier vet vi att populationsvariansen är \\(\\sigma^2 = 900\\). Hur stort ska stickprovet vara? Observera: Använd inte formlerna för beräkning av stickprovsstorlekar i formelsamlingen för att lösa uppgiften. Försök att antingen lösa ut stickprovsstorleken algebraiskt eller finn \\(n\\) numeriskt genom att prova er fram på miniräknaren. Mål: Beräkna hur stort stickprov som behövs när konfidensgraden är 95% och felmarginalen får vara max 20 kg. Parameter: \\(\\tau=N\\mu\\) = den totala vikten bland kalvarna i populationen. Estimator: \\(\\hat{\\tau}=N\\bar{x}\\) = den totala vikten bland kalvarna i stickprovet. Förutsättningar: \\(E(\\hat{\\tau})=NE(\\bar{x})=N\\mu=\\tau\\). Vi känner populationsstorleken och populationsvariansen så \\(V(\\tau)\\) skattas med \\(V(\\hat{\\tau})=N^2V(\\bar{x})=N^2\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}\\). Vi utgår från att vikten är normalfördelad och resultatet bygger på antagandet. Beräkning: Den statistiska felmarginalen ges av \\[z_{\\alpha/2}\\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{\\sigma^2}{n}}.\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Vi sätter in värden: # Testa dig fram genom att ändra på n. n &lt;- 20 N &lt;- 1000 sigma2 &lt;- 900 maxbredd &lt;- 20 z &lt;- qnorm(0.975) z * sqrt( ((N-n)/(N-1)) * (sigma2/n) ) ## [1] 13.02221 Svar: Med konfidensgraden 95% är den minsta stickprovsstorleken som ger en felmarginal på max 20 kg \\(n=9\\), givet att vikten är normalfördelad. rm(list=ls()) Övning 7.15 En population består av 6000 företag. Ett företag är intresserat av att uppskatta medelvärdet och totalen i populationen. Företagen delades in i tre strata efter storlek. Ur populationen drogs sedan ett proportionellt stratifierat urval om sammanlagt 600 företag. Tabell 1 presenterar en sammanställning från undersökningen. Stratum \\(N_j\\) \\(\\bar{x}_j\\) \\(s_j\\) Små företag 4000 50 5 Medelstora företag 1700 100 12 Stora företag 300 1000 90 Beräkna ett 95% konfidensintervall för medelvärdet i populationen. Mål: Beräkna ett 95% konfidensintervall för medelvärdet i populationen. Parameter: \\(\\mu\\) = medelvärdet i populationen. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^{K}\\frac{N_j}{N}\\bar{x}_j\\) = medelvärdet i stickprovet. Förutsättningar: Om vi förutsätter att företagen i respektive stratum har dragits genom OSU har vi \\(E(\\bar{x}_{st})=\\mu\\). Populationsstorlek: \\(N\\) = 6000. Urvalsstorlek: $n = 600. \\(\\frac{n}{N}=0,1\\) men eftersom vi vet populationsstorleken använder vi ändlighetskorrektion. \\(V(\\bar{x}_{st})\\) skattas därför med \\(\\hat{V}(\\bar{x}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Populationsfördelningen är okänd men vi har ett stort stickprov och kan förlita oss på CGS. Beräkning: Ett 95% konfidensintervall för medelvärdet i populationen ges av \\[\\bar{x}_{st}\\pm z_{\\alpha/2}\\sqrt{\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}}\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Stratumstorlekarna erhålls genom att multiplicera den totala stickprovsstorleken med respektive populationsproportion. Små företag: 400, medelstora företag: 170, stora företag: 30. Vi behöver \\(\\bar{x}_{st}\\) som ges av \\[\\bar{x}_{st}=\\sum_{j=1}^{K}\\frac{N_j}{N}\\bar{x}_j=\\frac{4000}{6000}50+\\frac{1700}{6000}100+\\frac{300}{6000}1000=111,667,\\] vilket vi också kan ta fram i R. # stratifierat urval. Vi kommer nu att få nytta av R:s förmåga att definiera variabler med flera värden i sig. # först skapar vi data. Ntot &lt;- 6000 # populationsstorlek. Nj &lt;- c(4000, 1700, 300) # storlekar på strata. Observera att sum(Nj) = 6000 = Ntot. nj &lt;- c(400, 170, 30) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. x.bar.j &lt;- c(50, 100, 1000) # stickprovsmedelvärden per stratum. sj &lt;- c(5, 12, 90) # stickprovsstandardavvikelser per stratum. # beräkning av stickprovsmedelvärde vid stratifierat urval. x.bar.tot &lt;- (4000/6000) * 50 + (1700/6000) * 100 + (300/6000) * 1000 # alternativt... använd R:s förmåga att hantera värden i variabler i en logisk följd. x.bar.tot &lt;- sum( (Nj / Ntot) * x.bar.j ) Den skattade variansen för \\(\\bar{x}_{st}\\) ges av: # beräkning av varians för estimatorn. Var.hat.theta.hat &lt;- (4000/6000)^2 * (1 - (400/4000) ) * (5^2 / 400) + (1700/6000)^2 * (1 - (170/1700) ) * (12^2 / 170) + (300/6000)^2 * (1 - (30/300) ) * (90^2 / 30) # alternativt... Var.hat.theta.hat &lt;- sum( (Nj / Ntot)^2 * (1 - (nj / Nj) ) * (sj^2 / nj)) Konfidensintervallets gränser ges av: lower.lim &lt;- x.bar.tot - qnorm(0.975) * sqrt(Var.hat.theta.hat) upper.lim &lt;- x.bar.tot + qnorm(0.975) * sqrt(Var.hat.theta.hat) Svar: Med 95% säkerhet täcker intervallet 110,31 till 113,03 medelvärdet i populationen. Beräkna ett 99% konfidensintervall för totalen i populationen. Mål: Beräkna ett 99% konfidensintervall för totalen i populationen. Parameter: \\(\\tau\\) = totalen i populationen. Estimator: \\(\\hat{\\tau}_{st}=\\sum_{j=1}^{K}N_j\\bar{x}_j\\) = totalen i stickprovet. Förutsättningar: Om vi förutsätter att företagen i respektive stratum har dragits genom OSU har vi \\(E(\\hat{\\tau}_{st})=\\tau\\). Populationsstorlek: \\(N\\) = 6000. Urvalsstorlek: \\(n\\) = 600. \\(\\frac{n}{N}=0,1\\) men eftersom vi vet populationsstorleken använder vi ändlighetskorrektion. \\(V(\\tau)\\) skattas därför med \\(\\hat{V}(\\hat{\\tau}_{st})=\\sum_{j=1}^{K}N_j^2\\hat{V}(\\bar{x}_j)=\\sum_{j=1}^{K}N_j^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Populationsfördelningen är okänd men vi har ett stort stickprov och kan förlita oss på CGS. Beräkning: Stickprovsstotalen ges av: tau.est &lt;- 4000 * 50 + 1700 * 100 + 300 * 1000 Den skattade variansen för \\(\\hat{\\tau}_{st}\\) ges av Var.hat.theta.hat &lt;- 4000^2 * (1 - (400/4000) ) * (5^2 / 400) + 1700^2 * (1 - (170/1700) ) * (12^2 / 170) + 300^2 * (1 - (30/300) ) * (90^2 / 30) Ett 99% konfidensintervall för populationstotalen ges av \\[\\hat{\\tau}_{st}\\pm z_{\\alpha/2}\\sqrt{\\sum_{j=1}^{K}N_j^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}}\\] där \\(z_{\\alpha/2}=z_{0,005}=2,5758\\). Insättning av värden ger: lower.lim &lt;- tau.est - qnorm(0.995) * sqrt(Var.hat.theta.hat) upper.lim &lt;- tau.est + qnorm(0.995) * sqrt(Var.hat.theta.hat) Svar: Med 99% säkerhet täcker intervallet 657146 till 682854 totalen i populationen. Tror du att man skulle erhålla sämre eller bättre precision om man i stället dragit ett OSU om 600 företag? Motivera ditt svar! Om det finns en skillnad mellan olika strata med avseende på stratifieringsvariabeln ger ett stratifierat urval ofta bättre precision än ett OSU. Ett OSU motsvarar om det inte finns någon skillnad mellan olika strata vad gäller stratifieringsvariabeln. Därför skulle ett OSU antagligen ge sämre precision i det här fallet. Om du vid en senare tidpunkt skulle genomföra en motsvarande undersökning med ett nytt stickprov om 600 företag ur samma population, skulle du då använda samma allokering som ovan? Om inte, beräkna den allokering som du då anser skulle vara bäst avseende skattningens precision. Eftersom storleken på respektive stratum skiljer sig så pass mycket skulle en lika allokering kunna ge bättre precision. Den proportionella allokeringen ger förhållandevis få stora företag. Med lika allokering skulle variansskattningen i (a) bli var.lika.allokering.mu &lt;- (4000/6000)^2 * (1 - (200/4000) ) * (5^2 / 200) + (1700/6000)^2 * (1 - (200/1700) ) * (12^2 / 200) + (300/6000)^2 * (1 - (200/300) ) * (90^2 / 200) # denna varians är mindre än den vid prop. allokering. vilket är betydligt mindre än variansskattningen vid proportionell allokering som var 0,6937. Den skattade variansen i (b) skulle bli var.lika.allokering.tau &lt;- 4000^2 * (1 - (200/4000) ) * (5^2 / 200) + 1700^2 * (1 - (200/1700) ) * (12^2 / 200) + 300^2 * (1 - (200/300) ) * (90^2 / 200) som också är betydligt mindre än den skattade variansen vid proportionell allokering som var 24903200. Alltså ger lika allokering högre precision i det här fallet. rm(list=ls()) Övning 7.16 Ett försäljningsdistrikt omfattade \\(20\\,000\\) hushåll i tätortsbebyggelsen och \\(10\\,000\\) från landsbygden. Till en marknadsundersökning drogs med ett OSU utan återläggning 250 hushåll från tätortsbebyggelsen. På samma sätt drogs från landsbygdshushållen 200 hushåll. Man studerade bl a hushållens konsumtion av en viss förbrukningsartikel under den senaste månaden. Resultaten från undersökningen återges i tabellen nedan. Stadsdel \\(n_j\\) \\(\\bar{x}_j\\) \\(s_j\\) Hushåll i tätortsbebyggelse 250 190 kr 90 Landsbygdshushåll 200 150 kr 30 Beräkna ett 95% konfidensintervall för den genomsnittliga förbrukningen per hushåll i populationen. Mål: Skatta den genomsnittliga förbrukningen per hushåll av en viss artikel med 95% konfidens. Parameter: \\(\\mu\\) = den genomsnittliga förbrukningen i försäljningsdistriktet. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^K\\frac{N_j}{N}\\bar{x}_j\\) = den genomsnittliga förbrukningen bland de 450 hushållen i stickprovet. Förutsättningar: OSU ger att \\(E(\\bar{x}_{st})=\\mu\\). Populationsstorlek: \\(N\\) = 30000. Urvalsstorlek: \\(n\\) = 450. \\(\\frac{n}{N}&lt;0,1\\) men eftersom vi vet populationsstorleken använder vi ändlighetskorrektion. Vi känner inte populationsfördelningen så \\(V(\\bar{x}_{st})\\) skattas med \\(\\hat{V}(\\bar{x}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Stickprovet är stort så vi kan förlita oss på CGS. Beräkning: Stickprovsmedelvärdet ges av # först skapar vi data. Ntot &lt;- 30000 # populationsstorlek. Nj &lt;- c(20000, 10000) # storlekar på strata. Observera att sum(Nj) = 6000 = Ntot. nj &lt;- c(250, 200) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. x.bar.j &lt;- c(190, 150) # stickprovsmedelvärden per stratum. sj &lt;- c(90, 30) # stickprovsstandardavvikelser per stratum. # Se uppgift 124 för bekrivningar av steg. Jämförelse med formler i formelsamling för stratifierat urval uppmuntras! x.bar.tot &lt;- (20000/30000) * 190 + (10000/30000) * 150 Variansskattningen för \\(\\bar{x}_{st}\\) ges av Var.hat.theta.hat.mu &lt;- (20000/30000)^2 * (1 - (250/20000) ) * (90^2 / 250) + (10000/30000)^2 * (1 - (200/10000) ) * (30^2 / 200) Ett 95% konfidensintervall för medelvärdet i populationen ges av: lower.lim &lt;- x.bar.tot - qnorm(0.975) * sqrt(Var.hat.theta.hat.mu) upper.lim &lt;- x.bar.tot + qnorm(0.975) * sqrt(Var.hat.theta.hat.mu) Svar: Med 95% säkerhet täcker intervallet 169,15 till 184,19 den genomsnittliga konsumtionen i populationen. Beräkna ett 95% konfidensintervall för den totala förbrukningen i kronor i populationen. Mål: Skatta den totala förbrukningen i försäljningsdistriktet av en viss artikel med 95% konfidens. Parameter: \\(\\tau\\) = den totala förbrukningen i försäljningsdistriktet. Estimator: \\(\\hat{\\tau}_{st}=\\sum_{j=1}^{K}N_j\\bar{x}_j\\) = den totala förbrukningen i stickprovet. Förutsättningar: OSU ger att \\(E(\\hat{\\tau}_{st})=\\tau\\). Populationsstorlek: \\(N\\) = 30000. Urvalsstorlek: \\(n\\) = 450. \\(\\frac{n}{N}&lt;0,1\\) men eftersom vi vet populationsstorleken använder vi ändlighetskorrektion. Vi känner inte populationsfördelningen och \\(V(\\tau)\\) skattas därför med \\(\\hat{V}(\\hat{\\tau}_{st})=\\sum_{j=1}^{K}N_j^2\\hat{V}(\\bar{x}_j)=\\sum_{j=1}^{K}N_j^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Populationsfördelningen är okänd men vi har ett stort stickprov och kan förlita oss på CGS. Beräkning: Stickprovstotalen ges av: tau.est &lt;- 20000 * 190 + 10000 * 150 Variansskattning: Var.hat.theta.hat.tau &lt;- 20000^2 * (1 - (250/20000) ) * (90^2 / 250) + 10000^2 * (1 - (200/10000) ) * (30^2 / 200) Ett 95% konfidensintervall för den totala förbrukningen ges av \\[\\hat{\\tau}_{st}\\pm z_{\\alpha/2}\\sqrt{\\sum_{j=1}^{K}N_j^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}}\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Insättning av värden ger lower.lim &lt;- tau.est - qnorm(0.995) * sqrt(Var.hat.theta.hat.tau) upper.lim &lt;- tau.est + qnorm(0.995) * sqrt(Var.hat.theta.hat.tau) Svar: Med 95% säkerhet täcker intervallet 5074481 kronor till 5525519 kronor den totala förbrukningen i försäljningsdistriktet. Med hjälp av informationen från undersökningen, vilken är din uppfattning om den ursprungliga allokeringen? Hade det, för precisionen i skattningarna, varit lämpligare med en annan allokering? Låt oss testa med proportionell allokering. Då ska vi ha \\(n_1\\) = 300 och \\(n_2\\) = 150 eftersom vi har fler hushåll i tätortsbebyggelsen än från landsbygden. Vi antar att stickprovsmedelvärden och standradavvikelser inte förändras då vi inte har tillgång till rådata. Då fås följande data: Ntot &lt;- 30000 # populationsstorlek. Nj &lt;- c(20000, 10000) # storlekar på strata. nj &lt;- c(300, 150) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. x.bar.j &lt;- c(190, 150) # stickprovsmedelvärden per stratum. sj &lt;- c(90, 30) # stickprovsstandardavvikelser per stratum. Variansen för medelvärdesestimatorn utifrån ett proportionellt urval beräknas. Variansen sjunker! Var.hat.theta.hat.mu.prop &lt;- (20000/30000)^2 * (1 - (300/20000) ) * (90^2 / 300) + (10000/30000)^2 * (1 - (150/10000) ) * (30^2 / 150) Variansen för totalestimatorn sjunker också! Var.hat.theta.hat.tau.prop &lt;- 20000^2 * (1 - (300/20000) ) * (90^2 / 300) + 10000^2 * (1 - (150/10000) ) * (30^2 / 150) rm(list=ls()) Övning 7.16 För att få en uppfattning om relativa andelen körkortsinnehavare i ett militärområde i Sverige bestämmer man sig för att göra en intervjuundersökning. Befolkningen inom området indelas i tre strata, med åldern som stratifieringsvariabel. Urvalet sker enligt principen för proportionellt stratifierat urval. Sammanlagt 800 individer intervjuas och resultat presenteras nedan. Åldersgrupp \\(n_j\\) \\(\\hat{p}_j\\) 18-34 200 0,5 35-49 400 0,3 50 och över 200 0,1 Kostnaderna för intervjuerna uppgår till 200 kr per individ, dvs 160 000 kr totalt. De administrativa kostnaderna i samband med stratifieringen belöper sig till 6 000 kr. Beräkna hur stor besparing man lyckas uppnå genom proportionellt stratifierat urval i jämförelse med OSU, om man vill ha samma precision i skattningen, dvs samma standardavvikelse (medelfel) för skattningen. Folkmängden i området uppgår till 500 000. Förtydligande: Vid OSU blir det naturligtvis inga stratifieringskostnader. Utgå från att vi antar \\(p=0.3\\) när stickprovsstorlek beräknas med OSU. Mål: Beräkna hur stor besparing en lyckas uppnå genom proportionellt stratifierat urval i jämförelse med OSU. Parameter: \\(p\\) = populationsandelen. Estimator: \\(\\hat{p}\\) = stickprovsandelen. Förutsättningar: OSU ger att \\(E(\\hat{p})=p\\). Beräkning: Vi börjar med att beräkna medelfelet utifrån det stratifierade urvalet. Medelfelet för stickprovsandelen ges av \\[SE(\\hat{p}_{st})=\\sqrt{\\hat{V}(\\hat{p}_{st})}=\\sqrt{\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{\\hat{p}(1-\\hat{p})}{n_j - 1}}.\\] Vi beräknar först variansskattningen: # vi börjar med att sammanställa våra data. Ntot &lt;- 500000 # populationsstorlek. Nj &lt;- c(125000, 250000, 125000) # storlekar på strata. nj &lt;- c(200, 400, 200) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. pj.hat &lt;- c(0.5, 0.3, 0.1) # skattade andelar. # vi beräknar sedan variansen för estimatorn vid prop. stratifierat urval. var.hat.theta.hat &lt;- (125000 / 500000)^2 * (1 - (200/125000)) * (0.25/199) + (250000 / 500000)^2 * (1 - (400/250000)) * (0.21/399) + (125000 / 500000)^2 * (1 - (200/125000)) * (0.09/199) Medelfelet blir då se.propstrat &lt;- sqrt(var.hat.theta.hat) Vi beräknar sedan nödvändig stickprovsstorlek vid OSU för att uppnå samma medelfel. Medelfelet för stickprovsandelen vid OSU ges av \\[SE(\\hat{p})=\\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{\\hat{p}(1-\\hat{p})}{n-1}}.\\] Vi sätter in värden enligt precisionskravet och löser ut \\(n\\): \\[0,0154=\\sqrt{\\left(1-\\frac{n}{500000}\\right)\\frac{0,3(1-0,3)}{n-1}}\\] \\[0,0154^2(n-1)=\\left(1-\\frac{n}{500000}\\right)0,21\\] \\[n\\left(0,0154^2+\\frac{1}{500000}0,21\\right)=0,21+0,0154^2\\] \\[n=\\frac{0,21+0,0154^2}{0,0154^2+\\frac{0,21}{500000}}=884,91.\\] Vi kan även testa oss fram med R: # Testa olika värden på n. Som skattning av p använder vi estimatorn för p vid OSU-UÅ. p.hat &lt;- (200*0.5 + 400*0.3 + 200*0.1)/800 N &lt;- 500000 n &lt;- 20 sqrt( (1-(n/N)) * (p.hat * (1-p.hat) )/(n-1) ) ## [1] 0.1051294 Vid OSU behövs alltså ett stickprov på 885 individer vilket ger kostnaden \\(885\\cdot200=177000\\) vilket är \\(177000-166000=11000\\) kronor mer än vid stratifierat urval. Svar: Besparingen som uppnås genom att använda stratifierat urval med proportionell allokering jämfört med OSU är 11000 kronor. rm(list=ls()) Övning 7.17 I en stad där det finns 5000 personer i åldern 20-24 år och 8000 i åldern 25-34 år, uttages genom OSU-UÅ 100 personer ur den första åldersgruppen och på samma sätt 200 personer ur den andra åldersgruppen. Genom intervjuer erhålls uppgifter om antalet inköpta veckotidningar per vecka och utgiften för dessa, vilka presenteras nedan. Antal inköpta veckotidningar 18-24 25-34 0 40 50 1 25 80 2 12 36 3 8 9 4 4 5 5 5 11 6 6 7 Antal person 100 200 Medelutgift i kronor för veckotidningar \\(\\bar{x}=1,20\\) \\(\\bar{y}=1,60\\) Standardavvikelse för utgiften \\(s_x=0,6\\) \\(s_{y}=0,8\\) Ange ett punktestimat för det totala antalet veckotidningar som inköps under en vecka av samtliga 13 000 personer i åldern 20-34 år. Mål: Punktskatta det totala antalet veckotidningar som inköps under en vecka. Parameter: \\(\\tau\\) = det totala antalet veckotidningar som köps av populationen. Estimator: \\(\\hat{\\tau}=N\\bar{x}=N\\frac{1}{n}\\sum_{i=1}^{n}f_ix_i\\) = det totala antalet veckotidningar som köps av stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{\\tau})=NE(\\bar{x})=N\\mu=\\tau\\). Beräkning: Vi börjar med att utöka tabellen Tidningar Individer Individer \\(\\cdot\\) tidningar Individer \\(\\cdot\\) tidningar\\(^2\\) 0 90 0 0 1 105 105 105 2 48 96 192 3 17 51 153 4 9 36 144 5 16 80 400 6 13 78 468 Summa 446 1462 En punktskattning av populationstotalen ges av: # vi börjar med att sammanställa data. Först betämmer vi tot. antal invider som köpt ett visst antal tidningar. individer &lt;- c(40+50, 25+80, 12+36, 8+9, 4+5, 5+11, 6+7) # Sedan beräknar vi ett punktestimat för totala antalet inköpta veckotidningar. Vi har ett stickprov på tot. 300 observationer och en tot. populationsstorlek på 13000 individer. Vi börjar med att beräkna &#39;tidningar*individer&#39; för att få fram totala antalet inköpta tidningar. tidningar &lt;- c(0, 1, 2, 3, 4, 5, 6) individer.tidningar &lt;- sum(individer * tidningar ) point.est &lt;- 13000 * (1/300) * individer.tidningar Svar: Ett punktestimat för det totala antalet sålda veckotidningar är 19327. Ange ett 99% KI för totalantalet inköpta veckotidningar i populationen. Mål: Intervallskatta antalet inköpta veckotidningar i populationen med 99% konfidens. Parameter: \\(\\tau\\) = det totala antalet veckotidningar som köps av populationen. Estimator: \\(\\hat{\\tau}=N\\bar{x}=N\\frac{1}{n}\\sum_{i=1}^{n}f_ix_i\\) = det totala antalet veckotidningar som köps av stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{\\tau})=NE(\\bar{x})=N\\mu=\\tau\\). Populationsstorlek: = 13000. Urvalsstorlek: = 300. Vi känner populationsstorleken men inte populationsfördelningen varpå \\(V(\\tau)\\) skattas med \\(\\hat{V}(\\hat{\\tau})=N^2\\hat{V}(\\bar{x})=N^2\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}\\). Populationsfördelningen är okänd men vi har ett stort stickprov och kan förlita oss på CGS. Beräkning: För att beräkna stickprovsvariansen krävs att vi först använder R och beräknar ’tidningar*individer^2’. individer.tidningar2 &lt;- sum(individer.tidningar^2 ) Stickprovsvariansen blir: s2 &lt;- ( (individer.tidningar2 - ( individer.tidningar2^2 / 300 ) ) / (300-1) ) Den skattade variansen för punktskattningen av det totala antalet sålda tidningar är var.hat.theta.hat &lt;- 13000^2 * (1 - (300 / 13000)) * (s2 / 300) Ett 99% konfidensintervall för det totala antalet sålda tidningar ges av: lower.lim &lt;- point.est - qnorm(0.995) * sqrt(var.hat.theta.hat) ## Warning in sqrt(var.hat.theta.hat): NaNs produced upper.lim &lt;- point.est + qnorm(0.995) * sqrt(var.hat.theta.hat) ## Warning in sqrt(var.hat.theta.hat): NaNs produced Svar: Med 99% säkerhet täcker intervallet 16203 till 22451 det totala antalet sålda tidningar. rm(list=ls()) Övning 7.18 En kommun ville undersöka en utgiftspost bland barnen i kommunens skolor. Populationen stratifierades därför utifrån åldersgrupp och sedan drogs ett OSU-UÅ från respektiva stratum. Undersökningen presenteras i tabellen nedan. Skolstadium \\(N_j\\) \\(n_j\\) \\(\\bar{x}_j\\) \\(s_j\\) Lågstadium 1300 140 95 28 Mellanstadium 1800 240 75 22 Högstadium 1900 220 63 16 Punktskatta populationens genomsnittliga utgift i kronor. Mål: Punktskatta populationens genomsnittliga utgift i kronor. Parameter: \\(\\mu\\) = den genomsnittliga utgiften i populationen. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^K\\frac{N_j}{N}\\bar{x}_j\\) = den genomsnittliga utgiften i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x}_{st})=\\mu\\). Beräkning: En punktskattning av populationens genomsnittliga utgift ges av: # först skapar vi data. Ntot &lt;- 50000 # populationsstorlek. Nj &lt;- c(1300, 1800, 1900) # storlekar på strata. nj &lt;- c(140, 240, 220) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. x.bar.j &lt;- c(95, 75, 63) # stickprovsmedelvärden per stratum. sj &lt;- c(28, 22, 16) # stickprovsstandardavvikelser per stratum. # (a) Se uppgift 124 för bekrivningar av steg. Jämförelse med formler i formelsamling för stratifierat urval uppmuntras! x.bar.tot &lt;- (1300/5000) * 95 + (1800/5000) * 75 + (1900/5000) * 63 Svar: Punktskattningen av populationens genomsnittliga utgift är 75,64 kronor. Beräkna den statistiska felmarginalen för skattningen i (a). Mål: Beräkna den statistiska felmarginalen för punktskattningen av populationens genomsnittliga utgift. Parameter: \\(\\mu\\) = den genomsnittliga utgiften i populationen. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^K\\frac{N_j}{N}\\bar{x}_j\\) = den genomsnittliga utgiften i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x}_{st})=\\mu\\). Populationsstorlek: \\(N\\) = 5000. Urvalsstorlek: \\(n\\) = 600. Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\bar{x}_{st})\\) med \\(\\hat{V}(\\bar{x}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Vi har ett stort stickprov och kan förlita och på CGS. Beräkning: Vi skattar först punktskattningens varians som ges av: Var.hat.theta.hat.mu &lt;- (1300/5000)^2 * (1 - (140/1300) ) * (28^2 / 140) + (1800/5000)^2 * (1 - (240/1800) ) * (22^2 / 240) + (1900/5000)^2 * (1 - (220/1900) ) * (16^2 / 220) Den statistiska felmarginalen för \\(\\bar{x}_{st}\\) med 95% konfidens ges av: qnorm(0.975) * Var.hat.theta.hat.mu ## [1] 1.397213 Svar: Den statistiska felmarginalen vid 95% konfidens för skattningen i (a) är 1,6549. Skatta den totala utgiften för samtliga individer i populationen med ett 95% KI. Mål: Skatta den totala utgiften för samtliga individer i populationen med konfidensgraden 95%. Parameter: \\(\\tau\\) = den totala utgiften för samtliga individer i populationen. Estimator: \\(\\hat{\\tau}_{st}=\\sum_{j=1}^KN_j\\bar{x}_j\\) = den totala utgiften för individerna i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{\\tau})=NE(\\bar{x})=N\\mu=\\tau\\). Populationsstorlek: \\(N\\) = 5000. Urvalsstorlek: \\(n\\) = 6000. Vi känner populationsstorleken men inte populationsfördelningen varpå \\(V(\\tau)\\) skattas med \\(\\hat{V}(\\hat{\\tau}_{st})=\\sum_{j=1}^{K}N_j^2\\hat{V}(\\bar{x}_j)=\\sum_{j=1}^{K}N_j^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Populationsfördelningen är okänd men vi har ett stort stickprov och kan förlita oss på CGS. Beräkning: En punktskattning för den totala utgiften är \\(\\hat{\\tau}=N\\bar{x}_{st}=5000\\cdot75,64=378200\\). Den skattade variansen för punktskattningen ges av: point.est &lt;- Ntot * x.bar.tot # variansskattning Var.hat.theta.hat.tau &lt;- (1300)^2 * (1 - (140/1300) ) * (28^2 / 140) + (1800)^2 * (1 - (240/1800) ) * (22^2 / 240) + (1900)^2 * (1 - (220/1900) ) * (16^2 / 220) #konfidensintervallet. lower.lim &lt;- point.est - qnorm(0.975) * sqrt(Var.hat.theta.hat.tau) upper.lim &lt;- point.est + qnorm(0.975) * sqrt(Var.hat.theta.hat.tau) Variansskattning: Var.hat.theta.hat.tau &lt;- (1300)^2 * (1 - (140/1300) ) * (28^2 / 140) + (1800)^2 * (1 - (240/1800) ) * (22^2 / 240) + (1900)^2 * (1 - (220/1900) ) * (16^2 / 220) Ett 95% konfidensintervall ges av \\[\\hat{\\tau}_{st}\\pm z_{\\alpha/2}\\sqrt{\\hat{V}(\\hat{\\tau}_{st})}\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Insättning av värden ger lower.lim &lt;- point.est - qnorm(0.975) * sqrt(Var.hat.theta.hat.tau) upper.lim &lt;- point.est + qnorm(0.975) * sqrt(Var.hat.theta.hat.tau) Svar: Med 95% säkerhet täcker intervallet 369926 till 386474 den totala utgiften för samtliga individer i populationen. rm(list=ls()) Övning 7.19 För en undersökning av livsmedelsutgifterna per hushåll kunde en viss stad delas in i tre separata delar med olika typer av bebyggelse och därmed i viss mån också med olika typer av hushåll. Med hjälp av liknande undersökningar uppskattade man standardavvikelsen för livsmedelsutgifterna i var och en av stadsdelarna. I tabellen nedan ges nödvändig information. Stadsdel Antal hushåll Uppskattning av standardavvikelse A 3000 1000 B 2700 2000 C 5000 800 Beräkna hur ett stickprov på 1000 hushåll bör allokeras på de tre stadsdelarna för att medelfelet i skattningen av de genomsnittliga livsmedelsutgifterna ska bli så litet som möjligt. Vi sammanställer data och kan sedan testa oss fram med R: Nj &lt;- c(3000, 2700, 5000) Ntot &lt;- sum(Nj) sj &lt;- c(1000, 2000, 800) nj &lt;- c(1, 1, 1) # bestäm värden här. Testa dig fram! Obs: sum(nj) ska bli 1000. Alltså måste ursprungliga värden ändras. # Medelfelet. &#39;sum&#39; gör att vi beräknar uttrycket med de första elementen i variablerna som vi definierat, sedan med de andra elementen och till sist med de tredje elementen. sum( (Nj/Ntot)^2 * (1- (nj/Nj)) * (sj/nj) ) ## [1] 380.5363 rm(list=ls()) Övning 7.20 Universitetsledningen ville undersöka hur många timmar i veckan som studenterna vid ett universitet lägger på att studera. Ledningen stratifierade utifrån program och drog ett OSU-UÅ från respektive stratum. Resultatet från undersökningen presenteras i tabellen nedan. Program Antal på program Antal i urval Genomsnitt per vecka \\(s_j\\) A 200 25 20 5 B 150 21 23 5 C 80 22 40 6 D 150 23 35 6 Beräkna ett 90% KI för det genomsnittliga antalet timmar som studenterna vid universitet lägger ner på studierna varje vecka. Mål: Skatta det genomsnittliga antalet timmar som studenterna lägger på studier varje vecka med 90% konfidens. Parameter: \\(\\mu\\) = det genomsnittliga antalet timmar i hela studentpopulationen. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^K\\frac{N_j}{N}\\bar{x}_j\\) = det genomsnittliga antalet timmar i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x}_{st})=\\sum_{j=1}^K\\frac{N_j}{N}E(\\bar{x}_j)=\\mu\\). Populationsstorlek: \\(N\\) = 580. Urvalsstorlek: \\(n\\) = 91. Eftersom \\(\\frac{n}{N}&gt;0,1\\) och vi inte känner populationsfördelningen skattas \\(V(\\bar{x}_{st})\\) med \\(\\hat{V}(\\bar{x}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Tumregeln för stratifierat urval att alla \\(n_j&gt;20\\) är uppfylld så vi kan förlita oss på CGS. Beräkning: Vi börjar med att punktskatta det genomsnittliga antalet timmar: # Först sammanställer vi data Nj &lt;- c(200, 150, 80, 150) # storlekar på strata. Observera att sum(Nj) = 6000 = Ntot. Ntot &lt;- sum(Nj) # populationsstorlek. nj &lt;- c(25, 21, 22, 23) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. x.bar.j &lt;- c(20, 23, 40, 35) # stickprovsmedelvärden per stratum. sj &lt;- c(5, 5, 6, 6) # stickprovsstandardavvikelser per stratum. # punktskatttning. Jämförelse med formler i formelsamling för stratifierat urval uppmuntras! x.bar.tot &lt;- (200/580) * 20 + (150/580) * 23 + (80/580) * 40 + (150/580) * 35 Den skattade variansen för punktskattningen ges av Var.hat.theta.hat.mu &lt;- (200/580)^2 * (1 - (25/200) ) * (5^2 / 25) + (150/580)^2 * (1 - (21/150) ) * (5^2 / 21) + (80/580)^2 * (1 - (22/80) ) * (6^2 / 22) + (150/580)^2 * (1 - (23/150) ) * (6^2 / 23) Ett 90% konfidensintervall för medelvärdet ges av \\[\\bar{x}_{st}\\pm z_{\\alpha/2}\\sqrt{\\hat{V}(\\bar{x}_{st})}.\\] där \\(z_{\\alpha/2}=z_{0,05}=1,6449\\). Insättning av värden: lower.lim &lt;- x.bar.tot - qnorm(0.975) * sqrt(Var.hat.theta.hat.mu) upper.lim &lt;- x.bar.tot + qnorm(0.975) * sqrt(Var.hat.theta.hat.mu) Svar: Med 90% säkerhet täcker intervallet 26,9 till 28,0 det genomsnittliga antalet timmar som studenterna vid universitet lägger på studier varje vecka. rm(list=ls()) Övning 7.21 Universitetsledningen ville undersöka hur stor andel av studenterna vid ett universitet som studerar minst 30 timmar i veckan. Ledningen stratifierade utifrån program och drog ett OSU-UÅ från respektive stratum. Resultatet från undersökningen presenteras i tabellen nedan. Program Antal på program Antal i urval Antal minst 30h/vecka A 200 19 5 B 150 25 7 C 80 16 6 D 150 18 9 Beräkna medelfelet för andelen som studerar minst 30 timmar i veckan. Mål: Beräkna medelfelet för andelen studenter som studerar minst 30 timmar i veckan. Parameter: \\(p\\) = andelen studenter i populationen som studerar minst 30 timmar i veckan. Estimator: \\(\\hat{p}_{st}\\) = andelen studenter i stickprovet som studerar minst 30 timmar i veckan. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{p}_{st})=\\sum_{j=1}^K\\frac{N_j}{N}E(\\hat{p}_j)=p\\). Populationsstorlek: \\(N\\) = 580. Urvalsstorlek: $n$ = 78. Eftersom \\(\\frac{n}{N}&gt;0,1\\) och populationsfördelningen är okänd skattas \\(V(\\hat{p}_{st})\\) med \\(\\hat{V}(\\hat{p}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{\\hat{p}(1-\\hat{p})}{n_j-1}\\). Beräkning: Den skattade variansen för andelen som studerar minst 30 timmar i veckan är # Först sammanställer vi data Nj &lt;- c(200, 150, 80, 150) # storlekar på strata. Observera att sum(Nj) = 6000 = Ntot. Ntot &lt;- sum(Nj) # populationsstorlek. nj &lt;- c(25, 21, 22, 23) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. pj.hat &lt;- c(5/19, 7/25, 6/16, 9/18) # (a) variansskattning Var.hat.theta.hat.p &lt;- (200/580)^2 * (1 - (19/200) ) * ( (5/19) * (1 - (5/19) ) / 18) + (150/580)^2 * (1 - (25/150) ) * ( (7/25) * (1 - (7/25) ) / 24) + (80/580)^2 * (1 - (16/80) ) * ( (6/16) * (1 - (6/16) ) / 15) + (150/580)^2 * (1 - (18/150) ) * ( (9/18) * (1 - (9/18) ) / 17) # medelfelet. sqrt(Var.hat.theta.hat.p) ## [1] 0.0522571 Svar: Medelfelet för andelen studenter som studerar minst 30 timmar i veckan är 0,0523. Kan du beräkna ett 90% KI för andelen studenter vid universitetet som studenterar minst 20 timmar i veckan? Vi vet inte andelen som uppger att de studerar minst 20 timmar i veckan men vi kan använda \\(p=0,5\\) som ger störst varians och alltså bredast möjliga intervall. Om andelen är lika i samtliga strata finns emellertid ingen anledning att använda stratifieringen då den kommer att ge samma resultat som ett OSU. Mål: Skatta andelen studenter som studerar minst 20 timmar i veckan med 90% konfidens. Parameter: \\(p\\) = andelen studenter i populationen som studerar minst 20 timmar i veckan. Estimator: \\(\\hat{p}\\) = andelen studenter i stickprovet som studerar minst 20 timmar i veckan. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{p})=p\\). Populationsstorlek: \\(N\\) = 580. Urvalsstorlek: \\(n\\) = 78. Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\hat{p})\\) med \\(\\hat{V}(\\hat{p})=\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}\\). Stickprovet är ganska stort så vi kan förlita oss på CGS. Beräkning: Ett 90% konfidensintervall för populationsandelen ges av \\[\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\left(\\frac{N-n}{N-1}\\right)\\frac{p(1-p)}{n}}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,6449\\). Insättning av värden ger # andelen som uppger att de studerar minst 20 timmar i veckan är okänd. Vi använder p = 0.5 här (inte p &quot;hatt&quot;, utan p) då detta ger bredast möjliga intervall. Om andelen är lika stor i varje stratum kommer vi att kunna använda OSU-UÅ-formlerna istället. p &lt;- 0.5 # varians för estimatorn. Var.theta.hat.p &lt;- ( (Ntot - sum(nj) ) / (Ntot - 1) ) * ( (p * (1-p))/sum(nj) ) # konfidensintervall. lower.lim &lt;- p - qnorm(0.95) * sqrt(Var.theta.hat.p) upper.lim &lt;- p + qnorm(0.95) * sqrt(Var.theta.hat.p) Svar: Med 90% säkerhet täcker intervallet 0,413 till 0,587 andelen studenter vid universitetet som studerar minst 20 timmar i veckan. rm(list=ls()) Övning 7.22 (Baserad på skrivningsuppgift A5, 110111) Anta att ICA Sverige med hjälp av besöksintervjuer undersökte butikernas kontakter med lokala producenter. Den primära undersökningsvariabeln var antalet lokala producenter. Den totala stickprovsstorleken bestämdes till 200 och man genomförde ett proportionellt stratifierat urval baserat på stratiferingsvariabeln butikstyp. Undersökningen gav följande resultat: Stratum \\(N_j\\) \\(n_j\\) \\(\\bar{x}_j\\) \\(s_j\\) ICA Nära 728 107 9 3 ICA Supermarket 444 65 6 2 ICA Kvantum 119 18 6 3 ICA Maxi 70 10 4 2 Gör en punktskattning av det genomsnittliga antalet lokala producenter bland ICA-butikerna i Sverige. Beräkna även medelfelet för skattningen. Mål: Punktskatta det genonsnittliga antalet lokala producenter bland ICA-butikerna i Sverige samt beräkna medelfelet för skattningen. Parameter: \\(\\mu\\) = det genonsnittliga antalet lokala producenter bland ICA-butikerna i Sverige. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^K\\frac{N_j}{N}\\bar{x}_j\\) = det genonsnittliga antalet lokala producenter i stickprovet. Förutsättningar: Om vi förutsätter OSU från respektive stratum har vi att \\(E(\\bar{x}_{st})=\\mu\\). Populationsstorlek: \\(N\\) = 1361. Urvalsstorlek: \\(n\\) = 200. Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\bar{x})\\) med \\(\\hat{V}(\\bar{x}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Beräkning: Genomsnittet beräknas som: # Först sammanställer vi data Nj &lt;- c(728, 444, 119, 70) # storlekar på strata. Observera att sum(Nj) = 6000 = Ntot. Ntot &lt;- sum(Nj) # populationsstorlek. nj &lt;- c(107, 65, 18, 10) # stickprovsstorlek per stratum. Vi har ett proportionellt stratifierat urval. x.bar.j &lt;- c(9, 6, 6, 4) # stickprovsmedelvärden per stratum. sj &lt;- c(3, 2, 3, 2) # stickprovsstandardavvikelser per stratum. # Genomsnittsberäkning: Jämförelse med formler i formelsamling för stratifierat urval uppmuntras! x.bar.tot &lt;- sum( (Nj/Ntot) * x.bar.j) (200/580) * 20 + (150/580) * 23 + (80/580) * 40 + (150/580) * 35 ## [1] 27.41379 Variansskattning: Var.hat.theta.hat.mu &lt;- (728/1361)^2 * (1 - (107/728) ) * (3^2 / 107) + (444/1361)^2 * (1 - (65/444) ) * (2^2 / 65) + (119/1361)^2 * (1 - (18/119) ) * (3^2 / 18) + (70/1361)^2 * (1 - (10/70) ) * (2^2 / 10) Medelfelet blir: sqrt(Var.hat.theta.hat.mu) ## [1] 0.1739847 Svar: Det genonsnittliga antalet lokala producenter bland ICA-butikerna i Sverige är 7,5 och skattningens medelfel är 0,174. Din uppdragsgivare vill att du beräknar felmarginalen för skattningen i a-uppgiften. Använd konfidensgraden 95 procent. Tolka felmarginalen! Har du någon invändning som statistikkunnig beträffande felmarginalen? Mål: Beräkna felmarginalen för skattningen i (a) med konfidensgraden 95%. Parameter: \\(\\mu\\) = det genonsnittliga antalet lokala producenter bland ICA-butikerna i Sverige. Estimator: \\(\\bar{x}_{st}=\\sum_{j=1}^K\\frac{N_j}{N}\\bar{x}_j\\) = det genonsnittliga antalet lokala producenter i stickprovet. Förutsättningar: Om vi förutsätter OSU från respektive stratum har vi att \\(E(\\bar{x}_{st})=\\mu\\). Populationsstorlek: \\(N\\) = 1361. Urvalsstorlek: \\(n\\) = 200. Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\bar{x})\\) med \\(\\hat{V}(\\bar{x}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Tumregeln vid stratifierat urval att alla \\(n_j&gt;20\\) är inte uppfylld vilket innebär att vi inte kan förlita oss på CGS utan måste anta normalfördelning för att kunna motivera beräkningen av felmarginalen. Beräkning: Felmarginalen ges av \\[z_{\\alpha/2} \\sqrt{\\hat{V}(\\bar{x}_{st})}\\] där \\(z_{\\alpha/2}=z_{0,025}=1,96\\). Insättning av värden: qnorm(0.975) * sqrt(Var.hat.theta.hat.mu) ## [1] 0.3410038 Svar: Felmarginalen innebär att vår punktskattning \\(\\bar{x}_{st}\\) med 95% säkerhet inte avviker med mer än 0,174 från det okända genonsnittliga antalet lokala producenter bland ICA-butikerna i Sverige. Vid en upprepning av undersökningen nästkommande år finns nu en uppfattning om osäkerheten i respektive stratum. Använd de skattade standardavvikelserna och gör en Neyman-allokering av stickprovet. Anta att den totala stickprovsstorleken är samma som föregående år. Mål: Gör en Neyman-allokering av stickprovet. Beräkning: Vi antar att kostnaden är lika för alla strata och ska därför göra allokeringen med följande formel \\[n_j=n\\frac{N_j\\sigma_j}{\\sum_{j=1}^KN_j\\sigma_j}.\\] Vi beräknar först nämnaren som är: Nj.sigmaj &lt;- 728 * 3 + 444 * 2 + 119 * 3 + 70 *2 Stickprovsstorleken är \\(n=200\\) och den nya allokeringen blir: n &lt;- 200 # allokeringar n1 &lt;- 200 * (728*3 / Nj.sigmaj) n2 &lt;- 200 * (444*2 / Nj.sigmaj) n3 &lt;- 200 * (119*3 / Nj.sigmaj) n4 &lt;- 200 * (70*2 / Nj.sigmaj) rm(list=ls()) Övning 7.23 Ett franschiseföretag är intresserat av undersöka den totala försäljningen av en specifik vara, \\(\\tau\\) . Företaget väljer med hjälp av stratifierat urval ut affärer i tre strata och får följande resultat för antalet sålda varor: Landsbygd (\\(N_1 = 510\\)) 30 21 48 38 26 25 41 19 46 41 25 17 36 41 43 35 26 32 30 38 39 37 23 32 34 9 20 22 33 41 54 11 Samhälle (\\(N_2 = 310\\)) 51 44 77 55 38 54 62 57 42 59 50 63 32 63 55 43 53 50 39 56 44 Stad (\\(N_3 = 410\\)) 49 54 63 54 77 94 25 23 53 44 65 86 61 43 85 39 93 43 61 46 32 73 57 Punktskatta det totala antalet sålda varor. Mål: Punktskatta den totala försäljningen av varan. Parameter: \\(\\tau\\) = totala antalet sålda varor. Estimator: \\(\\hat{\\tau}_{st}=\\sum_{j=1}^KN_j\\bar{x}_j\\) = antalet sålda varor i stickprovet. Förutsättningar: Om vi utgår från att varje stratum är draget med OSU har vi att \\(E(\\hat{\\tau}_{st})=NE(\\bar{x}_{st})=\\tau\\). Beräkning: Den totala försäljningen ges av: # först sammanställer vi data. Nj &lt;- c(510, 310, 410) landsbygd &lt;- c(30, 21, 48, 38, 26, 25, 41, 19, 46, 41, 25, 17, 36, 41, 43, 35, 26, 32, 30, 38, 39, 37, 23, 32, 34, 9, 20, 22, 33, 41, 54, 11) samh &lt;- c(51, 44, 77, 55, 38, 54, 62, 57, 42, 59, 50, 63, 32, 63, 55, 43, 53, 50, 39, 56, 44) stad &lt;- c(49, 54, 63, 54, 77, 94, 25, 23, 53, 44, 65, 86, 61, 43, 85, 39, 93, 43, 61, 46, 32, 73, 57) nj &lt;- c(length(landsbygd), length(samh), length(stad)) x.bar.j &lt;- c(mean(landsbygd), mean(samh), mean(stad)) sj &lt;- c( sd(landsbygd), sd(samh), sd(stad) ) # punktesitmat för totalen. x.bar.tot &lt;- 510 * 31.65625 + 310 * 51.7619 + 410 * 57.3913 # alternativt... x.bar.tot &lt;- sum( Nj * x.bar.j ) Svar: En punktskattning av den totala försäljningen av varan är 55721 stycken. Ge en intervallskattning för det totala antalet sålda varor. Använd konfidensgraden 90 procent. Mål: Intervallskatta det totala antalet sålda varor med konfidensgraden 90%. Parameter: \\(\\tau\\) = totala antalet sålda varor. Estimator: \\(\\hat{\\tau}_{st}=\\sum_{j=1}^KN_j\\bar{x}_j\\) = antalet sålda varor i stickprovet. Förutsättningar: Om vi utgår från att varje stratum är draget med OSU har vi att \\(E(\\hat{\\tau}_{st})=NE(\\bar{x}_{st})=\\tau\\). Populationsstorlek: \\(N\\) = 1230. Urvalsstorlek: \\(n\\) = 76. \\(\\frac{n}{N}&lt;0,1\\) men eftersom vi vet populationsstorleken använder vi ändlighetskorrektion och \\(V(\\hat{\\tau}_{st})\\) skattas med \\(\\hat{V}(\\hat{\\tau}_{st})=\\sum_{j=1}^{K}N_j^2\\hat{V}(\\bar{x}_j)=\\sum_{j=1}^{K}N_j^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{s_j^2}{n_j}\\). Tumregeln för stratifierat urval att \\(n_j&gt;20\\) är uppfylld så vi kan förlita oss på CGS. Beräkning: Den skattade variansen för punktskattningen ges av Var.hat.theta.hat.mu &lt;- 510^2 * (1 - (32/510) ) * (10.68798^2 / 32) + 310^2 * (1 - (21/310) ) * (10.39666^2 / 21) + 410^2 * (1 - (23/410) ) * (20.20742^2 / 23) # alternativt... Var.hat.theta.hat.mu &lt;- sum( Nj^2 * (1 - (nj / Nj) ) * (sj^2 / nj) ) Ett 90% konfidensintervall för det totala antalet sålda varor ges av: lower.lim &lt;- x.bar.tot - qnorm(0.95) * sqrt(Var.hat.theta.hat.mu) upper.lim &lt;- x.bar.tot + qnorm(0.95) * sqrt(Var.hat.theta.hat.mu) Svar: Med 90% säkerhet täcker intervallet 52371 till 59071 det totala antalet sålda varor. rm(list=ls()) Övning 7.24 Ett landsting vill skatta det totala antalet vaccinationer som behövs. Landstinget drar ett urval bestående av 23 vårdcentraler med OSU-UÅ från totalt 90 vårdcentaler i landstinget. Följande resultat erhålls från de 25 vårdcentralerna: Antal vaccinationer: 210 239 238 211 262 219 248 227 259 247 207 212 185 253 247 233 177 197 222 198 215 279 242 Antal invånare som är listade vid vårdcentralen: 2680 3820 2010 2000 3900 2970 1640 3120 2280 1740 2080 3420 3040 2730 2370 2430 3390 2800 2860 2740 2950 3010 1600 Beräkna ett 95% KI för det totala antalet vaccinationer som behövs i landstinget. Var noga med förutsättningar! Tolka intervallet! Mål: Skatta det totala antalet vaccinationer som behövs i landstinget med 95% konfidens. Parameter: \\(\\tau\\) = det totala antalet vaccinationer som behövs i landstinget. Estimator: \\(\\hat{\\tau}=N\\bar{x}\\) = antalet vaccinationer i stickprovet där \\(x_i\\) är antalet vaccinationer vid respektive vårdcentral. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{\\tau})=NE(\\bar{x})=N\\mu=\\tau\\). Populationsstorlek: \\(N\\) = 90. Urvalsstorlek: $n$ = 23. Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\hat{\\tau})\\) med \\(\\hat{V}(\\hat{\\tau})=N^2V(\\bar{x})=N^2\\left(1-\\frac{n}{N}\\right)\\frac{s^2)}{n}\\). Vi har ett för litet stickprov för att kunna förlita oss på CGS och antar därför att antalet vaccinationer är normalfördelad i populationen för att kunna använda formlerna vi lärt oss. Beräkning: En punktskattning av totala antalet vaccinationer som behövs är: # först sammanställer vi data. vacc &lt;- c(210, 239, 238, 211, 262, 219, 248, 227, 259, 247, 207, 212, 185, 253, 247, 233, 177, 197, 222, 198, 215, 279, 242) n &lt;- length(vacc) N &lt;- 90 sum.vacc &lt;- sum(vacc) # (a) # punktestimat point.est &lt;- N/n * sum.vacc Variansskattning: Var.hat.theta.hat &lt;- 90^2 * (1- (23 / 90)) * (sd(vacc)^2 / 23) Konfidensintervallet blir: lower.lim &lt;- point.est - qt(0.975, df = 23-1) * sqrt(Var.hat.theta.hat) upper.lim &lt;- point.est + qt(0.975, df = 23-1) * sqrt(Var.hat.theta.hat) Svar: Med 95% säkerhet täcker intervallet 19582 till 21325 det totala antalet vaccinationer som behövs i landstinget. Vad är det genomsnittliga antalet vaccinationer per invånare? Ge en punktskattning. Var noga med förutsättningar! Mål: Punktskatta det genomsnittliga antalet vaccinationer per invånare i landstinget. Parameter: \\(\\mu\\) = det genomsnittliga antalet vaccinationer per invånare i landstinget. Estimator: \\(\\bar{x}\\) = det genomsnittliga antalet vaccinationer per invånare i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Beräkning: Om vi definierar \\(\\sum_{i=1}^{23}y_i\\) = antal vaccinationer i stickprovet och \\(\\sum_{i=1}^{23}z_i\\) = antalet invånare i stickprovet ges det genomsnittliga antalet vaccinationer per invånare av \\[\\bar{x}_{vac/inv}=\\frac{\\sum_{i=1}^{23}y_i}{\\sum_{i=1}^{23}z_i}.\\] Beräkning i R ger: # invånarantalet. inv &lt;- 2680 + 3820 + 2010 + 2000 + 3900 + 2970 + 1640 + 3120 + 2280 + 1740 + 2080 + 3420 + 3040 + 2730 + 2370 + 2430 + 3390 + 2800 + 2860 + 2740 + 2950 + 3010 + 1600 vacc.per.inv &lt;- sum.vacc / inv Svar: En punktskattning av det genomsnittliga antalet vaccinationer per invånare i landstinget är 0,085. rm(list=ls()) Övning 7.25 Vi vill undersöka andelen som röker bland högstadieelever i en kommun. Vi drar därför ett OSU-UÅ bestående av 12 klasser från kommunens totalt 80 klasser och undersöker alla elever i dessa klasser. Totalt finns det 2200 högstadielever i kommunen. Antalet som röker i klasserna i stickprovet är: 12 1 3 4 2 2 7 5 5 12 6 13 och dragna klassernas storlek är 34 26 33 27 21 24 25 29 28 28 30 19. Hur stor andel av kommunens högstadieelever röker? Ange förutsättningar! Mål: Skatta hur stor andel av kommunens högstadieelever som röker. Parameter: \\(p\\) = andelen av kommunens högstadieelever som röker. Estimator: \\(\\hat{p}\\) = andelen högstadieelever i stickprovet som röker. Förutsättningar: OSU-UÅ ger att \\(E(\\hat{p})=p\\). Populationsstorlek: \\(N\\) = 2200. Urvalsstorlek: \\(n\\) = 324. Eftersom \\(\\frac{n}{N}&gt;0,1\\) skattas \\(V(\\hat{p})\\) med \\(\\hat{V}(\\hat{p})=\\left(1-\\frac{n}{N}\\right)\\frac{\\hat{p}(1-\\hat{p})}{n-1}\\). Vi har ett stort stickprov och kan därmed förlita oss till CGS för approximativ normalfördelning. Beräkning: Andelen i stickprovet som röker är # Sammanställ data. n &lt;- 34 + 26 + 33 + 27 + 21 + 24 + 25 + 29 + 28 + 28 + 30 + 19 N &lt;- 2200 smoke &lt;- 12 + 1 + 3 + 4 + 2 + 2 + 7 + 5 + 5 + 12 + 6 + 13 # punktestimat p.hat &lt;- (1/n) * smoke och ett 95% konfidensintervall för andelen ges av \\[\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\hat{V}(\\hat{p})}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,96\\). Insättning av värden ger variansskattningen: Var.hat.theta.hat &lt;- (1 - (smoke/n) ) * ( (p.hat * ( 1 - p.hat ) ) / (n-1) ) Intervallet blir: lower.lim &lt;- p.hat - qnorm(0.975) * sqrt(Var.hat.theta.hat) upper.lim &lt;- p.hat + qnorm(0.975) * sqrt(Var.hat.theta.hat) Svar: Med 95% säkerhet täcker intervallet 0,18 till 0,26 andelen av kommunens högstadieelever som röker. rm(list=ls()) Övning 7.26 En organisation vill skatta medelåldern bland avlidna i ebola i ett område i Liberia. Urvalsramen består av 150 vårdenheter och 3 av dessa väljs med OSU-UÅ. Information om åldern på de avlidna hämtas fram från respektive vårdenhet och är som följer: Ålder på avlidna, vårdenhet 1: 13 36 31 23 34 14 23 20 26 28 33 39 32 29 26 26 40 22 19 30 42 34 28 9 47 25 15 26 18 11 18 30 27 25 33 2 15 33 28 38 31 42 16 23 33 35 20 43 11 35 35 31 19 31 43 20 49 Ålder på avlidna, vårdenhet 2: 30 25 30 27 23 31 30 21 36 31 28 32 35 38 28 27 41 35 34 32 33 30 40 29 29 29 34 25 26 Ålder på avlidna, vårdenhet 3: 29 40 36 28 17 24 31 27 40 20 26 35 40 34 23 44 30 12 32 35 37 28 35 35 39 33 40 40 36 25 46 40 Organisationen får fram att den genomsnittliga åldern bland de avlidna i området med 95% säkerhet är mellan 27,32 till 30,46 år. Beräkna ett alternativt medelfel om du vet att det totalt dog 5100 i ebola på de 150 vårdenheterna. Är ditt medelfel mer korrekt än organisationens? Mål: Beräkna medelfelet för den genomsnittliga åldern bland avlidna i Ebola i stickprovet. Parameter: \\(\\mu\\) = den genomsnittliga åldern bland avlidna i Ebola i populationen. Estimator: \\(\\bar{x}\\) = den genomsnittliga åldern bland avlidna i Ebola i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Populationsstorlek: \\(N\\) = 5100. Urvalsstorlek: \\(n\\) = 118. \\(\\frac{n}{N}&lt;0,1\\) men vi vet populationsstorleken och använder ändlighetskorrektion varpå \\(V(\\bar{x})\\) skattas med \\(\\hat{V}(\\bar{x})=\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}\\). Beräkning: Medelfelet ges av \\[\\text{Medelfel} = \\sqrt{\\hat{V}(\\bar{x})} =\\sqrt{\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}}.\\] Insättning av värden ger: # sammanställ data. N &lt;- 5100 age &lt;- c(13, 36, 31, 23, 34, 14, 23, 20, 26, 28, 33, 39, 32, 29, 26, 26, 40, 22, 19, 30, 42, 34, 28, 9, 47, 25, 15, 26, 18, 11, 18, 30, 27, 25, 33, 2, 15, 33, 28, 38, 31, 42, 16, 23, 33, 35, 20, 43, 11, 35, 35, 31, 19, 31, 43, 20, 49, 30, 25, 30, 27, 23, 31, 30, 21, 36, 31, 28, 32, 35, 38, 28, 27, 41, 35, 34, 32, 33, 30, 40, 29, 29, 29, 34, 25, 26, 29, 40, 36, 28, 17, 24, 31, 27, 40, 20, 26, 35, 40, 34, 23, 44, 30, 12, 32, 35, 37, 28, 35, 35, 39, 33, 40, 40, 36, 25, 46, 40) n &lt;- length(age) # alternativt medelfel, jämfört med organisationens. se.age &lt;- sqrt( (1 - (n/N)) * (var(age) / n ) ) Svar: Medelfelet för genomsnittsåldern bland avlidna i Ebola i området är 0,7878. Eftersom vi nu har använt information om populationsstorleken är vårt medelfel mer korrekt än organisationens. Kan du beräkna ett konfidensintervall? Mål: Beräkna ett 95% konfidensintervall för den genomsnittliga åldern i området. Parameter: \\(\\mu\\) = den genomsnittliga åldern bland avlidna i Ebola i populationen. Estimator: \\(\\bar{x}\\) = den genomsnittliga åldern bland avlidna i Ebola i stickprovet. Förutsättningar: OSU-UÅ ger att \\(E(\\bar{x})=\\mu\\). Populationsstorlek: \\(N\\) = 5100. Urvalsstorlek: \\(n\\) = 118. \\(\\frac{n}{N}&lt;0,1\\) men vi vet populationsstorleken och använder ändlighetskorrektion varpå \\(V(\\bar{x})\\) skattas med \\(\\hat{V}(\\bar{x})=\\left(1-\\frac{n}{N}\\right)\\frac{s^2}{n}\\). Vi har ett stort stickprov och kan förlita oss på CGS. Beräkning: Ett 95% konfidensintervall för populationsmedelvärdet ges av \\[\\bar{x} \\pm z_{\\alpha/2} \\sqrt{\\hat{V}(\\bar{x})}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,96\\). Insättning av värden i intervallet ger: point.est &lt;- mean(age) lower.lim &lt;- point.est - qnorm(0.975) * se.age upper.lim &lt;- point.est + qnorm(0.975) * se.age Svar: Med 95% säkerhet täcker intervallet 28,02 till 31,15 den genomsnittliga åldern bland avlidna i Ebola i området. rm(list=ls()) Övning 7.27 En kommun vill undersöka andelen som ställer sig positiva till en ny arena. Kommunen stratifierar på ålder och drar sedan i respektive ålderskategori ett systematiskt urval från RTB. Resultatet blev följande: Stratum \\(N_j\\) \\(n_j\\) Andel positiva \\(\\hat{p}_j\\) 18-34 år 3300 400 0,5 35-59 år 4000 400 0,7 60 år eller äldre 3400 400 0,3 Beräkna ett 90% KI för andelen positiva i kommunen. Var noga med förutsättningar! Tolka intervallet! Mål: Skatta andelen i kommunen som ställer sig positiva till en ny arena med ett 90% konfidensintervall. Parameter: \\(p\\) = andelen i kommunen som ställer sig positiva till en ny arena. Estimator: \\(\\hat{p}_{st}=\\sum_{j=1}^{K}\\frac{N_j}{N}\\hat{p}_j\\) = andelen i stickprovet som ställer sig positiva till en ny arena. Förutsättningar: Om vi utgår från att respektive stratum framtagits slupmässigt har vi att \\(E(\\hat{p}_{st})=p\\). Populationsstorlek: \\(N\\) = 10700. Urvalsstorlek: \\(n\\) = 1200. Eftersom \\(\\frac{n}{N}&gt;0,1\\) och populationsfördelningen är okänd skattas \\(V(\\hat{p}_{st})\\) med \\(\\hat{V}(\\hat{p}_{st})=\\sum_{j=1}^{K}\\left(\\frac{N_j}{N}\\right)^2\\left(1-\\frac{n_j}{N_j}\\right)\\frac{\\hat{p}_j(1-\\hat{p}_j)}{n_j-1}\\). Tumregeln för stratifierat urval att \\(n_j&gt;20\\) är uppfylld och vi kan förlita oss på CGS. Beräkning: En punktskattning av andelen positiva är # sammanställ data. Anta slumpmässigt framtagna värden i våra strata. Nj &lt;- c(3300, 4000, 3400) Ntot &lt;- sum(Nj) nj &lt;- c(400, 400, 400) pj.hat &lt;- c(0.5, 0.7, 0.3) # punktskattning p.hat &lt;- (3300/10700) * 0.5 + (4000/10700) * 0.7 + (3400/10700) * 0.3 Den skattade variansen för punktskattningen är Var.hat.theta.hat.p &lt;- (3300/10700)^2 * (1 - (400/3300) ) * ( (1/2) * (1 - (1/2) ) / 399) + (4000/10700)^2 * (1 - (400/4000) ) * ( (7/10) * (1 - (7/10) ) / 399) + (3400/10700)^2 * (1 - (400/3400) ) * ( (3/10) * (1 - (3/10) ) / 399) Ett 90% konfidensintervall för andelen positiva i kommunen ges av \\[\\hat{p}_{st} \\pm z_{\\alpha/2} \\sqrt{\\hat{V}(\\hat{p}_{st})}\\] där \\(z_{\\alpha/2}=z_{0,05}=1,6449\\). Insättning av värden ger: lower.lim &lt;- p.hat - qnorm(0.95) * sqrt(Var.hat.theta.hat.p) upper.lim &lt;- p.hat + qnorm(0.95) * sqrt(Var.hat.theta.hat.p) Svar: Med 90% säkerhet täcker intervallet 0,4900 till 0,5324 andelen i kommunen som ställer sig positiva till en ny arena. "]
]
