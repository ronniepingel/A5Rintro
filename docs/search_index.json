[
["experiment.html", "Kapitel 10 Experiment 10.1 Det klassiska experimentet 10.2 Stratifiering 10.3 ANOVA 10.4 Jämförelse med t-test 10.5 Experimentella designer 10.6 Aspekter som inte ingår i detta block", " Kapitel 10 Experiment 10.1 Det klassiska experimentet 10.1.1 Randomiseringen I det klassiska experimentet allokeras \\(n\\) objekt (individer) slumpmässigt till en behandlingsgrupp bestående av \\(n_t\\) objekt eller en kontrollgrupp bestående av \\(n_c\\) objekt. Sannolikheten för ett objekt att hamna i behandlingsgruppen är \\(\\Pr(T=1) = n_t/n\\) och sannolikhet att hamna i kontrollgruppen är \\(1-\\Pr(T=1) = \\Pr(T=0) = n_c/n\\). För att i praktiken allokera objekten genomförs en slumpmässig permutation av objekt i en identifieringsvariabel (som vi kan kalla id_nr). Permutationen görs med sample() och utan återläggning. Objekten allokeras sedan till behandlingsgruppen och kontrollgruppen genom att skapa en binär behandlingsvariabel, w, där de första \\(n_t\\) elementen består av 1or (eller ett annat värde som syftar på behandlingsgruppen) och de resterande \\(n_c\\) elementen är 0or (eller något annat värde som syftar på kontrollgruppen). Allokeringen kan genomföras oavsett om det finns en komplett lista på objekt (motsvarande en urvalsram i urvalsmetoder) eller om rekrytering sker löpande där id-nr relaterar till när ett objekt rekryteras till studiens. Det enda som krävs för allokeringen är kunskap om antalet objekt i behandlingsgruppen och kontrollgruppen. Traditionellt har man då haft kuvert med id-nummer innehållande en lapp som indikerar allokering. Exempel 1 Adman och Larsson Taghizadeh (2020) ville bland annat undersöka om det finns en effekt av avsändarens yrkestitel i e-post på skoladministratörers respons vad gäller en frågor om skolval. Utifrån en lista baserat på alla Sveriges 290 kommuner gjordes en allokering till olika behandlingsgrupper. Exempel 2 Selin et al. undersökte effekten av det värkstimulerade medlet oxytocin bland gravida med utdragen förlossning. Avsikten var att se om det fanns en effekt av dos oxytocin (låg vs hög dos) på tid till att barnet var fött. Rekryteringen till det här experimentet skedde löpande på ett antal förlossningsavdelningar i Sverige. En kvinna på förlossningen blev tillfrågad om hon ville delta i experimentet. Om hon tackade ja tilldelades hon ett id-nummer och en enkät fylldes in. Därefter öppnades ett kuvert med id-numret och i kuvertet fanns stod A eller B. Eftersom blindning är viktigt vet endast den som gjort randomiseringen vilken dos A eller B refererar till. Av 1296 kvinnor som tackade ja allokerades 647 till hög dos och 648 till låg dos. Exempel 3 Anta att vi i Uppsala kommun rekryterar 40 individer till att delta i ett randomiserat försök. Individerna som valt att delta i experimentet slumpas till en av två grupper. Listan med allokeringen sparas. Id-nummer skrivs ner på ett kuvert och en lapp som indikerar behandlingsgrupp läggs i kuvertet. # Antal objekt (individer) i experimentet n &lt;- 40 # Antal objekt i behandlingsgrupp n_t &lt;- 22 # Antal objekt i kontrollgrupp n_c &lt;- 18 # Lista med id-nr id_nr &lt;- 1:40 # Skapa en slumpmässig permutation (Ni kommer få en annan fördelning om vi inte sätter slumptalsfröet). set.seed(8) id &lt;- sample(id_nr, replace = FALSE) # Skapa en behandlingsvariabel w &lt;- c(rep(1, n_t), rep(0, n_c)) # Dataframe för data df_trt &lt;- data.frame(id = id, trt = w) df_trt id trt 1 32 1 2 34 1 3 15 1 4 12 1 5 1 1 6 29 1 7 3 1 8 6 1 9 22 1 10 20 1 11 11 1 12 8 1 13 4 1 14 14 1 15 9 1 16 26 1 17 37 1 18 7 1 19 35 1 20 19 1 21 33 1 22 23 1 23 2 0 24 38 0 25 17 0 26 10 0 27 13 0 28 31 0 29 25 0 30 16 0 31 40 0 32 5 0 33 18 0 34 21 0 35 27 0 36 24 0 37 28 0 38 36 0 39 30 0 40 39 0 Det är dock mycket vanligt att vid rekryteringen eller före randomseringen samla in data om individerna/objekten. Denna information kan vara mycket användbar på många sätt och är ofta nödvändig för att skapa sig en helhetsbild i en studie. En oerhört viktig princip är att baslinjevariabler mäts före randomiseringen eller åtminstone före man öppnar kuvertet som anger allokeringen. Exempel 3 forts. Anta att vi i vårt exempel mäter ålder, kön och utbildning före öppnandet av kuvertet. Vi erhåller ett mer omfattande dataset med bakgrundvariabler. df &lt;- df_trt[order(df_trt$id),] # Variablerna mäts efterhand som individerna deltar i studien. df$alder &lt;- c(34,56,59,34,37,46,43,45,66,55,29,55,67,66,54,67,45,32,44,45,29,33,66,55,34,22,66,23,34,25,26,48,56,33,61,60,30,40,66,43) df$kon &lt;- factor(c(&quot;kvinna&quot;, &quot;man&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;man&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;,&quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;man&quot;, &quot;man&quot;,&quot;man&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;,&quot;man&quot;, &quot;man&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;kvinna&quot;, &quot;man&quot;, &quot;kvinna&quot;,&quot;man&quot;,&quot;kvinna&quot;), levels = c(&quot;kvinna&quot;, &quot;man&quot;)) df$utbildning &lt;- factor(c(&quot;mellan&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;hög&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;låg&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;låg&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;hög&quot;, &quot;låg&quot;, &quot;hög&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;låg&quot;, &quot;hög&quot;, &quot;låg&quot;, &quot;mellan&quot;, &quot;hög&quot;, &quot;hög&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;mellan&quot;, &quot;låg&quot;, &quot;hög&quot;, &quot;mellan&quot;, &quot;mellan&quot;), levels = c(&quot;låg&quot;, &quot;mellan&quot;, &quot;hög&quot;) ) df id trt alder kon utbildning 5 1 1 34 kvinna mellan 23 2 0 56 man mellan 7 3 1 59 man mellan 13 4 1 34 kvinna låg 32 5 0 37 man hög 8 6 1 46 kvinna mellan 18 7 1 43 man låg 12 8 1 45 kvinna låg 15 9 1 66 man mellan 26 10 0 55 man mellan 11 11 1 29 man låg 4 12 1 55 kvinna mellan 27 13 0 67 kvinna mellan 14 14 1 66 kvinna mellan 3 15 1 54 man låg 30 16 0 67 kvinna låg 25 17 0 45 kvinna mellan 33 18 0 32 kvinna mellan 20 19 1 44 man hög 10 20 1 45 kvinna låg 34 21 0 29 kvinna hög 9 22 1 33 man mellan 22 23 1 66 kvinna mellan 36 24 0 55 man mellan 29 25 0 34 man låg 16 26 1 22 man mellan 35 27 0 66 man låg 37 28 0 23 kvinna låg 6 29 1 34 kvinna hög 39 30 0 25 man låg 28 31 0 26 kvinna mellan 1 32 1 48 man hög 21 33 1 56 man hög 2 34 1 33 kvinna mellan 19 35 1 61 kvinna låg 38 36 0 60 kvinna mellan 17 37 1 30 man låg 24 38 0 40 kvinna hög 40 39 0 66 man mellan 31 40 0 43 kvinna mellan 10.1.2 Balans av baslinjemätningar När randomiseringen blivit genomförd undersöker vi om randomseringen har fungerat. Detta görs genom att redovisa beskrivande statistik för baslinjemätningen i behandlingsgrupp respektive kontrollgrupp. Notera att vi inte genomför någon hypotesprövning vid en jämförelse av baslinjemätningarna. Eftersom behandlingen är slumpmässig vet vi de facto att populationen inte finns någon skillnad mellan behandlingsgrupperna. En hypotesprövning är därför ologisk att genomföra eftersom vi testar en hypotes som vi vet är sann. Däremot är det viktigt att deskriptivt se på hur det ser ut i data och det gör vi genom vi genom att ställa upp deskriptiv statistik i en tabell. För kvantitativa variabler redovisar man i regel antingen medelvärde och median samt tillhörande spridning mått standardavvikelse eller kvartilavstånd. För kategorivariabler redovisas oftast antal och procent. Exempel 3 forts. Vi vill nu i vårt randomiserade försök studera om det finns en skillnad i stickprovet mellan behandlingsgrupperna. För att undersöka detta skapar vi en tabell. Tabellen kan man sedan exportera till html-format för vidare import till ett ordbehandlingsprogram. # Ålder alder_balans &lt;- c(mean(df$alder[df$trt == 1]), sd(df$alder[df$trt == 1]), mean(df$alder[df$trt == 0]), sd(df$alder[df$trt == 0])) # Kön kon_balans_kvinna &lt;- c(table(df$kon[df$trt == 1])[1], 100*prop.table(table(df$kon[df$trt == 1]))[1], table(df$kon[df$trt == 0])[1], 100*prop.table(table(df$kon[df$trt == 0]))[1]) kon_balans_man &lt;- c(table(df$kon[df$trt == 1])[2], 100*prop.table(table(df$kon[df$trt == 1]))[2], table(df$kon[df$trt == 0])[2], 100*prop.table(table(df$kon[df$trt == 0]))[2]) # Utbildning utbildning_balans_lag &lt;- c(table(df$utbildning[df$trt == 1])[1], 100*prop.table(table(df$utbildning[df$trt == 1]))[1], table(df$utbildning[df$trt == 0])[1], 100*prop.table(table(df$utbildning[df$trt == 0]))[1]) utbildning_balans_mellan &lt;- c(table(df$utbildning[df$trt == 1])[2], 100*prop.table(table(df$utbildning[df$trt == 1]))[2], table(df$utbildning[df$trt == 0])[2], 100*prop.table(table(df$utbildning[df$trt == 0]))[2]) utbildning_balans_hog &lt;- c(table(df$utbildning[df$trt == 1])[3], 100*prop.table(table(df$utbildning[df$trt == 1]))[3], table(df$utbildning[df$trt == 0])[3], 100*prop.table(table(df$utbildning[df$trt == 0]))[3]) # Antal i behandlingsgrupper samt NA eftersom vi har fyra kolumner. n &lt;- c(n_t,NA,n_c,NA) # Sammanfoga vektorerna och ange sedan kolumnnamn och radnanmn Tabell1 &lt;- rbind(n, alder_balans, kon_balans_kvinna, kon_balans_man, utbildning_balans_lag, utbildning_balans_mellan, utbildning_balans_hog) colnames(Tabell1) &lt;- c(&quot;Behandlingsgrupp&quot;, &quot;&quot;, &quot;Kontrollgrupp&quot;, &quot;&quot;) rownames(Tabell1) &lt;- c(&quot;n&quot;, &quot;Ålder (medelvärde (sd))&quot;, &quot;Kön: Kvinna (antal (%))&quot;, &quot;Kön: Man (antal (%))&quot;, &quot;Utbildning: låg (antal (%))&quot;, &quot;Utbildning: mellan (antal (%))&quot;, &quot;Utbildning: hög (antal (%))&quot;) # Exportera tabellen till html. Digits anger antal decimaler i respektive kolumna library(&quot;xtable&quot;) print(xtable(Tabell1, digits = c(0,1,1,1,1)), type = &quot;html&quot;) Behandlingsgrupp V2 Kontrollgrupp V4 n 22.0 18.0 Ålder (medelvärde (sd)) 45.6 13.4 45.9 15.8 Kön: Kvinna (antal (%)) 11.0 50.0 10.0 55.6 Kön: Man (antal (%)) 11.0 50.0 8.0 44.4 Utbildning: låg (antal (%)) 8.0 36.4 5.0 27.8 Utbildning: mellan (antal (%)) 10.0 45.5 10.0 55.6 Utbildning: hög (antal (%)) 4.0 18.2 3.0 16.7 Exempel 4 Vi använder National Supported Work Demonstration project, som är att arbetsstödsprogram för långtidsarbetslösa som riktade sig till fyra grupper: tidigare dömda för brott, tidigare narkomaner, kvinnor som under en lång tid fått ekonomiskt bistånd samt avhoppare från skola. Programmet pågick i 12-18 månader på 15 ställen i USA. 6600 invivider allokerades slumpmässigt till antingen deltagande i arbetsstödsprogram eller till en kontrollgrupp. Vi har här ett urval av originaldata bestående av 722 individer. Variablerna är treat: 1 jobbsupport, 0 ingen support age: Ålder år ed: Utbildningsår black: 1 afro-amerikan, 0 annars. hisp: 1 hispanic, 0 annars. married: 1 gift, 0 annars nodel: 1 collegeexamen, 0 annars. re75: reel inkomst 1975 (efter randomiseringen och start av programmet) re78: reel inkomst 1978 (huvudutfallet) Vi skapar nu en Tabell 1 för att studera om randomiseringen har fungerat. library(&quot;ATE&quot;) data(nsw) alder_balans &lt;- c(mean(nsw$age[nsw$treat == 1]), sd(nsw$age[nsw$treat == 1]), mean(nsw$age[nsw$treat == 0]), sd(nsw$age[nsw$treat == 0])) utb_balans &lt;- c(mean(nsw$ed[nsw$treat == 1]), sd(nsw$ed[nsw$treat == 1]), mean(nsw$ed[nsw$treat == 0]), sd(nsw$ed[nsw$treat == 0])) etnicitet_balans_black&lt;- c(table(nsw$black[nsw$treat == 1])[1], 100*prop.table(table(nsw$black[nsw$treat == 1]))[1], table(nsw$black[nsw$treat == 0])[1], 100*prop.table(table(nsw$black[nsw$treat == 0]))[1]) etnicitet_balans_hisp &lt;- c(table(nsw$hisp[nsw$treat == 1])[1], 100*prop.table(table(nsw$hisp[nsw$treat == 1]))[1], table(nsw$hisp[nsw$treat == 0])[1], 100*prop.table(table(nsw$hisp[nsw$treat == 0]))[1]) civilstand_balans_gift&lt;- c(table(nsw$married[nsw$treat == 1])[1], 100*prop.table(table(nsw$married[nsw$treat == 1]))[1], table(nsw$married[nsw$treat == 0])[1], 100*prop.table(table(nsw$married[nsw$treat == 0]))[1]) examen_balans_nodeg &lt;- c(table(nsw$nodeg[nsw$treat == 1])[1], 100*prop.table(table(nsw$nodeg[nsw$treat == 1]))[1], table(nsw$nodeg[nsw$treat == 0])[1], 100*prop.table(table(nsw$nodeg[nsw$treat == 0]))[1]) n_t &lt;- sum(nsw$treat == 1) n_c &lt;- sum(nsw$treat == 0) n &lt;- c(n_t, NA, n_c, NA) # Sammanfoga vektorerna och ange sedan kolumnnamn och radnanmn Tabell1 &lt;- rbind(n, alder_balans, utb_balans, etnicitet_balans_black, etnicitet_balans_hisp, civilstand_balans_gift, examen_balans_nodeg) colnames(Tabell1) &lt;- c(&quot;Behandlingsgrupp&quot;, &quot;&quot;, &quot;Kontrollgrupp&quot;, &quot;&quot;) rownames(Tabell1) &lt;- c(&quot;n&quot;, &quot;Ålder (medelvärde (sd))&quot;, &quot;Utbildningsår: (medelvärde (sd))&quot;, &quot;Etnicitet: Afro-amerikan (antal (%))&quot;, &quot;Etnicitet: Hispanic (antal (%))&quot;, &quot;Civilstånd: Gift (medelvärde (sd))&quot;, &quot;Examen: Ingen examen (antal (%))&quot;) # Exportera tabellen till html. Digits anger antal decimaler i respektive kolumna library(&quot;xtable&quot;) print(xtable(Tabell1, digits = c(0,1,1,1,1)), type = &quot;html&quot;) Behandlingsgrupp V2 Kontrollgrupp V4 n 297.0 425.0 Ålder (medelvärde (sd)) 24.6 6.7 24.4 6.6 Utbildningsår: (medelvärde (sd)) 10.4 1.8 10.2 1.6 Etnicitet: Afro-amerikan (antal (%)) 59.0 19.9 85.0 20.0 Etnicitet: Hispanic (antal (%)) 269.0 90.6 377.0 88.7 Civilstånd: Gift (medelvärde (sd)) 247.0 83.2 358.0 84.2 Examen: Ingen examen (antal (%)) 80.0 26.9 79.0 18.6 För att få tabellerna estetiskt tilltalande i en rapport är det enklare för nybörjaren att modifiera dem i ordbehandlingsprogrammet när rapport närmar sig att bli färdig. Nedan finns ett exempel på hur en sådan tabell kan se ut. Det bör avslutningsvis nämnas att det finns paket i R som skapar tabeller som jämför baslinjemätningar i behandlingsgrupp och i kontrollgrupp. 10.1.3 Analys Anta att målet är att jämföra två stycken populationer med avseende på medelvärden. I populationen har vi \\[\\delta = \\mu_t - \\mu_c\\] För att skatta denna skillnad använder vi \\[\\hat{\\delta} = \\bar{y}_t - \\bar{y}_c\\] där \\(\\bar{y}_t = \\dfrac{1}{n_t}\\sum_{i=1}^{n_t} y_{t,i}\\) och \\(\\bar{y}_c = \\dfrac{1}{n_c}\\sum_{i=1}^{n_c} y_{c,i}\\). För att skatta variansen för denna estimator använder vi \\[\\hat{V}(\\hat{\\delta}) = \\dfrac{s^2_t}{n_t} + \\dfrac{s^2_c}{n_c}\\] \\(\\hat{\\delta}\\) är approximativt normalfördelad i stora stickprov. library(&quot;ATE&quot;) data(nsw) df &lt;- nsw n_t &lt;- sum(df$treat == 1) n_c &lt;- sum(df$treat == 0) ybar_t &lt;- mean(df$re78[df$treat == 1]) ybar_c &lt;- mean(df$re78[df$treat == 0]) deltahat &lt;- ybar_t -ybar_c s2_t &lt;- var(df$re78[df$treat == 1]) s2_c &lt;- var(df$re78[df$treat == 0]) vhatdeltahat &lt;- s2_t/n_t + s2_c/n_c se_hatdelta &lt;- sqrt(vhatdeltahat) KI_delta &lt;- c(deltahat - 1.96*sqrt(vhatdeltahat), deltahat + 1.96*sqrt(vhatdeltahat)) zobs &lt;- deltahat/sqrt(vhatdeltahat) p_value &lt;- 2*(1 - pnorm(abs(zobs))) deltahat [1] 886.3037 se_hatdelta [1] 488.2045 KI_delta [1] -70.57715 1843.18461 zobs [1] 1.815435 p_value [1] 0.06945704 I R används Welchs \\(t\\)-test t.test(df$re78 ~ df$treat, var.equal = FALSE) Welch Two Sample t-test data: df$re78 by df$treat t = -1.8154, df = 557.06, p-value = 0.06999 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -1845.25051 72.64305 sample estimates: mean in group 0 mean in group 1 5090.048 5976.352 Lika eller olika varianser? t.test(df$re78 ~ df$treat, var.equal = TRUE) Two Sample t-test data: df$re78 by df$treat t = -1.8774, df = 720, p-value = 0.06086 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -1813.13381 40.52635 sample estimates: mean in group 0 mean in group 1 5090.048 5976.352 10.2 Stratifiering Utgå från att vi har \\(G\\) strata eller block där stratum \\(g\\) består \\(n_g\\) observationer. Vi utför inom varje stratum en randomisering, enligt det klassiska experimentet. Vi har nu en stratumspecifik medelvärdesskillnad \\[\\delta_g = \\mu_{t,g} - \\mu_{c,g}\\] vilken skattas med \\[\\hat{\\delta}_g = \\bar{y}_{t,g} - \\bar{y}_{c,g}\\] {y}_{t,g} Variansen för denna skattas med \\[\\hat{V}(\\hat{\\delta}_g) = \\dfrac{s^2_{t,g}}{n_{t,g}} + \\dfrac{s^2_{c,g}}{n_{c,g}}\\] Skattningarna vi får är nu \\[\\hat{\\delta}_{st} = \\sum_{g=1}^G\\left(\\dfrac{n_g}{n}\\right)\\hat{\\delta}_g\\] vars varians skattas med \\[\\hat{V}\\left(\\hat{\\delta}_{st}\\right) = \\sum_{g=1}^G\\left(\\dfrac{n_g}{n}\\right)^2\\hat{V}(\\hat{\\delta}_g)\\] # Stratum (block) 1 n_t1 &lt;- sum(df$treat == 1 &amp; df$u75 == 0) n_c1 &lt;- sum(df$treat == 0 &amp; df$u75 == 0) n_1 &lt;- n_t1 + n_c1 ybar_t1 &lt;- mean(df$re78[df$treat == 1 &amp; df$u75 == 0]) ybar_c1 &lt;- mean(df$re78[df$treat == 0 &amp; df$u75 == 0]) deltahat_1 &lt;- ybar_t1 - ybar_c1 s2_t1 &lt;- var(df$re78[df$treat == 1 &amp; df$u75 == 0]) s2_c1 &lt;- var(df$re78[df$treat == 0 &amp; df$u75 == 0]) vhatdeltahat_1 &lt;- s2_t1/n_t1 + s2_c1/n_c1 # Stratum (block) 2 n_t2 &lt;- sum(df$treat == 1 &amp; df$u75 == 1) n_c2 &lt;- sum(df$treat == 0 &amp; df$u75 == 1) n_2 &lt;- n_t2 + n_c2 ybar_t2 &lt;- mean(df$re78[df$treat == 1 &amp; df$u75 == 1]) ybar_c2 &lt;- mean(df$re78[df$treat == 0 &amp; df$u75 == 1]) deltahat_2 &lt;- ybar_t2 - ybar_c2 s2_t2 &lt;- var(df$re78[df$treat == 1 &amp; df$u75 == 1]) s2_c2 &lt;- var(df$re78[df$treat == 0 &amp; df$u75 == 1]) vhatdeltahat_2 &lt;- s2_t2/n_t2 + s2_c2/n_c2 n &lt;- n_1 + n_2 # Effekt deltahat_st &lt;- (n_1/n)*deltahat_1 + (n_2/n)*deltahat_2 vhatdeltahat_st &lt;- (n_1/n)^2*vhatdeltahat_1 + (n_2/n)^2*vhatdeltahat_2 se_hatdelta_st &lt;- sqrt(vhatdeltahat_st) zobs_st &lt;- deltahat_st/sqrt(vhatdeltahat_st) p_value_st &lt;- 2*(1 - pnorm(abs(zobs_st))) KI_delta_st &lt;- c(deltahat_st - 1.96*sqrt(vhatdeltahat_st), deltahat_st + 1.96*sqrt(vhatdeltahat_st)) deltahat_st [1] NaN se_hatdelta_st [1] NaN KI_delta_st [1] NaN NaN p_value_st [1] NaN # Jämförelse av variansskattningar vhatdeltahat/vhatdeltahat_st [1] NaN 10.3 ANOVA För att introducera Analysis of Variance (ANOVA) och få en förståelse för en del underliggande koncept ska vi se på mönstringsdatat INSARK. Framför allt fokuserar vi på benstyrkan hos unga män födda år 1962, 1968 och 1974 som mönstrade. Populationsdata som består av 52347 stycken 1962, 48771 år 1968 samt 43741 år 1974 presenteras nedan. df &lt;- read.csv2(&quot;data/conscriptiondata.csv&quot;) par(mfrow = c(3,1)) hist(df$legstrength[df$year == 1962], breaks = 100, col = &quot;red&quot;, freq = FALSE, main = &quot;&quot;, xlab = &quot;Benstyrka (Newton)&quot;) hist(df$legstrength[df$year == 1968], breaks = 100, add = TRUE, col = &quot;blue&quot;, freq = FALSE) hist(df$legstrength[df$year == 1974], breaks = 100, add = TRUE, col = &quot;darkgreen&quot;, freq = FALSE) plot(density(df$legstrength[df$year == 1962], bw = 15), col = &quot;red&quot;, main = &quot;Tre populationner?&quot;, xlab = &quot;Benstyrka (Newton)&quot;) lines(density(df$legstrength[df$year == 1968], bw = 15), col = &quot;blue&quot;) lines(density(df$legstrength[df$year == 1974], bw = 15), col = &quot;darkgreen&quot;) plot(density(df$legstrength[df$year == 1962 | df$year == 1968 | df$year == 1974], bw = 40), col = &quot;black&quot;, main =&quot;En population?&quot;, xlab = &quot;Benstyrka (Newton)&quot;) Börja nu med att anta att vi inte kan observera all data. Vi önskar dock få en uppfattning om benstyrkan i populationen och om denna skiljer sig åt mellan åren. För att besvara denna fråga drar vi ett OSU från respektive födelseår med storlekarna \\(n_1=120\\), \\(n_2=300\\), \\(n_3=200\\). Dessa individers benstyrka mäts och data lägga in i ett dataframe. df &lt;- data.frame(y = c(467.4,590.5,599.7,546.7,615.9,508.3,780.3,563.4,782,625.9,709.2,471.9,623.9,636.6,706.8,740.6,580.3,518.1,526.6,584.8,470.5,463.8,627.5,448.1,464.5,365.2,603.8,541.6,612.6,457.1,472.3,568.6,479.2,584.1,303,673.8,397.6,513.2,529.6,766.1,696,430.3,452.4,540.8,641.8,480.2,411.3,726.2,577.5,421.5,515.7,833.8,512.2,509.3,420.9,704.2,467.8,400.7,419,427.3,565.9,564.2,204.2,490.5,448.9,792,389.9,437.7,440.2,581.2,465.1,569.1,698.7,632.1,336.2,485.5,452.2,695.1,394.7,566.1,628.6,513.7,692.2,624.7,664,482.7,586.8,651,530,683.9,440.5,548,563,592.3,750,515.9,685.4,522,750.1,778.5,591.8,635.9,524.9,356.2,379.3,455.4,656.4,587.2,600.9,623.4,526.3,550.4,748.2,518,594.7,696.7,829.4,362.9,679.9,421.8,626.4,830,680.2,400.8,725.5,472.5,456.9,640,710.8,755.6,643.1,481.6,794.9,501.1,597.1,615.3,524,732.2,475.6,641.2,571.4,721.9,545.8,487.9,646.1,546.7,857,472.1,497.6,565.2,835,478.7,650.7,564.2,631.5,636.2,767.6,437.9,664.7,592.8,534.3,465.2,651,566.8,608.9,517.3,582.2,498.9,616.7,728.5,541.3,466.1,449.2,518.9,702.9,547.9,582.1,595.4,532.6,826.1,633.6,518.5,500.3,550.6,635.8,459.2,777.1,631.4,578.4,485.9,855.1,634.8,816.6,546.8,555.5,602.4,501.3,590.5,518,634.4,701.2,762.5,436.8,497.6,520.6,556.4,686.6,553.2,614.2,580.5,463.3,707.5,677.5,773.4,570,530.9,524.5,377.8,467.9,753.2,705.8,436.4,732.1,450.2,699.9,586.2,464.4,535.9,632.2,642,557.7,436,604.3,324.8,496.3,494.5,576.1,615.4,439.6,325.9,589.9,683.2,513.3,376,549,806.1,463.5,591,529,577.3,567.7,469.4,408.6,659,928.6,679.3,525.9,427.4,882.2,528.1,539.5,656.5,612.4,629,370.4,590.9,582.9,394.5,590.4,529.7,401.5,489.3,826.5,588.6,659.4,501.5,598.2,226.1,446.7,738.5,738.9,504.9,440.6,448.6,733.6,508.4,560.2,516.5,784,549.7,566.8,582.5,730.7,623.4,688.2,746.1,574,655.1,690.8,728.5,489.4,557.2,622.6,644.8,586.7,748.9,900,649.2,474.3,485.1,667.3,667,457.1,988.4,445.3,452.1,691,556.8,764.6,615.5,351.7,436.6,576.8,553.6,302.5,586.1,556.1,601.8,458.7,704.1,644.5,471.7,689.4,482,728.1,389.4,723.4,519.5,761.1,559.6,635.3,544.8,750.6,556.4,498.1,607.5,576.7,533.2,536.5,454.6,625.7,580.3,499.5,631.5,396.4,505.1,616.7,696.5,694.8,536.7,435.4,553.1,484,561,575,487.4,575.6,567.4,604.6,453.6,794.4,557.7,633.8,635.4,705.6,504.4,966.9,463.3,580.2,502.1,549.1,668.9,686,618.6,458.5,762.3,388.3,645.9,483.9,704.9,561.9,726.9,535.9,701.6,611.8,434.7,668.3,500.9,617.1,433.5,682.1,520.5,709.5,678.8,699.9,412.6,857.7,733.1,643.9,773.4,662.8,573.8,673.9,509.7,608.4,966.8,628.5,727.7,542.2,540.4,625.1,668.2,645.6,637.1,554.2,677.3,562.1,626.8,742.3,587.1,903.6,418.5,895.8,604.1,378.7,444.8,526.6,546.4,751.4,616.7,723.6,621.7,786.4,780.3,622.9,579.2,744.1,820.4,792.3,835.9,563.9,405.1,671.8,494.6,735.4,540.7,605.4,523,504.5,697.8,854.2,580.1,440.3,480,415.1,731.8,489.5,545.8,460.5,587.5,689.3,509.2,798.3,614.1,661.4,706,547.9,663.1,918.8,724.9,680.4,744.2,469.7,360.4,781.5,700.2,560.4,591.5,661.4,697,595.4,783.1,570,630,1011.9,584.2,572.7,611.4,543.5,687.2,666,435.7,775.8,709.3,441.8,723.2,874,767.6,555.3,595.6,497.3,722.2,589.8,607.3,673.2,616.3,537,645.6,622.5,666,659.5,731.3,621.6,426.3,638.4,686.8,661.7,615.5,606.2,565.2,585.9,461.9,646.6,847.2,590.7,707,574.1,711.4,501.1,621.3,618.3,569.1,680.4,541.7,729,577,702.8,608.5,690.5,442.7,613.7,541.6,568.6,598.2,577.8,505.5,507.3,722.8,482.4,640.7,554,789.2,661.4,680.1,525.4,645.4,650.1,499.4,826.5,493.2,580.1,728.4,511.8,711.7,813.2,610.9,385.2,604.5,516.6,737.1,489.7,674.7,643.4,641.3,1018.2,698.8,572.6,774.5,687.2,417.1,661.6,817.2,732.5,451.3,488.1,653.3,577.9,494.4,659.9,457.5,487.8,641.2,499.5,611.4,473,699.3,518.8,961.8,774.9,602.5,539.5,558.8,638,421.2,392.6,640.8,450,591.7,530.1,698.5), year = c(rep(&quot;1962&quot;, 120), rep(&quot;1968&quot;, 300), rep(&quot;1974&quot;, 200))) Som sig bör tittar vi på data, även om vi har formulerat vår frågeställning och eventuella statistiska hypoteser i förväg. Figurerna ger inte särskilt vägledning. Det verkar finnas ganska mycket överlapp mellan åren. par(mfrow = c(4,1)) hist(df$y[df$year == &quot;1962&quot;], xlim = c(0,1200), freq= FALSE, col =&quot;red&quot;, main = &quot;1962&quot;, xlab = &quot;Benstyrka (Newton)&quot;, ylab = &quot;Täthet&quot;) hist(df$y[df$year == &quot;1968&quot;], xlim = c(0,1200), freq= FALSE, col = &quot;blue&quot;, main = &quot;1968&quot;, xlab = &quot;Benstyrka (Newton)&quot;, ylab = &quot;Täthet&quot;) hist(df$y[df$year == &quot;1974&quot;], xlim = c(0,1200), freq= FALSE, col = &quot;darkgreen&quot;, main = &quot;1974&quot;, xlab = &quot;Benstyrka (Newton)&quot;, ylab = &quot;Täthet&quot;) boxplot(df$y ~ df$year, xlab = &quot;&quot;, ylab = &quot;Benstyrka (Newton)&quot;) Det är tur att vi redan bestämt oss för att undersöka detta formellt och inte utifrån att vi tittat på data. Vi inleder med att konstatera att en individs värde kan delas upp i två delar \\[y_{ij} = \\mu_i + \\varepsilon_{ij}\\] där \\(\\mu_i\\) är medelvärdet i population \\(i\\) från vilket individen är vald och \\(\\varepsilon_{ij}\\) som är skillnaden mellan en populations medelvärde och individens värde. För en kontinuerlig variabel har alla individer i given population \\(i\\) olika avvikelser. Eftersom individer väljs slumpmässigt med ett osu är denna avvikelse slumpmässig. Nu kommer vi till en stort steg vad gäller målet för inferens. Vi slutar nämligen just här att intressera oss för just denna ändliga population. Visserligen skulle vi med vårt stickprov undersöka om det finns en skillnad i medelvärden i den ändliga populationen, men vid närmare eftertanke är denna hypotes tämligen ointressant. Undersökte vi alla så skulle det förmodligen finnas skillnader mellan medelvärden, om än kanske liten! UDessutom vet vi att det finns en slumpmässig naturlig variation. Det finns ingen anledning att tänka sig att benstyrkan i populationen är exakt samma varje år, utan den kommer naturligtvis att variera. För att en jämförelse ska bli användbar så att en intressant frågeställning kan besvaras, t ex har benstyrkan bland ungan män förändrats mellan åren, modifierar vi ovanstående ekvation. Istället för att ha ändliga populationen som utgångspunkt ställer vi upp populationen som en statistisk fördelning. Även om skulle observera alla individer varje år så antar vi att det är dessa statistiska fördelningar som gett upphov till individernas värden. x = 1:1200 plot(x, dnorm(x, 583.8242, 120), type = &quot;l&quot;, col = &quot;black&quot;, ylim = c(0,1200), main= &quot;Nollhypotes&quot;) plot(x, dnorm(x, 552.1966, 120), type = &quot;l&quot;, col = &quot;red&quot;, main = &quot;Mothypotes&quot;) lines(x, dnorm(x, 592.1725, 120), type = &quot;l&quot;, col = &quot;blue&quot;) lines(x, dnorm(x, 612.3662, 120), type = &quot;l&quot;, col = &quot;darkgreen&quot;) Nollhypotesen är den översta populationen, dvs vi tänker att benstyrkan är samma för alla år och följer samma fördelning. Mothypotesen är att minst något att medelvärdena skiljer sig åt, dvs populationerna har olika parametervärden. Och det är just detta vi vill undersöka, det vill säga har det skett än förändring i dessa underliggare fördelningar? För att besvara detta ställer vi ekvation som förut \\[y_{ij} = \\mu_i + \\varepsilon_{ij}\\] där vi nu antar att \\(\\varepsilon_{ij}\\) är en oberoende slumpvariabel som är normalfördelad med medelvärde 0 och varians \\(\\sigma^2_{\\varepsilon}\\). Oberoende innebär intuitivt att en slumpmässig dragning från denna modell inte påverkas av en tidigare dragning. Vi skriver detta som att \\[\\varepsilon_{ij} \\sim $N(0,\\sigma^2_{\\varepsilon})\\]. Detta kan tyckas vara ett stort antagande att göra, men vi ska se att modellen trots detta är användbar. Medelvärdena syftar nu på medelvärdena i dessa fördelningar, inte i den ändliga populationen och vi formulerar hypoteserna som \\[H_0: \\mu_{1962} = \\mu_{1968} = \\mu_{1974}\\] vs \\[H_0: \\text{Minst ett av medelvärdena skiljer sig åt}\\] Detta är en modellbaserad ansats där vi utgår från att data kommer från statistisk modell, och vårt mål i detta fall är att med hjälp av detta data uttala oss om något om parametrarna i modellen. Vi \\(a\\) stycken grupper. \\[H_0: \\mu_{1} = \\mu_{2} = \\cdots = \\mu_{a}\\] vs \\[H_1: \\text{Minst en}\\,\\, \\mu_{i} \\neq \\mu_{j}\\] Vi observerar \\(y_{ij}\\), där Varje grupp har \\(n_i\\) observationer. \\(\\bar{y}\\) är medelvärdet för alla observationer i stickprovet \\(\\bar{y}_i\\) är medelvärdet för observationerna i stickprovet tillhörande grupp \\(i\\) \\(i = 1,\\ldots,a\\) indexerar grupper/faktornivår/populationer \\(j = 1,\\ldots,n_{i}\\) indexerer individer i grupp \\(i\\) \\(n = \\sum_{1=i}^3 n_i\\) är antalet indivder i studien. För att undersöka detta studeras variationen mellan grupperna och inom grupper. Vi förkastar \\(H_0\\) om variationen mellan grupperna är stor i relation till variationen inom grupperna (som vi antar är samma). Variationen mellan grupper mäter vi med \\[SSA = \\sum_{i=1}^a n_i(\\bar{y}_i - \\bar{y})^2\\] Variationen inom grupperna är \\[SSE = \\sum_{i=1}^a \\sum_{j}^{n_i}(y_{ij} - \\bar{y}_i)^2\\] Den totala variation är \\[SST = \\sum_{i=1}^a \\sum_{j}^{n_i}(y_{ij} - \\bar{y})^2\\] Man kan visa att \\(SST = SSA + SSE\\)! Detta är ett mycket viktigt resultat och kallas för kvadratsummeuppdelning. Det visar sig att dessa kvadratsummor följer statistiska fördelningar. Vi har att \\[\\dfrac{SST}{\\sigma^2} \\sim \\chi^2_{n-1}\\,\\,\\,\\,\\,\\,\\,\\,\\dfrac{SSA}{\\sigma^2} \\sim \\chi^2_{a-1}\\,\\,\\,\\,\\,\\,\\,\\,\\ \\dfrac{SSE}{\\sigma^2} \\sim \\chi^2_{n-a}\\] Om SSA och SSE är oberoende så är \\[\\dfrac{SSA/(a-1)}{SSE/(n-a)} = \\dfrac{MSA}{MSE}\\sim F_{a-1,n-a}\\] Eftersom dessa kvadratsummor följer en fördelning under nollhypotesen så kan vi beräkna \\[F_{obs} =\\dfrac{MSA}{MSE}\\] och jämföra med denna fördelning. Om \\(F_{obs} &gt; F_{a-1,n-a, \\alpha}\\), förkasta \\(H_0\\). Intutionen bakom testet är att om variationen mellan behandlingarna är stor relativt variationen inom behandlingarna så är \\(F_{obs}\\) stort. Då är det troligt att det finns en underliggare skillnad mellan populationernan. Om \\(F_{obs}\\) är litet så är det med överensstämmelde med att det inte finns någon skillnad mellan grupperna. F-fördelningen? par(mfrow=c(3,2)) x &lt;- seq(0,10,0.1) plot(x, df(x, 2, 4), type = &quot;l&quot;, main = &quot;F(2,4)&quot;, ylab = &quot;Täthet&quot;) plot(x, df(x, 2, 40), type = &quot;l&quot;, main = &quot;F(2,40)&quot;,ylab = &quot;Täthet&quot;) plot(x, df(x, 2, 400), type = &quot;l&quot;, main = &quot;F(2,400)&quot;,ylab = &quot;Täthet&quot;) plot(x, df(x, 5, 4), type = &quot;l&quot;, main = &quot;F(5,4)&quot;,ylab = &quot;Täthet&quot;) plot(x, df(x, 5, 40), type = &quot;l&quot;, main = &quot;F(5,40)&quot;,ylab = &quot;Täthet&quot;) plot(x, df(x, 5, 400), type = &quot;l&quot;, main = &quot;F(5,400)&quot;,ylab = &quot;Täthet&quot;) Stegen för en ANOVA är alltså: Ställ upp modellen \\[y_{ij} = \\mu_i + \\varepsilon_{ij}\\] där \\(\\varepsilon_{ij} \\sim N(0, \\sigma^2_\\varepsilon)\\). Ställ upp hypoteserna enligt ovan. Beräkna F-statisikan. Jämför observerade \\(F\\)-värdet med \\(F\\)-fördelningen under nollhypotesen. # Illustration a &lt;- 3 y_1 &lt;- df$y[df$year == &quot;1962&quot;] y_2 &lt;- df$y[df$year == &quot;1968&quot;] y_3 &lt;- df$y[df$year == &quot;1974&quot;] y &lt;- df$y n_1 &lt;- length(y_1) n_2 &lt;- length(y_2) n_3 &lt;- length(y_3) ybar &lt;- mean(y) ybar_1 &lt;- mean(y_1) ybar_2 &lt;- mean(y_2) ybar_3 &lt;- mean(y_3) n &lt;- n_1 + n_2 + n_3 SSA &lt;- n_1*(ybar_1 - ybar)^2 + n_2*(ybar_2 - ybar)^2 + n_3*(ybar_3 - ybar)^2 SSE &lt;- sum((y_1 - ybar_1)^2) + sum((y_2 - ybar_2)^2) + sum((y_3 - ybar_3)^2) SST &lt;- sum((y - ybar)^2) fg1 &lt;- a-1 fg2 &lt;- n-a MSA &lt;- SSA/fg1 MSE &lt;- SSE/fg2 Fobs &lt;- MSA/MSE p_value &lt;- 1 - pf(Fobs, fg1, fg2) x &lt;- seq(0, 10, 0.1) df(x, fg1, fg2) [1] 1.000000e+00 9.045589e-01 8.182533e-01 7.402064e-01 6.696255e-01 [6] 6.057944e-01 5.480656e-01 4.958541e-01 4.486311e-01 4.059185e-01 [11] 3.672843e-01 3.323380e-01 3.007264e-01 2.721305e-01 2.462616e-01 [16] 2.228591e-01 2.016870e-01 1.825322e-01 1.652019e-01 1.495218e-01 [21] 1.353343e-01 1.224970e-01 1.108809e-01 1.003695e-01 9.085757e-02 [26] 8.224968e-02 7.445968e-02 6.740964e-02 6.102907e-02 5.525421e-02 [31] 5.002739e-02 4.529645e-02 4.101421e-02 3.713798e-02 3.362917e-02 [36] 3.045284e-02 2.757739e-02 2.497425e-02 2.261755e-02 2.048388e-02 [41] 1.855209e-02 1.680302e-02 1.521932e-02 1.378533e-02 1.248685e-02 [46] 1.131103e-02 1.024626e-02 9.282008e-03 8.408768e-03 7.617922e-03 [51] 6.901673e-03 6.252963e-03 5.665406e-03 5.133220e-03 4.651172e-03 [56] 4.214524e-03 3.818988e-03 3.460682e-03 3.136091e-03 2.842034e-03 [61] 2.575630e-03 2.334271e-03 2.115596e-03 1.917466e-03 1.737945e-03 [66] 1.575282e-03 1.427887e-03 1.294324e-03 1.173291e-03 1.063609e-03 [71] 9.642099e-04 8.741275e-04 7.924858e-04 7.184916e-04 6.514265e-04 [76] 5.906396e-04 5.355415e-04 4.855984e-04 4.403264e-04 3.992874e-04 [81] 3.620846e-04 3.283582e-04 2.977824e-04 2.700621e-04 2.449298e-04 [86] 2.221432e-04 2.014827e-04 1.827493e-04 1.657629e-04 1.503599e-04 [91] 1.363924e-04 1.237262e-04 1.122397e-04 1.018227e-04 9.237538e-05 [96] 8.380713e-05 7.603596e-05 6.898749e-05 6.259432e-05 5.679536e-05 [101] 5.153520e-05 plot(x, df(x, fg1, fg2), type = &quot;l&quot;) abline(h=c(Fobs)) Det finns även inbyggd funktion i R för att beräkna. # lm() model1 &lt;- lm(df$y ~ df$year) anova(model1) Analysis of Variance Table Response: df$y Df Sum Sq Mean Sq F value Pr(&gt;F) df$year 2 338372 169186 11.393 1.384e-05 *** Residuals 617 9162495 14850 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 par(mfrow = c(1,2)) qqnorm(model1$residuals) hist(model1$residuals) Under förutsättning av variansen är samma kan vi även beräkna ett konfidensintervall. För det första skattas \\(\\mu_i\\) med \\(\\bar{y}_i\\). Eftersom \\(\\varepsilon_{ij} \\sim N(0, \\sigma^2_{\\varepsilon})\\) så är \\[V(\\bar{y}_i) = \\dfrac{\\sigma^2_\\varepsilon}{n_i} \\approx \\dfrac{MSE}{n_i}\\] Ett konfidensintervall för \\(\\mu_i\\) ges då av \\[\\bar{y}_i \\pm t_{\\alpha/2,n-a}\\sqrt{\\dfrac{MSE}{n_i}}\\]. 10.4 Jämförelse med t-test ANOVA med två grupper är samma som t-test med lika varianser. ANOVA är ett annat sätt att formulera regressionsanalys I praktiken om experimenten är någotlunda stora, ingen skillnad. 10.5 Experimentella designer Completely randomized expreiment (analogt med OSU) Strafifierat randomized exerpiment (analogit med stratifierat urval) Grupp (kluster) randomized experiment (analogt med grupp urval) 10.6 Aspekter som inte ingår i detta block Hantering av bortfall. Jämförelse av medelvärden vid ANOVA med mer än 2 behandling, t ex Tukeys eller Dunnets metod. Diskussion om massignifikans. Analys av klusterrandomiserade experiment Val av relevant parameter: Intention-to-treat. Complier average causal effect. Per protocol. Hänsyn tagen till utfall mätt före randomisering. Ingår dock i regressionsdelen på kursen. Styrkeberäkning En tydlig åtskillnad mellan block och strata. Flera mätningar per individ. Icke-parametriskt alternativ Icke-normalitet "],
["referenser-2.html", "Kapitel 11 Referenser", " Kapitel 11 Referenser Adman, P., &amp; Taghizadeh, J. L. (2020) Offentliga tjänstemäns bemötande av minoritetsklienter. IFAU Rapport Serie. Selin, Lotta, Ulla-Britt Wennerholm, Maria Jonsson, Anna Dencker, Gunnar Wallin, Eva Wiberg-Itzel, Elisabeth Almström, Max Petzold, and Marie Berg (2019). High-dose versus low-dose of oxytocin for labour augmentation: a randomised controlled trial. Women and Birth, 32(4), 356-363 "]
]
